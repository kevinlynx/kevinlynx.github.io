[ { "title": "Kubernete APIServer Sample", "url": "/posts/kube_apiserver_sample/", "categories": "弹性调度", "tags": "kubernetes", "date": "2018-05-30 00:00:00 +0800", "snippet": "kubernetes从apiserver中独立出来了一个项目：apiserver，可以基于这个库快速实现一个类似kubernetes apiserver的服务。 Generic library for building a Kubernetes aggregated API server. 如果直接阅读kubenetes的apiserver源码，会发现很多实现都位于这个项目中。kubenetes源码目录下还有个sample-apiserver，是用于示例如何使用这个库的。从这个sample可以更快速地了解kubernetes apiserver的实现，以及如何使用。简单来说，这个apiserver库做了很多抽象，基本上，用户只需要描述自己的资源结构是怎样的，就可以构建出一个类似kubernetes的apiserver，具备资源多版本兼容能力，对外提供json/yaml的http restful接口，并持久化到etcd中。接下来主要讲下大概的用法以及apiserver中的主要概念。apiserver简介apiserver简单来说，可以理解为一个基于etcd，并提供HTTP接口的对象(资源)系统。其提供了针对多种资源的操作，例如CRUD、列表读取、状态读取。kubernetes中POD、Deployment、Service，都是资源，可以说kubernetes所有组件都是围绕着资源运作的。apiserver库本身是不提供任何资源的，它做了很多抽象，使得应用层可以根据自己需要添加各种资源。同时，apiserver支持相同资源多个版本的存在。为了更容易地理解apiserver的设计，可以先自己思考如何实现出这样一个通用的资源服务框架，例如，可能需要解决以下问题： HTTP接口层，根据资源名映射出不同的URI，如何统一地从HTTP请求中创建出不同类型的资源 不同的资源支持的操作不同，如何区分 资源的多版本如何实现 资源如何统一地序列化存储到etcd中 核心概念 在看例子代码之前，有必要提一下apiserver中的一些关键概念。 StorageStorage连接底层存储etcd与HTTP route。apiserver库中会自动注册各种资源对应的HTTP route。在route的处理中则会调用storage的接口。storage是分类型的，其通过检查是否实现了某个golang接口来确定其类型，例如在apiserver的代码中：//(a *APIInstaller) registerResourceHandlerscreater, isCreater := storage.(rest.Creater)namedCreater, isNamedCreater := storage.(rest.NamedCreater)lister, isLister := storage.(rest.Lister)getter, isGetter := storage.(rest.Getter)通过确定某个资源的storage类型，以确定该资源支持哪些动作，apiserver中叫HTTP verb。 SchemeScheme用于描述一种资源的结构，就像可以用一段JSON描述一个对象的结构一样。Scheme可以描述一种资源如何被创建；资源不同版本间如何转换；某个版本的资源如何向internal资源转换。通常会看到类似的注册：// 注册资源类型scheme.AddKnownTypes(SchemeGroupVersion,\t&amp;Flunder{},\t&amp;FlunderList{},\t&amp;Fischer{},\t&amp;FischerList{},)Scheme 会在很多地方被用到，可以理解为其实它就是一种隔离具体数据类型的机制。作为一个库，要支持应用层注册不同类型的资源，就需要与应用层建立资源的契约：应用层如何让框架层知道某个具体的资源长什么样，在诸如存储、编解码、版本转换等问题上如何提供给框架特有的信息。 CodecCodec和上面的Scheme密不可分。Codec利用Scheme在HTTP请求及回应中对一个资源做编解码。这其中又会涉及到Serializer之类的概念，主要也是利用Scheme来支持类似yaml/json这些不同的请求格式。Codec基本对应用层透明。这里把上面3个概念串通：HTTP请求来时，利用Codec基于Scheme将具体的资源反序列化出来，最后交给Storage持久化到etcd中；反之，当读取资源时，通过Storage从etcd中基于Scheme/Codec读取资源，最后Codec到HTTP Response中。 版本及Groupapiserver中对不同的资源做了分组，这里暂时不关心。相同资源可以有不同的版本并存。值得注意的是，apiserver内部有一个internal版本的概念。internal版本负责与Storage交互，从而隔离Storage与不同版本资源的依赖。不同版本的资源都可以与internal版本转换，不同版本之间的转换则通过internal版本间接转换。样例通过sample-apiserver，可以理解apiserver的接口。看下sample-apiserver的源码结构：// kubernetes/staging/src/k8s.io/sample-apiserverpkg/├── admission├── apis│   └── wardle│   ├── install│   └── v1alpha1├── apiserver├── client├── cmd│   └── server└── registry └── wardle ├── fischer └── flunder其中，核心的目录主要包括： cmd/apiserver，基本上相当于程序入口，其中会初始化整个框架 register，Storage相关部分 apis，定义具体的资源类型，初始化Scheme要通过apiserver构建出一个类似kubernetes的apiserver，大概要完成以下步骤： 初始化框架，可以理解为如何把apiserver跑起来 Storage，为不同group不同版本定义好Storage，有很多工具类可以直接使用 Scheme，定义资源的Scheme，告知框架资源长什么样基于以上过程，接下来看下sample-apiserver如何完成的。启动过程程序入口从cmd包中看，然后会到apiserver包。核心的代码主要在apiserver.go中func (c completedConfig) New() 。其中核心的对象是genericapiserver.GenericAPIServer。拿到该对象时，就可以run起来：// cmd/server/start.goreturn server.GenericAPIServer.PrepareRun().Run(stopCh)其中，拿到GenericAPIServer后最重要的就是安装资源的Storage：// apiserver/apiserver.goapiGroupInfo := genericapiserver.NewDefaultAPIGroupInfo(wardle.GroupName, registry, Scheme, metav1.ParameterCodec, Codecs)apiGroupInfo.GroupMeta.GroupVersion = v1alpha1.SchemeGroupVersionv1alpha1storage := map[string]rest.Storage{}v1alpha1storage[\"flunders\"] = wardleregistry.RESTInPeace(flunderstorage.NewREST(Scheme, c.GenericConfig.RESTOptionsGetter))v1alpha1storage[\"fischers\"] = wardleregistry.RESTInPeace(fischerstorage.NewREST(Scheme, c.GenericConfig.RESTOptionsGetter))apiGroupInfo.VersionedResourcesStorageMap[\"v1alpha1\"] = v1alpha1storageif err := s.GenericAPIServer.InstallAPIGroup(&amp;apiGroupInfo); err != nil {\treturn nil, err}上面的代码中，apiGroupInfo保存了单个Group下多个Version的资源Storage，关键数据成员是VersionedResourcesStorageMap，这个例子代码表示： 有1个Version: v1alpha1 该Version下有2个资源：flunders，fischers 为每个资源配置对应的StorageStorageStorage如何构建，就可以继续跟下wardleregistry.RESTInPeace。这部分代码主要在registry下。核心的实现在NewRest中，如：// pkg/registry/wardle/fischer/etcd.go store := &amp;genericregistry.Store{\tNewFunc: func() runtime.Object { return &amp;wardle.Fischer{} },\tNewListFunc: func() runtime.Object { return &amp;wardle.FischerList{} },\tPredicateFunc: MatchFischer,\tDefaultQualifiedResource: wardle.Resource(\"fischers\"),\tCreateStrategy: strategy,\tUpdateStrategy: strategy,\tDeleteStrategy: strategy,}要构建storage，其实只要使用genericregistry.Store即可。这里可以针对一些主要数据成员做下说明。NewFunc返回的对象，会被用于响应REST接口，例如通过API获取一个资源时，就会先NewFunc获取到一个空的资源对象，然后由具体的存储实现(如etcd)来填充这个资源。举个例子，genericregistry.Store.Get会直接被HTTP route调用，其实现大概为：// kubernetes/vendor/k8s.io/apiserver/pkg/registry/generic/registry/store.gofunc (e *Store) Get(ctx genericapirequest.Context, name string, options *metav1.GetOptions) (runtime.Object, error) {\tobj := e.NewFunc()\tkey, err := e.KeyFunc(ctx, name)\t...\tif err := e.Storage.Get(ctx, key, options.ResourceVersion, obj, false); err != nil {\t\treturn nil, storeerr.InterpretGetError(err, e.qualifiedResourceFromContext(ctx), name)\t}...}以上，e.Storage就是具体的存储实现，例如etcd2，而obj传入进去是作为输出参数。在创建资源时，NewFunc出来的对象，也是用于e.Storage从etcd存储中读取的对象，作为输出用。Scheme前面看到apiserver.go中时，除了创建GenericAPIServer外，还存在包的init实现，即该包被import时执行的动作。这个动作，主要就是用来处理Scheme相关事宜。// pkg/apiserver/apiserver.gofunc init() {\tinstall.Install(groupFactoryRegistry, registry, Scheme)\t...}同时注意apiserver.go 中定义的全局变量：var (...\tScheme = runtime.NewScheme()\tCodecs = serializer.NewCodecFactory(Scheme))install.Install的实现比较典型，kubernetes自身的apiserver中也有很多类似的注册代码。// pkg/apis/wardle/install/install.go\tif err := announced.NewGroupMetaFactory(\t\t&amp;announced.GroupMetaFactoryArgs{\t\t\tGroupName: wardle.GroupName,\t\t\tRootScopedKinds: sets.NewString(\"Fischer\", \"FischerList\"),\t\t\tVersionPreferenceOrder: []string{v1alpha1.SchemeGroupVersion.Version},\t\t\tAddInternalObjectsToScheme: wardle.AddToScheme,\t\t},\t\tannounced.VersionToSchemeFunc{\t\t\tv1alpha1.SchemeGroupVersion.Version: v1alpha1.AddToScheme,\t\t},\t).Announce(groupFactoryRegistry).RegisterAndEnable(registry, scheme); err != nil {\t\tpanic(err)\t}RegisterAndEnable最终完成各种资源类型注册到Scheme中。在install.go中import里还要注意register.go中的init初始化：// pkg/apis/wardle/v1alpha1/register.govar (\tlocalSchemeBuilder = &amp;SchemeBuilder\tAddToScheme = localSchemeBuilder.AddToScheme)func init() {\tlocalSchemeBuilder.Register(addKnownTypes)}func addKnownTypes(scheme *runtime.Scheme) error {\tscheme.AddKnownTypes(SchemeGroupVersion,\t\t&amp;Flunder{},\t\t&amp;FlunderList{},\t\t&amp;Fischer{},\t\t&amp;FischerList{},\t)\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)\treturn nil}SchemeBuilder 其实就是个function列表，在前面的RegisterAndEnable中最终会传递Scheme对象到这个函数列表中的每个函数，也就会执行到上面的addKnownTypes。除了注册资源类型外，在类似 zz_generated.conversion.go文件中还通过init自动注册了各种转换函数。Scheme的工作原理比较复杂，这个改天有机会讲。回过头来看Scheme的用法，其实主要就是告诉框架层这个对象长什么样，实现上就是传了个空对象指针进去。Codec与Scheme前面的全局变量中就涉及到Codec，可以看出是依赖了Scheme的。可以稍微进去看看底层实现，例如：// k8s.io/apimachinery/pkg/runtime/serializer/codec_factory.gofunc NewCodecFactory(scheme *runtime.Scheme) CodecFactory {\tserializers := newSerializersForScheme(scheme, json.DefaultMetaFactory)\treturn newCodecFactory(scheme, serializers)}其中，newSerializersForScheme 就根据scheme创建了json/yaml的Serializer，可以理解为用于解析HTTP请求，创建对应的资源。从这里可以看看Serializer是如何工作的，如何与Scheme关联的，例如Serializer必然会被用于解析HTTP请求：// k8s.io/apimachinery/pkg/runtime/serializer/json/json.go// 可以推测originalData就是HTTP请求内容func (s *Serializer) Decode(originalData []byte, gvk *schema.GroupVersionKind, into runtime.Object) (runtime.Object, *schema.GroupVersionKind, error) {\t...\tobj, err := runtime.UseOrCreateObject(s.typer, s.creater, *actual, into)\t...\t// 拿到一个空的资源对象后，直接用json解析\tif err := jsoniter.ConfigCompatibleWithStandardLibrary.Unmarshal(data, obj); err != nil {\t...}// 这里的ObjectTyper/ObjectCreater都是Schemefunc UseOrCreateObject(t ObjectTyper, c ObjectCreater, gvk schema.GroupVersionKind, obj Object) (Object, error) {\t...\t// 最终根据gvk (group version kind) 创建具体的资源\treturn c.New(gvk)}以上可以看出Scheme其实并没有什么神秘的地方，有点像一种factory的模式，用于避免框架层对应用层具体类型的依赖：objPtr := factory.New()json.Unmarshal(data, objPtr)总结kubernetes apiserver 库虽然是个独立的library，但是使用起来却不容易，也没有什么文档。所以这里仅仅是通过分析其源码，了解apiserver内部的一些概念，方便阅读kubernetes自己的apiserver实现，以及深入apiserver库的实现。" }, { "title": "kubernetes网络相关总结", "url": "/posts/kube-network/", "categories": "弹性调度", "tags": "kubernetes", "date": "2018-04-01 00:00:00 +0800", "snippet": "要理解kubernetes的网络模型涉及到的技术点比较多，网络上各个知识点讲得细的有很多，这里我就大概梳理下整个架构，方便顺着这个脉络深入。本文主要假设kubernetes使用docker+flannel实现。整体上，了解kubernetes的网络模型，涉及到以下知识： linux网络及网络基础 docker网络模型 kubernetes网络需求，及flannel网络实现最后大家就可以结合实例对照着学习。Linux网络先看几个概念，引用自Kubernetes网络原理及方案: 网络命名空间 Linux在网络栈中引入网络命名空间，将独立的网络协议栈隔离到不同的命令空间中，彼此间无法通信；docker利用这一特性，实现不同容器间的网络隔离 网桥 网桥是一个二层网络设备,通过网桥可以将linux支持的不同的端口连接起来,并实现类似交换机那样的多对多的通信 Veth设备对 Veth设备对的引入是为了实现在不同网络命名空间的通信 路由 Linux系统包含一个完整的路由功能，当IP层在处理数据发送或转发的时候，会使用路由表来决定发往哪里借图以关联上面的概念：安装docker后，系统中就会有一个docker0网桥。通过ifconfig 或ip link可以查看(准确的说是查看网络设备？)：$ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT qlen 1000 link/ether 00:16:3e:00:03:9a brd ff:ff:ff:ff:ff:ff3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT link/ether 02:42:c0:a8:05:01 brd ff:ff:ff:ff:ff:ff一个docker POD中，多个容器间是共享网络的。在POD中，有一个默认的网络设备，就像物理机上一样，名为eth0。POD中的eth0通过Veth设备对，借由docker0网桥与外部网络通信。veth设备对同样可以用ip link查看，系统中有多少POD就会有多少veth对：$ip link...219: veth367a306c@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT link/ether 62:de:88:30:86:fa brd ff:ff:ff:ff:ff:ff link-netnsid 19220: veth684956fd@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT link/ether fe:b8:33:8c:25:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 20222: veth9e23eff7@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT link/ether 7e:e9:2d:f2:28:e5 brd ff:ff:ff:ff:ff:ff link-netnsid 22veth对只是不同网络命名空间通信的一种解决方案，还有其他方案，借图：最后，“路由”表可以通过ip route查看，这块内容我理解就是根据网络地址交给不同的设备做处理：$ip routedefault via 10.101.95.247 dev eth0 ...# 匹配前24bits的地址交由flannel.1设备处理10.244.0.0/24 via 10.244.0.0 dev flannel.1 onlink docker网络模型docker网络模型用于解决容器间及容器与宿主机间的网络通信，主要分为以下模型： Bridge，默认模式，也就是上面通过docker0做通信的模式 Host，容器内的网络配置同宿主机，没有网络隔离 None，容器内仅有loopback不同的模式通常在启动容器时，可以通过--net=xx参数指定。可以通过docker network inspect [host|bridge]查看本机某种网络模型下启动的容器列表，例如：$sudo docker network inspect host[ { \"Name\": \"host\", \"Id\": \"19958f2d93e0bf428c685c12b084fc5e6a7bd499627d90ae9ae1ca4b11a8f437\", \"Scope\": \"local\", \"Driver\": \"host\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [] }, \"Internal\": false, \"Containers\": { \"03d2b6e1faa3763fefd5528cce29ca454a13220dab693f242ff808051d7fd34b\": { \"Name\": \"k8s_POD_kube-proxy-69rl4_kube-system_b793f549-22a0-11e8-9ce1-00163e00039a_0\", \"EndpointID\": \"4380fab27d237e21f7fa6f84cf23b8a6d605f4e612968a3377f853abf987f6a4\", \"MacAddress\": \"\", \"IPv4Address\": \"\", \"IPv6Address\": \"\" }, \"9140fdf7a3ea0b19fec3a922e998ba3c544d328c1bd372525dfef816c620a431\": { \"Name\": \"k8s_POD_kube-flannel-ds-m88p6_kube-system_b793f466-22a0-11e8-9ce1-00163e00039a_0\", \"EndpointID\": \"01024d8050167cd88c11220375f89217116b5c929575a45695fe5d759038f320\", \"MacAddress\": \"\", \"IPv4Address\": \"\", \"IPv6Address\": \"\" } }, \"Options\": {}, \"Labels\": {} }]docker解决了单机容器网络隔离与网络通信，但没有解决多机间的通信。Kubernetes网络模型及Flannel实现kubernetes为了简单，它要求的网络模型里，整个集群中所有的POD都有独立唯一的IP。POD间互相看到的IP是稳定的，是直接可达的，是一个平铺网络。如何实现kubernetes的这个网络需求，CNI插件是一种解决方案，而Flannel项目则是CNI插件的一种实现。Flannel的实现，本质上主要是两方面内容： 一个proxy做流量转发，也就是flanneld进程，可以自行ps查看 通过中心化存储etcd来对整个集群做POD的IP分配借图，了解flannel网络原理：flannel网络上已经有很多资料，例如一篇文章带你了解Flannel。flannel的网络通信可以配置不同的backend，例如，配置UDP为backend时，那么交由flanneld进程转发网络包时，就会以UDP包的形式包装起来做转发，到达对端的flanneld进程时再解包。当然，实际使用时是不会使用这种方式的，通常会使用由内核支持的vxLan。参考flannel backend配置。在安装kubernetes时，基于kube-flannel.yml文件配置flannel就使用的vxLan：net-conf.json: |{ \"Network\": \"10.244.0.0/16\", \"Backend\": {\t\"Type\": \"vxlan\" }}docker在创建容器时，会给容器分配IP，flannel的安装里会hack docker daemon的启动方式，增加--bip参数，用于限定docker分配的IP范围，这也是网络上很多文章提到的。在我的环境里，docker容器全部以host方式设置网络，所以有没有设置bip也无所谓。安装了flannel后，在kubernetes网络中就可以直接ping一个POD容器。到这里，可以小结一下，基于以上的技术，在一个集群中，每一个POD都可以有一个独立唯一的IP，其他宿主机的POD可以直接访问这个POD。但是，一个分布式服务通常处于性能和稳定性考虑会有多个实例，所以kubernetes还要解决负载均衡问题。Kubernetes中的负载均衡kubernetes中通过service概念来对应用做多POD间的负载均衡。service是一个虚拟概念，service都会被分配一个clusterIP，其实就是service对外暴露的地址。你可以为一个redis服务暴露一个service，然后将这个service的clusterIP传给一个PHP应用，以让PHP应用访问redis。那么，这个PHP应用具体是如何通过这个service clusterIP负载均衡到redis的多个容器呢？在kubernetees中，目前主要是通过iptable来实现。借图：要理解上图，首先大概要有一个iptable的知识，大概就是在整个包收发处理过程中可以配置很多链，当一个链的条件被满足时，就可以执行一个动作。这里，我们主要关注上图中的左边分支部分。本质上，拿到一个service的clusterIP，到发送到目的POD，整个过程主要涉及到内容： service clusterIP是虚拟的，是一个iptable规则，这个规则最终会映射到一个POD的IP 一个应用有多少POD，那么在集群中的每台机器上，就会有多少iptable链在kubernetes集群中，可以实际追踪看看。例如上面提到的redis service clusterIP为10.99.136.250：$sudo iptables-save | grep 10.99.136.250# -d 10.99.136.250/32 地址完全匹配，然后执行 -j KUBE-SVC-AGR3D4D4FQNH4O33 规则-A KUBE-SERVICES -d 10.99.136.250/32 -p tcp -m comment --comment \"default/redis-slave: cluster IP\" -m tcp --dport 6379 -j KUBE-SVC-AGR3D4D4FQNH4O33# 这条规则对应到上图中`source!=podIP`，主要用于配合SNAT处理，简单理解为改写封包源IP-A KUBE-SERVICES ! -s 10.244.0.0/16 -d 10.99.136.250/32 -p tcp -m comment --comment \"default/redis-slave: cluster IP\" -m tcp --dport 6379 -j KUBE-MARK-MASQ追KUBE-SVC-AGR3D4D4FQNH4O33规则：$sudo iptables-save | grep KUBE-SVC-AGR3D4D4FQNH4O33:KUBE-SVC-AGR3D4D4FQNH4O33 - [0:0]-A KUBE-SVC-AGR3D4D4FQNH4O33 -m comment --comment \"default/redis-slave:\" -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-GDIX2RIKQIYS7RMI-A KUBE-SVC-AGR3D4D4FQNH4O33 -m comment --comment \"default/redis-slave:\" -j KUBE-SEP-J5QZN63T7ON4OKV7...因为redis-slave有2个POD，所以上面通过--probability 0.50实现了50%的流量负载均衡。KUBE-SEP-XX就是各个POD的地址，可以继续追，例如：$sudo iptables-save | grep KUBE-SEP-GDIX2RIKQIYS7RMI:KUBE-SEP-GDIX2RIKQIYS7RMI - [0:0]-A KUBE-SEP-GDIX2RIKQIYS7RMI -s 10.244.1.56/32 -m comment --comment \"default/redis-slave:\" -j KUBE-MARK-MASQ-A KUBE-SEP-GDIX2RIKQIYS7RMI -p tcp -m comment --comment \"default/redis-slave:\" -m tcp -j DNAT --to-destination 10.244.1.56:6379最终，封包发送到POD之一10.244.1.56。上面的过程，对着前面图的左半部分很容易理解。kubernetes中还提供了kube-dns，主要是为service clusterIP提供一个域名。每个service都可以按固定格式拼出一个域名，而kube-dns则负责解析这个域名，解析为service的clusterIP，实际网络数据传输流程还是同上。总结熟悉kubernetes，几大组件的工作原理其实不难理解。而kubernetes网络模型显得更难，尤其是要结合各种工具、命令去实践时，很容易与理论脱节。一旦梳理通彻整个链路，回头看时就会发现也就那么回事。当然，上面提到的各个技术点，深入下去了解还是有很多内容的。" }, { "title": "使用Kubeadm在CentOS部署Kubernets 1.8.7", "url": "/posts/deploy-kubernetes/", "categories": "弹性调度", "tags": "kubernetes", "date": "2018-03-08 00:00:00 +0800", "snippet": "主要参考： 官方文档 如何在国内愉快的安装 Kubernetes kubernetes 1.8.7 国内安装(kubeadm)建议都大致浏览下。这里我也是简单地记录，估计每个人遇到的细节问题不一样。环境准备我拿到手的环境docker已经ready： docker (alidocker-1.12.6.22) CentOS 7上面博客提到的一些系统设置可以先做掉：cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsysctl -p /etc/sysctl.d/k8s.conf其他一些设置： 防火墙最好关闭 swap最好关闭 setenforce 0 软件包及镜像 众所周知的局域网问题，官方的很多软件包和镜像无法获取。解决这个问题主要靠阿里云： 配置yum源，由于阿里云yum源相对官方有滞后，并且各个软件包版本匹配我没有找到，所以就按照上面博客提到的，安装1.8.7，避免版本问题：cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF可以把包下到本地以备不时之需：yum install -y --downloadonly --downloaddir=./ kubelet-1.8.7 kubeadm-1.8.7 kubectl-1.8.7 kubernetes-cni-0.5.1yum install -y *.rpm docker镜像问题后来我发现可以从阿里云直接拉，拉下来后通过打tag避免后续部署从google官方拉以下脚本内容未验证，主要注意镜像得提前拉全(上面链接的博客有写漏了)#!/bin/shimages=(kube-scheduler-amd64:v1.8.7 \\kube-proxy-amd64:v1.8.7 \\kube-apiserver-amd64:v1.8.7 \\etcd-amd64:3.0.17 \\pause-amd64:3.0 \\k8s-dns-sidecar-amd64:1.14.5 \\k8s-dns-kube-dns-amd64:1.14.5 \\k8s-dns-dnsmasq-nanny-amd64:1.14.5 \\kubernetes-dashboard-amd64:v1.8.1)for imageName in ${images[@]} ; do docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName gcr.io/google_containers/$imageName docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageNamedone# 注意这个镜像最好提前拉，看flannel的yaml描述里会用到docker pull quay.io/coreos/flannel:v0.9.1-amd64贴个我部署好后的镜像列表(自行忽略多余的)，方便对比：$sudo docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEregistry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64 v1.8.3 0c60bcf89900 3 weeks ago 102.3 MBgcr.io/google_containers/kubernetes-dashboard-amd64 v1.8.1 63c78846e37b 4 weeks ago 120.7 MBgcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64 1.14.5 6d7cc6e484b3 4 weeks ago 41.42 MBgcr.io/google_containers/k8s-dns-kube-dns-amd64 1.14.5 33072cb8c892 4 weeks ago 49.38 MBgcr.io/google_containers/k8s-dns-sidecar-amd64 1.14.5 e1414b167ca6 4 weeks ago 41.81 MBgcr.io/google_containers/pause-amd64 3.0 8ca66ae4813a 4 weeks ago 746.9 kBgcr.io/google_containers/etcd-amd64 3.0.17 10010bfa0a74 4 weeks ago 168.9 MBgcr.io/google_containers/kube-scheduler-amd64 v1.8.7 906029e1500b 4 weeks ago 55.13 MBgcr.io/google_containers/kube-apiserver-amd64 v1.8.7 c3bb648343de 4 weeks ago 194.7 MBgcr.io/google_containers/kube-proxy-amd64 v1.8.7 125dec6bd8f2 7 weeks ago 93.36 MBregistry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy-amd64 v1.8.7 125dec6bd8f2 7 weeks ago 93.36 MBgcr.io/google_containers/kube-controller-manager-amd64 v1.8.7 d8df883aabf9 7 weeks ago 129.6 MBregistry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager-amd64 v1.8.7 d8df883aabf9 7 weeks ago 129.6 MBquay.io/coreos/flannel v0.9.1-amd64 2b736d06ca4c 3 months ago 51.31 MB启动mastersystemctl enable kubeletsystemctl start kubelet注意，这里官方文档也提到了，需要确认docker的cgroup配置与kubelet的一致：docker info | grep -i cgroupcat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf不一致改成一致。例如：sed -i \"s/cgroup-driver=systemd/cgroup-driver=cgroupfs/g\" /etc/systemd/system/kubelet.service.d/10-kubeadm.conf配置有变更需要重启kubelet：systemctl daemon-reloadsystemctl restart kubeletsystemctl status kubelet查看日志会发现里面有warning/error级别的日志，所以出问题时很容易被误解。按照官方文档，在这一步时，kubelet会不断重启，所以这个时候可以继续，准备初始化master：#!/bin/bashkubeadm init --kubernetes-version=v1.8.7 --pod-network-cidr 10.244.0.0/16mkdir -p $HOME/.kubecp -i /etc/kubernetes/admin.conf $HOME/.kube/configchown $(id -u):$(id -g) $HOME/.kube/configkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.9.1/Documentation/kube-flannel.yml注意上面flannel的版本与前面的链接不同，v0.9.1测试可用。当flannel启动后，kubelet就会发现这个CNI实现，从而趋于成功运行状态。可以通过以下命令来确认master是否真的初始化成功：$sudo kubectl get nodeNAME STATUS ROLES AGE VERSIONv101083237zsqazzmf Ready master 12m v1.8.7$sudo kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system etcd-v101083237zsqazzmf 1/1 Running 0 11mkube-system kube-apiserver-v101083237zsqazzmf 1/1 Running 0 11mkube-system kube-controller-manager-v101083237zsqazzmf 1/1 Running 0 11mkube-system kube-dns-545bc4bfd4-f7hsx 3/3 Running 0 11mkube-system kube-flannel-ds-d6z78 1/1 Running 5 6mkube-system kube-proxy-z88cd 1/1 Running 0 11mkube-system kube-scheduler-v101083237zsqazzmf 1/1 Running 0 11m$sudo kubectl get csNAME STATUS MESSAGE ERRORcontroller-manager Healthy ok scheduler Healthy ok etcd-0 Healthy {\"health\": \"true\"} master初始成功会返回加入node的token，例如：kubeadm join --token 795c0c.c5a1b252c2d23a0c 10.101.83.237:6443 --discovery-token-ca-cert-hash sha256:1c7760c9f02e2f058de3f6bc759e85316b65376cfcc83d975ea6c64ac2175ecc注意token默认24小时过期。如果在这个过程中始终有问题，可以做reset回到干净状态：kubeadm reset部署node及加入 系统设置同上 前面提到的软件需要安装 镜像只需要部分 运行kubelet的cgroup设置参考前面images=(kube-proxy-amd64:v1.8.7 \\pause-amd64:3.0 \\kubernetes-dashboard-amd64:1.8.1)images=(kube-proxy-amd64:v1.8.7)for imageName in ${images[@]} ; do docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName gcr.io/google_containers/$imageName docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageNamedone贴下镜像列表：$sudo docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEregistry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64 v1.8.3 0c60bcf89900 3 weeks ago 102.3 MBgcr.io/google_containers/kube-proxy-amd64 v1.8.7 263b722c47c1 4 weeks ago 93.36 MBgcr.io/google_containers/pause-amd64 3.0 8ca66ae4813a 4 weeks ago 746.9 kBgcr.io/google_containers/kubernetes-dashboard-amd64 1.8.1 758ae6af38ca 5 weeks ago 120.7 MBquay.io/coreos/flannel v0.9.1-amd64 2b736d06ca4c 3 months ago 51.31 MB最后使用kubeadm join xxxx (部署master时会返回)加入网络。加入后在master端可以确认：$sudo kubectl get nodesNAME STATUS ROLES AGE VERSIONv101083225zsqazzmf Ready &lt;none&gt; 2h v1.8.7v101083237zsqazzmf Ready master 3h v1.8.7部署dashboard高版本的dashboard出于安全考虑，访问方式发生了变更，需要处理鉴权相关的问题。验证token的方式测试不成功，使用HTTP协议的方式也不成功。最后成功的方式如下：# commit 9159b005f65b21bd6b7156ccabd92f9e50c11333kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml注意 替换里面的镜像地址，可以直接在阿里云找对应镜像。参考stackoverflow 最后一种方法：$ cat &lt;&lt;EOF | kubectl create -f -apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard labels: k8s-app: kubernetes-dashboardroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard namespace: kube-systemEOF最后启动proxy，默认端口8001：# 不加disable-filter浏览器端无法访问kubectl proxy --address `hostname -i` --disable-filter=true浏览器端即可访问：http://10.101.83.237:8001/ui 会重定向到新的URI。测试可以参考官方的例子stateless application sample 进行测试。这一步很顺利没有什么问题。同样，注意配置中镜像地址的修改。" }, { "title": "基于Yarn的分布式应用调度器Slider", "url": "/posts/apache-slider/", "categories": "弹性调度", "tags": "slider", "date": "2018-01-24 00:00:00 +0800", "snippet": "Apache Hadoop Map-Reduce框架为了解决规模增长问题，发展出了yarn。而yarn不仅解决Map-Reduce调度问题，还成为了一个通用的分布式应用调度服务。yarn中的一个创新是把各种不同应用的调度逻辑拆分到了一个称为ApplicationManager(以下简称AM)的角色中，从而让yarn自己变得更通用，同时解决调度性能问题。ApacheSlider就是这其中的一个AM具体实现。但Slider进一步做了通用化，可以用于调度长运行(long-running)的分布式应用。为了更好地理解Slider/Yarn，需要思考这样一个问题：在不用Slider/Yarn这种自动部署并管理应用的软件时，我们如何在一个网络环境中部署一个分布式应用？ 可能需要在目标物理机上创建虚拟容器，指定容器所用的CPU核数、内存数 到容器中下载或复制应用运行所需的所有软件包 可能需要改写应用所需的各种配置 运行应用，输入可能很长的命令行参数注意这些操作需要在所有需要运行的容器中执行，当然现在也有很多自动部署的工具可以解决这些问题。但是，当应用首次部署运行起来后，继续思考以下问题： 某台机器物理原因关机，对应的应用实例不可服务，如何自动发现故障并迁移该实例 应用有突发流量，需要基于当前运行中的版本做扩容 应用需要更新架构看一下yarn的总体架构：yarn管理的每台机器上都会部署Node Manager (简称NM)，NM主要用于创建容器，用户的应用运行在这个容器中。一台机器可能会跑多个应用的实例(Instance)。Resource Manager(简称RM)用于管理整个集群的资源，例如CPU、内存。App Master(Manager) (简称AM) 用于管理容器中用户的应用。AM本身也运行在容器中。通过Client提交AM的请求到RM中，RM找到一个可用的NM并启动该AM。随后，AM与RM交互，为应用请求各种资源，并发出应用的部署请求。在运行期间，AM会监视应用每个实例的正确性，以在假设有机器挂掉后，申请新的资源来自动恢复该实例。为了更具体地了解这个过程，可以先参考Writing YARN Applications。Slider是AM的一种实现，接下来从以下几个方面来了解Slider： Slider架构 如何描述一个应用 使用流程及主要接口 如何定制 其他细节Slider架构借图(Slider设计理念与基本架构)：作为一个Yarn AM其结构与之前描述的相差无几。Slider Client是一个命令行程序，它直接与RM交互，提交一个Slider AM包给RM。RM分配资源并配合NM启动Slider AM这个服务程序。Slider AM在启动目标应用时，通常会在目标容器中部署一个SliderAgent。这个Agent实现了一套与不同应用之间的交互协议，例如：INSTALL/CONFIGURE/START/STOP/STATUS，应用一般通过Python脚本实现这些协议命令，就可以被Slider部署起来。如何描述一个应用完整地描述一个应用，就可以让第三方调度器，例如Slider，自动地部署应用、迁移应用。在Slider中描述一个应用，主要分为3部分内容： 资源描述，resources.json，例如单实例所需要的CPU核数、内存数，总共需要多少实例 应用特定的配置描述，appConfig.json，例如Java应用JVM的内存配置 应用适配协议，这个不是配置文件，一般是Python脚本，实现一个应用实例如何安装、如何启动除了以上内容外，Slider认为一个完整的分布式应用可能包含多个组件(Component)，例如HBase包含Master、Worker。应用描述还应该包含各个组件的描述，例如每个组件可以有自己的资源需求。Component也被称为Role(可能不准确，但意思接近)。当有多个Component时，可以配置每个Component的优先级，高优先级的Component优先得到资源分配。例如，一个resource.json例子，主要就是指定各个Component的资源：{ \"schema\": \"http://example.org/specification/v2.0.0\", \"metadata\": { \"description\": \"example of a resources file\" }, \"global\": { \"yarn.vcores\": \"1\", \"yarn.memory\": \"512\" }, \"components\": { \"master\": { \"instances\": \"1\", \"yarn.vcores\": \"1\", \"yarn.memory\": \"1024\" }, \"worker\": { \"instances\":\"5\", \"yarn.vcores\": \"1\", \"yarn.memory\": \"512\" } }}appConfig.json主要就是应用相关的配置参数：{ \"schema\": \"http://example.org/specification/v2.0.0\", \"global\": { \"zookeeper.port\": \"2181\", \"zookeeper.path\": \"/yarnapps_small_cluster\", \"zookeeper.hosts\": \"zoo1,zoo2,zoo3\", }, \"components\": { \"worker\": { \"jvm.heapsize\": \"512M\" }, \"master\": { \"jvm.heapsize\": \"512M\" } } \"credentials\" { }}在Slider中，应用需要将这些配置信息以及应用自己部署所需要的各种软件包，按照规范打成一个压缩包。然后使用slider工具提交，slider工具会将包上传至HDFS上。可以通过Hello World Slider App获得直观的印象。使用流程及主要接口使用Slider主要就是使用其客户端工具slider。要通过Slider启动一个应用，主要步骤如下： 准备好应用包，配置资源描述resources.json、应用配置appConfig.json、开发适配协议脚本。 打包并上传，通过slider install-package完成 提交并部署，通过slider create完成其中，应用的部署和AM自身的部署是一起提交的。在应用部署好后，后续的运维操作都可以通过slider工具完成，例如： 对应用做扩缩容: ./slider flex cl1 --component worker 5 对应用做更新：slider upgrade MyHBase_Facebook_Finance --components HBASE_MASTER HBASE_REGIONSERVER对应用做更新时，Slider文档中指出不可以同时做扩缩容。另外，如果更新过程中有部分容器坏掉自动替换，可能会自动更新为新版本。在更新过程中，Slider并不做更新过程的维护，即用户需要自己指定当前希望哪些容器得到更新（或全部更新），用户通过slider工具检查这些容器的版本是否达到预期，并继续更新下一批容器。过程大体如下：# 上传更新包slider package --install --name MyHBase_Facebook --version 2.0 --package ~/slider-hbase-app-package_v2.0.zip# upgrades the internal state slider upgrade MyHBase_Facebook_Finance --template ~/myHBase_appConfig_v2.0.json --resources ~/myHBase_resources_v2.0.json# 重复以下步骤，根据应用的需求更新各个容器slider upgrade MyHBase_Facebook_Finance --containers id1 id2 .. idn如果应用有多个Component，Component之间的更新一般是有顺序的，这里Slider交给用户自己去控制。用户也可以控制容器之间的更新间隔。更新过程的细节参考Rolling Upgrade。如何定制Slider中有一个概念叫Provider。provider可以理解为为了支持特定应用类型而开发的插件，以让Slider部署这些特殊的应用。默认的provider就是前面提到的slider agent。这个agent是一堆Python脚本，定义了与应用交互的各种协议。实现自己的provider，需要实现client端和server端。client端会被slider client (前面提到的slider工具)调用，可以用于添加应用所需要的特殊包，以提交为Slider AM。而server端主要指的是Slider AM端，可以定制具体部署应用时的行为，例如部署自己定制的agent。具体provider例子可以参考源码中slider-providers子项目。其他细节以下细节仅供记录，未深入了解。服务发现服务发现用于解决分布式系统中上游服务如何发现下游服务实例，以发出RPC调用。Slider中依靠Yarn的服务发现机制，目前主要是通过zookeeper来自动对服务做注册。参考The Yarn Service Registry。资源分配策略Slider在请求yarn分配容器时，可以配置不同的策略，这个称为Placement Policy。例如是否优先跑在打有特殊标签的机器上，或者跑在特定的机架(rack)上。这里的资源标签就是一些普通的文本，例如给一个机器打上gpu标签，而分配容器时，也只是简单的匹配，并没有看到互斥、多标签组合等功能。分配策略可以解决带数据应用的机器亲近性，当应用实例发生迁移时，优先在有历史数据的机器上部署，可以获得更快的启动速度。具体参考Apache Slider Placement。总结翻看了Slider的文档及部分源码，主要功能了解得七七八八。Slider虽然可以自动调度起一个应用，但是一个用于生产环境的调度器还要在很多细节上做得出色，例如： 需要与服务发现深度结合。应用实例在服务发现中的状态能够参与到调度器的调度中，例如是否能做到对上游应用透明地更新 应用实例与agent交互时，STATUS需要表达应用确实可提供服务，并且在运行期间持续透出可服务状态 调度整个集群时，是否能对失败节点做容错，是否会自动recover这些失败节点，也就是我们说的基于目标式的调度实现(level-triggered) 应用的更新是日常运维的常态，更新语义应该基于百分比，而不是基于容器；更新既然是常态，调度器就该处理好在这期间集群里可能发生的任何事情，例如有容器被自动替换" }, { "title": "Python协程greenlet实现原理", "url": "/posts/greenlet/", "categories": "python", "tags": "greenlet", "date": "2018-01-17 00:00:00 +0800", "snippet": "greenlet是stacklessPython中剥离出来的一个项目，可以作为官方CPython的一个扩展来使用，从而支持Python协程。gevent正是基于greenlet实现。协程实现原理实现协程主要是在协程切换时，将协程当前的执行上下文保存到协程关联的context中。在c/c++这种native程序中实现协程，需要将栈内容和CPU各个寄存器的内容保存起来。在Python这种VM中则有些不同。例如，在以下基于greenlet协程的python程序中：def foo(): bar()def bar(): a = 3 + 1 gr2.switch()def func(): passgr1 = greenlet(foo)gr2 = greenlet(func)gr1.switch()在bar中gr2.switch切换到gr2时，协程库需要保存gr1协程的执行上下文。这个上下文包括: Python VM的stack Python VM中解释执行的上下文理解以上两点非常重要，至于为什么呢？想象一下如何去实现一个PythonVM，去解释执行一段Python代码。其实这在任何基于VM的语言中，原理都是一样的（native程序可以把x86物理CPU也视作特殊的VM)。可以参考Python解释器简介-深入主循环。主要包含两方面内容： VM在执行代码时，其自身调用栈通常都是递归的 VM在执行代码时，通常会创建相应的数据结构来表示代码执行块，例如通常会有个struct Frame来表示一个函数在VM的实现中通常会有类似以下的代码:struct Frame { unsigned char *codes; // 存放代码指令 size_t pc; // 当前执行的指令位置 int *stack; // stack-based的VM会有一个栈用于存放指令操作数};void op_call(frame) { switch (OP_CODE()) { case OP_CALL: child_frame = new_frame() op_call(child_frame) ... case OP_ADD: op_add(...) }}对应到前面的Python例子代码，在某一时刻VM的call stack可能是这样的：op_addop_callop_call理解了以上内容后，就可以推测出greenlet本质上也是做了以上两件事。greenlet实现原理greenlet库中每一个协程称为一个greenlet。greenlet都有一个栈空间，如下图：图中未表达出来的，greenlet的栈空间地址可能是重叠的。对于活跃的（当前正在运行）的greenlet，其栈内容必然在c程序栈顶。而不活跃的被切走的greenlet，其栈内容会被copy到新分配的堆内存中。greenlet的栈空间是动态的，其起始地址是固定的，但栈顶地址不固定。以下代码展示一个greenlet的栈空间如何确定：579 if (!PyGreenlet_STARTED(target)) { // greenlet未启动，是一个需要新创建的greenlet580 void* dummymarker; // 该局部变量的地址成为新的greenlet的栈底581 ts_target = target;582 err = g_initialstub(&amp;dummymarker); // 创建该greenlet并运行以上greenlet-&gt;stack_stop确定了栈底，而栈顶则是动态的，在切换到其他greenlet前，对当前greenlet进行上下文的保存时，获取当前的RSP（程序实际运行的栈顶地址）：410 static int GREENLET_NOINLINE(slp_save_state)(char* stackref)411 {412 /* must free all the C stack up to target_stop */413 char* target_stop = ts_target-&gt;stack_stop;414 PyGreenlet* owner = ts_current;415 assert(owner-&gt;stack_saved == 0);416 if (owner-&gt;stack_start == NULL)417 owner = owner-&gt;stack_prev; /* not saved if dying */418 else419 owner-&gt;stack_start = stackref; // stack_start指向栈顶stackref是通过汇编获取当前RSP寄存器的值： __asm__ (\"movl %%esp, %0\" : \"=g\" (stackref));保存栈内容到堆内存参看g_save的实现，没什么特别的。除了保存栈内容外，如上一节讲的，还需要保存VM执行函数所对应的Frame对象，这个在g_switchstack中体现：460 PyThreadState* tstate = PyThreadState_GET(); // 获取当前线程的VM执行上下文461 current-&gt;recursion_depth = tstate-&gt;recursion_depth;462 current-&gt;top_frame = tstate-&gt;frame; // 保存当前正在执行的frame到当前正在执行的greenlet ...473 slp_switch(); // 做栈切换 ...487 PyThreadState* tstate = PyThreadState_GET();488 tstate-&gt;recursion_depth = target-&gt;recursion_depth;489 tstate-&gt;frame = target-&gt;top_frame; // 切换回来上面的代码展示VM frame的切换。接下来看下最复杂的部分，当切换到目标greenlet时，如何恢复目标greenlet的执行上下文，这里主要就是恢复目标greenlet的栈空间。假设有如下greenlet应用代码：def test1(): gr2.switch()def test2(): print('test2')gr1 = greenlet(test1)gr2 = greenlet(test2)gr1.switch()在gr1中切换到gr2时，也就是gr2.switch，会发生什么事情。// g_switch 实现574 if (PyGreenlet_ACTIVE(target)) {575 ts_target = target; // 找到目标greenlet，也就是gr2576 err = g_switchstack(); // 开始切换// g_switchstack 实现462 current-&gt;top_frame = tstate-&gt;frame; ...473 err = slp_switch();// slp_switch 实现，根据不同平台实现方式不同，原理相同69 SLP_SAVE_STATE(stackref, stsizediff);// 这个很重要，强行将当前的栈指针ESP/EBP (32位OS)通过加上一个与目标greenlet栈地址的偏移，而回到了// 目标greenlet的栈空间。可以在下文看到stsizediff的获取实现70 __asm__ volatile (71 \"addl %0, %%esp\\n\"72 \"addl %0, %%ebp\\n\"73 :74 : \"r\" (stsizediff)75 );76 SLP_RESTORE_STATE();// SLP_SAVE_STATE 实现316 #define SLP_SAVE_STATE(stackref, stsizediff) \\317 stackref += STACK_MAGIC; \\318 if (slp_save_state((char*)stackref)) return -1; \\319 if (!PyGreenlet_ACTIVE(ts_target)) return 1; \\// 获取目标greenlet的栈空间与当前栈地址的偏移，用于稍后设置当前栈地址回目标greenlet的栈地址320 stsizediff = ts_target-&gt;stack_start - (char*)stackref // slp_save_state 没啥看的，前面也提过了，主要就是复制当前greenlet栈内容到堆内存// SLP_RESTORE_STATE 也没什么看的，主要就是把greenlet堆内存复制回栈空间以上，首先将ESP/EBP的值改回目标greenlet当初切换走时的ESP/EBP值，然后再把greenlet的栈空间内存（存放于堆内存中）全部复制回来，就实现了greenlet栈的回切。尤其注意的是，这个栈中是保存了各种函数的return地址的，所以当slp_switch返回时，就完全恢复到了目标greenlet当初被切走时栈上的内容，包括各种函数调用栈。而当前greenlet的栈，则停留在了类似以下的函数调用栈：g_switchstackg_switch...参考 Stackless Python 探秘 python协程的实现（greenlet源码分析) 深度分析gevent运行流程" }, { "title": "写了一个棋牌游戏服务器框架", "url": "/posts/chess-gameserver/", "categories": "game develop", "tags": "skynet, pigy", "date": "2017-12-12 00:00:00 +0800", "snippet": "最近业余时间写了一个棋牌游戏服务端框架：pigy。对于棋牌游戏服务端框架，我的定义是： 分布式的 包含网络棋牌游戏中包括登陆、大厅、游戏框架、数据持久化等基础组件 提供具体游戏框架，游戏逻辑程序员可以基于这个框架focus在游戏的开发上写得差不多的时候，我在网上搜索了下，发现棋牌游戏源码已经烂大街，自己精力有限，也没有心思和动力去研究现有实现的优缺点而做出一个更好的替代。所以我这份实现仅作为一个demo放出来让大家开心下好了。pigy基于skynet实现。之所以选择skynet是看中其中已经有不少网络游戏基础组件可以使用，结合开发下来稍微花点业余时间就可以完成雏形。除此之外，部分源码也参考/复制了metoo项目。架构服务器主要有3类角色： Login，登陆/账号服务器，负责玩家账号相关 Hall，大厅服务器，职责包括： 获取玩家信息及公告推送等独立于具体游戏的逻辑 房间相关管理，分配玩家到游戏服务器 Game，游戏服务器，包装具体的游戏，提供游戏运行框架我希望除了Game之外，Login和Hall都具备高可用性，例如可水平扩展，在挂掉后对玩家无影响。要做到这一点就要对服务器的状态数据做较好的管理，以实现挂掉后要么玩家被自动迁移到其他服务，要么挂掉的服务重启后可以快速恢复之前的数据。对于Login/Hall而言最主要的状态数据就是玩家的登陆数据，由于数据简单，可以选择直接持久化到redis并且不需要落盘。redis就可以作为单点，保存全服的数据。这样，Login/Hall还可以水平扩展，动态根据实例数分摊全服玩家数据。但是我只是实现了一个阉割版。我暂时不希望太过依赖redis，所以我让Login/Hall互相作为数据备份。Login和Hall本身就持有玩家的登陆数据，可以在对方挂掉重启后，自动恢复数据。为了恢复数据时简单可靠，我让Login作为单点存在。毕竟，Login并不与Client保持长连接，也没有除了登陆外其他更复杂的逻辑，加上skynet多线程的特性，性能上单点就足够支撑。Hall是支持水平扩展的。Login可以按玩家uid一致性哈希地选择一个Hall，其实按普通取模哈希也没有什么问题。1个Hall实例挂掉后，Client启动重连定时器，预期能在短时间内重新启动完成这个挂掉的Hall。Game (server)肯定是支持水平扩展的。我在Game中抽象了Gamelet概念，本质上就是一个具体的游戏。Gamelet可以部署到任意一个Game内，Game单实例可以跑多个Gamelet。Hall会定期查询所有Game的Gamelet实时情况。Gamelet的实时情况主要包括某具体游戏关联的所有房间信息。Hall聚合这些信息，主要确定两方面信息： 哪些Game加载了哪些Gamelet，主要用于在Hall上创建房间 某具体的Game有哪些房间，一般用于Client展示游戏房间信息各个Server角色之间通信全部依靠skynet Cluster机制，节省了不少工作。账号处理Login最开始是完全基于skynet Login Server实现。但是涉及到账号相关的功能还包括： 游客账号及自有注册账号 账号绑定所以扩展了LoginServer，在原有协议上增加了扩展命令，搞得类似HTTP协议的URI。消息及RPC除了Login使用文本协议外，Hall/Game都使用基于skynet Gate Server的长度+消息体的格式，而消息体又使用protobuf格式。为了支持消息的派发，将消息值映射到skynet service method上，类似于简单的RPC：消息code值 -&gt; 消息code到service.method字符串映射 -&gt; 找到对应的service，调用其method这里也可以使用云风提供的sproto。本质上都是解决消息格式编码及消息dispatch问题。断线重连断线重连主要牵涉到几个问题： 玩家的状态数据不能依赖socket的状态 server间对于玩家数据一般有鉴权处理，Client断线重连时可以直接携带token直连某个server，而不用走重新登陆逻辑 server对client数据做重连补发其中，重连补发根据实现又分为两种情况： 基于断线协议，在server框架层，或者整个游戏服务器组的统一接入层自动解决。例如goscon 在应用层解决，一般就是游戏内根据具体游戏重发全量游戏数据到Client在pigy中，我认为更简单可靠的做法是在应用层解决。当然，一些前提还是得实现的。例如玩家在线状态不基于socket、server间传递token以支持Client直连server。数据持久化及缓存持久化及缓存是基于三层结构：本地内存、redis缓存、mysql。mysql作为关系型数据库，其表里的每一行记录，都会映射为redis中的一个哈希表。哈希表自身由db table name 及该行关键值确定，id可以作为关键值。而为了获取该数据库表里所有行，又将所有行的index字段(配置)作为redis一个有序集合关联起来。这样，通过获取redis有序集合所有元素，就可以获取该数据库表所有行记录。例如，有玩家表：id | name | age |---|------|-----|1 | kev | 18 |---|------|-----|2 | john | 20 |映射到redis中，就会得到2个哈希表，对应2行；另外得到一个有序集合，根据配置，集合中存储了所有id字段值。然后，基于以上结构，可以配置有些数据库表，是需要在启动时全部载入内存，而有些数据，例如玩家数据，由于数据会很多，并且很多数据并不需要，所以就只载入一部分。整个游戏的数据会根据玩家uid进行分区(partition)，redis可以以独立集群的模式启动多个集群，然后玩家数据根据uid分区存储到这些redis中。游戏框架网络棋牌游戏中有很多子游戏，所以游戏框架是肯定需要的。游戏框架主要用来抽象/隔离各种底层细节，包括网络数据发送、同房间玩家数据获取、数据持久化等等。设计上主要就是包装，但是目前的实现还不完整。pigy将子游戏抽象为gamelet，类似于servlet。这个抽象本质上就是与框架交互协议的包装，以及框架对一些数据的接口化透出。例如：function init(source) -- 将房间service传入 room = sourceendfunction accept.enter(user) -- 某个玩家进入该房间endpigy中某个Game (server)是可以载入多个gamelet的。所以在Hall端会聚合出来某个游戏(gamelet)在哪些Game上部署，以在其上创建房间。网关网关服务器主要用于隔离内部服务器与外网，避免受到恶意攻击。在早期我并不想花精力去重写一个Gate (server)，同时我希望Gate的加入应该尽可能少地对其他服务造成侵入。所以这造成了一种困境，因为在Game上的通信不太方便实现为Req/Resp的模式，所以现成的类似nginx TCP的网关也用不上，自己写优先级也不高，所以直到目前我也没有花时间去实现一个出来。如何运行准备好skynet，然后参考doc/guide.md。总结网络游戏服务器毕竟是分布式系统，在框架层面，稳定性及可扩展性是比较有趣的问题。在移动网络游戏方面，断线重连又是无法逃避的问题。这些问题要做得完美还是很不容易。" }, { "title": "协程并发模型及使用感受", "url": "/posts/coroutine/", "categories": "other", "tags": "gevent", "date": "2017-12-03 00:00:00 +0800", "snippet": "协程可以简单理解为更轻量的线程，但有很多显著的不同： 不是OS级别的调度单元，通常是编程语言或库实现 可能需要应用层自己切换 由于切换点是可控制的，所以对于CPU资源是非抢占式的 通常用于有大量阻塞操作的应用，例如大量IO协程与actor模式的实现有一定关系。由于协程本身是应用级的并发调度单元，所以理论上可以大量创建。在协程之上做队列及通信包装，即可得到一个actor框架，例如python-actor最近1年做了一个python项目。这个项目中利用gevent wsgi对外提供HTTP API，使用gevent greelet来支撑上层应用的开发。当可以使用协程后，编程模型会得到一定简化，例如相对于传统线程池+队列的并发实现，协程可以抛弃这个模型，直接一个协程对应于一个并发任务，例如网络服务中一个协程对应一个socket fd。但是python毕竟是单核的，这个项目内部虽然有大量IO请求，但随着业务增长，CPU很快就到达了瓶颈。后来改造为多进程结构，将业务单元分散到各个worker进程上。python gevent中的协议切换是自动的，在遇到阻塞操作后gevent会自动挂起当前协程，并切换到其他需要激活的协程。阻塞操作完成，对应的协程就会处于待激活状态。在这个项目过程中，我发现协程也存在很多陷阱。协程的陷阱 死循环普通的死循环很难遇到，间接的死循环一旦发生，就会一直占用CPU资源，导致其他协程被饿死。 留意非协程化的阻塞接口gevent中通常会将python内置的各种阻塞操作green化，也就是我这里说的协程化，例如socket IO接口、time.sleep、各种锁等待。如果在系统中引入一个不能被协程化的库，例如MySQL-python。当协程被阻塞在这种库的接口时，协程不能被切走，而是等到python内线程的抢占式切换，实际上对于gevent的协程调度其总计可用的CPU就不是100%了。在压力较大的情况下，协程就可能出现延迟调度。意思是在协程阻塞操作完成后，在负载较小的情况下，该协程会立即得到切换。这里有一个小技巧，可以写一个time.sleep延时的协程，检查真实的延时情况和time.sleep的延时参数相差多少，就可以衡量整个系统中协程切换的延时情况。 注意不同角色协程的CPU资源分配这个问题本质上类似于在基于线程的应用中，需要为不同角色的线程设定不同的优先级。在多核程序中由于总的CPU资源比较多，所以一般也不会遇到需要分配不同优先级的情况。但在基于协程的单核程序中，由于单核CPU资源很快就会被压榨到80-90%，所以就需要关注不同角色协程的优先级。例如，系统中有用于服务HTTP API的协程集，有用于做耗时任务的协程集。耗时任务正常情况下可能需要分钟级，所以做任务的协程就算慢几秒也没什么关系。但是对外提供API的协程，本身API时延就在毫秒到秒级，如果晚几秒到几十秒，对上游系统或者用于就会造成不良的影响，表现为服务质量差。但是通常协程库是没有设定优先级的功能的。所以这个时候就要从应用层解决。例如前面的耗时任务例子，一般情况下，为了编程简单，我们会为每一个任务分配一个协程去做。由于所有协程优先级相同，大家被切换的机会是均等的，那么当任务增多后，API相关的协程获得的切换机会更少，影响服务质量。所以这个时候，就会创建一个用于完成耗时任务的协程池，以限制耗时任务占用的总协程数量。这就又回到了基于线程的并发模型中。 留意协程切换在gevent这种协程切换不需要程序员显示操作的协程库中，程序员会慢慢忘掉自己是在协程环境下编程。前面的例子中，我们创建了一个协程池去限制耗时任务可用的协程数量。在实际项目中可能会对调度做一些包装，让应用层只关注自己的业务代码。那么，在业务代码中，对于一些需要重试的失败操作，我sleep一段较长的时间也很合情理吧。这个时候如果由于外部依赖服务异常，而导致部分业务协程失败，处于sleep中。这个时候，协程池内有限的协程都被挂起了。导致很多本来可以获得CPU资源的任务无法得到消费，导致整个系统的吞吐量下降。总结协程会在低CPU系统中获得不少易于编程的好处，但是当系统总CPU上去后就需要付出等价于甚至大于多线程编程中的代价。" }, { "title": "实现一个memcache proxy", "url": "/posts/memcache-proxy/", "categories": "java", "tags": "memcache", "date": "2017-05-18 00:00:00 +0800", "snippet": "通常我们会使用多台memcached构成一个集群，通过客户端库来实现缓存数据的分片(replica)。这会带来2个主要问题： memcached机器连接数过多 不利于做整体的服务化；缺少可运维性。例如想对接入的客户端做应用级隔离；或者对缓存数据做多区域(机房)的冗余实现一个memcache proxy，相对于减少连接数来说，主要可以提供更多的扩展性。目前已经存在一些不错的memcache proxy，例如twitter的twemproxy，facebook的mcrouter。稍微调研了下，发现twemproxy虽然轻量，但功能较弱；mcrouter功能齐全，类似多区域多写的需求也满足。处于好玩的目的，之前又读过网络库xnio源码，我还是决定自己实现一个。这个项目简单取名为kvproxy，通过简单的抽象可以实现为memcache或redis等key-value形式的服务proxy。 这是一些预想中的feature。在目前的阶段，主要关注于其性能。因为memcached本身的RT非常小，所以这个proxy的性能就要求比较高。这里主要先关注下核心功能的实现。架构如下图： Service，用于抽象key-value服务，如memcache；MemcacheService是其实现之一 ServerLocator，用于定位memcached机器列表，例如ConstantLocator则是从配置文件中读取。可以实现一个从名字服务读取列表的locator。 Connection，配合KVProxy，基于xnio，表示一个与客户端的连接 ConnectionListener，用于处理网络连接上的请求，例如RequestHandler则是MemcaheService中的listener，用于处理从客户端发过来的memcache协议请求 MemClient，包装memcache客户端，用于proxy将请求转发到后端的memcache服务 GroupClient，包装MemClient，可以用于多区域数据的同时写入，目前实现为单个primary及多个slave。写数据同步写入primary异步写入slave；读取数据则只从primary读。本身要抽象的东西不复杂，所以结构其实是很简单的，也没有花太多心思。接下来关注下性能方面的问题。异步性作为一个proxy，异步基本是必然选择的方案，指的是，proxy在收到memcache的请求时，不阻塞当前的IO线程，形成一个请求context，在收到回应时拿到这个context来回应客户端。这样通过增加消耗的内存，来释放CPU资源，可以让IO模块尽可能多地接收从客户端来的请求。当然，如果请求过多，可能就会耗尽内存。为了简单，我没有自己实现memcache client。网络上有很多开源的memcache client。我试了几个，例如xmemcached(为此还读过它的源码)，但由于这些客户端都是同步的，虽然可以自己起线程池来把同步包装为异步，但始终不是最优方案。最后无意发现了folsom，集成到kvproxy后性能表现还不错。当然，真正要做到性能最优，最好还是自己实现memcache client，这样可以使用同一个xnio reactor，不用开那么多IO线程，拿到数据后就可以直接得到ByteBuffer，应该可以减少内存拷贝操作(能提高多少也不确定)。性能测试我使用了memtier_benchmark来做压力测试。测试环境是16core的虚拟机(宿主机不同)，benchmark工具同目标测试服务部署在不同的机器，proxy同memcache部署在相同机器。目标服务基于OS centos7，测试命令为：./memtier_benchmark -s 127.0.0.1 -p 22122 -P memcache_text --test-time 60 -d 4096 --hide-histogram默认开启4个压测线程，每个线程建立50个连接，测试60秒，默认设置是1:10的set/get。首先是直接压测memcached：ALL STATS========================================================================Type Ops/sec Hits/sec Misses/sec Latency KB/sec------------------------------------------------------------------------Sets 5729.65 --- --- 3.27500 23141.85Gets 57279.42 80.33 57199.09 3.16000 1771.99Waits 0.00 --- --- 0.00000 ---Totals 63009.07 80.33 57199.09 3.17000 24913.84然后我压测了twitter的twemproxy，RT差不多增加70%。ALL STATS========================================================================Type Ops/sec Hits/sec Misses/sec Latency KB/sec------------------------------------------------------------------------Sets 3344.58 --- --- 5.58400 13508.68Gets 33430.28 40.00 33390.28 5.41900 1006.32Waits 0.00 --- --- 0.00000 ---Totals 36774.85 40.00 33390.28 5.43400 14515.00最后是压测kvproxy (jdk8)，只与memcache建立一个连接，RT增加95%，基本上翻倍。不过由于是Java实现，相对于twemproxy的C实现感觉也不差。当然，机器资源消耗更大(主要是内存)。ALL STATS========================================================================Type Ops/sec Hits/sec Misses/sec Latency KB/sec------------------------------------------------------------------------Sets 2959.41 --- --- 6.62400 11953.00Gets 29578.47 33.90 29544.57 6.20800 884.38Waits 0.00 --- --- 0.00000 ---Totals 32537.88 33.90 29544.57 6.24600 12837.37压测中IO线程CPU并没有跑满，推测是虚拟机之间的网络带宽还是不够。" }, { "title": "Xmemcached源码阅读", "url": "/posts/xmemcached/", "categories": "java", "tags": "xmemcached", "date": "2017-04-23 00:00:00 +0800", "snippet": "Xmemcached 是一个memcached客户端库。由于它提供的是同步API，而我想看下如何增加异步接口。所以就大致浏览了下它的源码。主要结构针对memcache客户端的实现，主要结构如下： XMemcachedClient 是应用主要使用的类，所有针对memcache的接口都在这里 Command 用于抽象二进制协议或文本协议下各个操作，这里称为Command。CommandFactory 用于创建这些command MemcachedSessionLocator 用于抽象不同的负载均衡策略，或者说数据分布策略。在一个memcached集群中，数据具体存放在哪个replica中，主要就是由这个类的实现具体的，例如KetamaMemcachedSessionLocator 实现了一致性哈希策略 MemcachedConnector 包装了网络部分，与每一个memcached建立连接后，就得到一个Session。command的发送都在MemcachedConnector中实现 各个Session类/接口，则涉及到Xmemcached使用的网络库yanf4j。这个库也是Xmemcached作者的。Command 类的实现中有个关键的CountDownLatch。在将Command通过session发送出去之后，就利用这个latch同步等待，等到网络模块收到数据后回调。Command会和session绑定，在这个session上收到数据后，就认为是这个command的回应。由于本身memcached库核心东西比较少，上面的结构也就很好理解。协议的抽象和数据分布策略的抽象是必须的。接下来看看网络实现部分。网络实现Xmemcached的网络实现主要结构如下： SocketChannelController，主要的类，将IO事件通知转交给session NioController，主要关注其成员SelectorManagrer SelectorManager 内置若干个Reactor，数量由CPU核数决定 Reactor，IO事件的产生器，一个Reactor对应一个线程，线程循环中不断轮询NIO selector是否产生了IO事件 CodecFactory，编解码网络消息接口 PoolDispatcher ，Dispatcher 用于调度一个IO事件的具体处理过程，而PoolDispatcher则是放到一个单独的线程池中处理 DispatcherFactory ，用于创建具体的dispatcher这个网络实现还是比较典型的Reactor模式。其中，产生IO事件后，IO事件的具体处理，默认交给了一个独立的线程池。一般网络库都会提供类似的机制，以使得IO线程不至于被业务逻辑阻塞住，导致IO处理效率下降。写数据时，数据都会写到一个队列中，在设备可写时才具体写入。看下具体的读数据过程：从Reactor中最终调用到Xmemcached的command，用于具体解析回应数据。要调整为异步的话，则可以修改Command的实现，增加异步回调。同时注意控制dispatcher使用的线程池。完。" }, { "title": "XNIO源码阅读", "url": "/posts/xnio-source/", "categories": "java, network", "tags": "xnio", "date": "2017-04-09 00:00:00 +0800", "snippet": "XNIO是JBoss的一个IO框架。最开始我想找个lightweight servlet container库，于是看到了undertow，发现其网络部分使用的就是XNIO。所以干脆就先把XNIO的源码读下。XNIO文档非常匮乏，能找到都是3.0的版本，而且描述也不完全。Git上已经出到3.5.0。我读的是3.3.6.Final。使用方式可以参考SimpleEchoServer.java，不过这个例子使用的API已经被deprecated，仅供参考。使用方式大致为： 创建服务，提供acceptListener 在acceptListener中accept新的连接，并注册连接listener 在连接listener回调中完成IO读写 主要概念 Channel，基本上同Java NIO中的Channel一致，一个server socket是一个channel，accept出来的连接也是channel ChannelListener，监听Channel上的IO事件，应用代码与XNIO交互的地方 XnioWorker，维护IO线程池及应用任务线程池项目结构源码分为两个项目: xnio-api及nio-impl。xnio-api属于API层；nio-impl是基于NIO的实现。通过Java service provider动态地找到nio-impl这个实现。可见XNIO还可以用其他方式来实现。org.xnio.channels这个包里包含了大量的Channel接口定义，这个是非常恶心的一个地方，读代码的时候很容易被绕进去。这个包主要的实现后面提。org.xnio.conduits，我理解为比Channel更底层的传输通道，channel依赖于conduit实现，总之也是个恶心的概念。线程模型可以通过连接如何建立以及建立连接后如何管理连接来了解XNIO的线程模型。通过这个过程我简单画了下主要类关系以及连接建立过程：用的Dia绘图，UML图支持得不够好XNIO的线程模型是一个典型的one loop per thread的Reactor模型。WorkerThread类就是这个线程，其有一个主循环，不断地检测其关心的IO设备是否有IO事件发生。当有事件发生时，就将事件通知给关心的listener。站在上层模块的角度，这个线程就是一个Reactor，事件产生器。整个系统有固定数量的WorkerThread，也就是IO线程数。这个模型基本上凡是基于epoll/select模型实现的网络库都会用，例如muduo。可以回看下这个模型：XNIO中接收到一个新连接时，会根据这个连接的地址(remote&amp;local address)算出一个哈希值，然后根据哈希值分配到某一个IO线程，然后该连接以后的IO事件都由该线程处理。WorkerThread会始终回调NioHandle。QueuedNioTcpServerHandle是一个accept socket，监听accept事件。而NioSocketStreamConnection则是一个建立好的连接，每次新连接进来就会创建，被哈希到某个WorkerThread处理。NioSocketConduit是一个连接具体关心IO事件的类，正是前面提到的，是一个Channel的底层实现。NioXnioWorker继承于XnioWorker，XnioWorker内部包含了一个应用任务的线程池。应用代码通过channel listener获取到IO事件通知，channel listener是在IO线程中回调的，所以不适合做耗时操作，否则会导致IO线程中其他IO设备饿死。所以对于这类任务就可以放到这个线程池中做。Channel架构前面提到的XNIO例子使用了一个deprecated的接口，那如何不使用这个接口呢？这就需要更具体地了解channel。XNIO中抽象的channel有很多类型，有些是只读的，有些是只写的，有些则是全双工的。channel还能被组合 (AssembledChannel)。可以看下3.1里channel包的大图：channel package summary这里我只关注基于TCP服务中的channel。如图：重点关注 QueuedNioTcpServer 及 NioSocketStreamConnection。QueuedNioTcpServer实现AcceptingChannel 没什么好说的，就是表示一个可以接收连接的channel。NioSocketStreamConnection表示一个网络连接。StreamConnection是一个可读可写的channel，但是其内部是通过另外两个channel来实现的，分别是ConduitStreamSourceChannel及ConduitStreamSinkChannel，分别用读和写。这两个channel内部其实是分别通过两个conduit 来实现，分别为ConduitStreamSourceChannel 及 ConduitStreamSinkChannel 。NioSocketStreamConnection 内部包含NioSocketConduit，这个类实现了 ConduitStreamSourceChannel 及 ConduitStreamSinkChannel 。在TCP场景下，StreamConnection中的读写channel正是指向了NioSocketConduit。这个层次包装得有点绕，需要慢慢梳理。在accept的时候，得到的可以是StreamConnection，其实也就是得到了一个可读可写的channel，设计得也没问题。可以基于这个channel设置读写listener。但是如果想在读listener里发起写操作，由于在读listener里看到的是一个只读的channel，所以就没办法写。所以才会有其他包装的channel。理清了以上关系，就可以不用那个deprecated的API来实现一个echo server：class ReadListener implements ChannelListener&lt;StreamSourceChannel&gt; { // 保存一个可写的channel，才能在读listener里做写操作 private StreamSinkChannel sinkChannel; public ReadListener(StreamSinkChannel sinkChannel) { this.sinkChannel = sinkChannel; } public void handleEvent(StreamSourceChannel channel) { final ByteBuffer buffer = ByteBuffer.allocate(512); int res; try { while ((res = channel.read(buffer)) &gt; 0) { buffer.flip(); Channels.writeBlocking(sinkChannel, buffer); } Channels.flushBlocking(sinkChannel); if (res == -1) { channel.close(); } else { channel.resumeReads(); } } catch (IOException e) { e.printStackTrace(); IoUtils.safeClose(channel); } }}final ChannelListener&lt;AcceptingChannel&lt;StreamConnection&gt;&gt; acceptListener = new ChannelListener&lt;AcceptingChannel&lt;StreamConnection&gt;&gt;() { public void handleEvent(AcceptingChannel&lt;StreamConnection&gt; channel) { try { StreamConnection accepted; // channel is ready to accept zero or more connections while ((accepted = channel.accept()) != null) { System.out.println(\"accepted \" + accepted.getPeerAddress()); // stream channel has been accepted at this stage. // read listener is set; start it up accepted.getSourceChannel().setReadListener(new ReadListener(accepted.getSinkChannel())); accepted.getSourceChannel().resumeReads(); } } catch (IOException ignored) { } }};final XnioWorker worker = Xnio.getInstance().createWorker( OptionMap.EMPTY);// Create the server.AcceptingChannel&lt;? extends StreamConnection&gt; server = worker .createStreamConnectionServer(new InetSocketAddress(12345), acceptListener, OptionMap.EMPTY);// lets start accepting connectionsserver.resumeAccepts();完。" }, { "title": "实现JVM中的JIT", "url": "/posts/toy-jit/", "categories": "java", "tags": "jvm", "date": "2017-03-09 00:00:00 +0800", "snippet": "在JVM中，JIT (Just-in-Time) 即时编译指的是在Java程序运行过程中JVM优化部分指令为本地指令，从而大幅提升性能。在上一篇文章写一个玩具Java虚拟机中实现了一个基本可以运行Java字节码的JVM。本篇文章描述我是如何在这个玩具JVM中实现JIT的。推荐文章“How to JIT - an introduction”，介绍了JIT的基本实现原理。作者把JIT分为两个阶段： 运行期生成机器代码(本地指令) 执行机器代码生成机器代码很好理解，就是一个JVM指令到机器指令的翻译；而执行机器代码，原理上是利用了OS提供了API可以分配可以执行的内存，然后往这块内存中写入机器码，从而实现运行期可以执行动态生成的机器码功能。我们可以利用这个原理来实现JIT，但是未免太底层了点，需要做很多工作来完成这件事情。我们可以利用libjit来简化实现。这个作者博客里还有些libjit的教程，其中part 1值得阅读。 简单来说，libjit对机器指令做了抽象，利用它的API来描述一个函数包含了哪些指令，实现了什么功能。然后具体的指令生成以及指令执行则交给libjit完成。例如以下使用libjit的代码：// t = ujit_insn_store(F, t, u); // 类似 mov 指令// u = vjit_insn_store(F, u, v);// v = t % vjit_value_t rem = jit_insn_rem(F, t, v); // 求余指令jit_insn_store(F, v, rem);所以，我们需要做的，就是将JVM的字节码，翻译成一堆libjit的API调用。但是我希望能够稍微做点抽象，我们写个翻译器，能够将JVM这种基于栈的指令，翻译成基于寄存器的指令，才方便后面无论是使用libjit还是直接翻译成机器码。指令翻译要将基于栈的指令翻译成基于寄存器的指令（类似），仔细想想主要解决两个问题： 去除操作数栈 跳转指令所需要的标签去除操作数栈，我使用了一个简单办法，因为JVM中执行字节码时，我们是可以知道每条指令执行时栈的具体情况的，也就是每条指令执行时，它依赖的操作数在栈的哪个位置是清楚的。例如，假设某个函数开头有以下指令：opcode [04] - 0000: iconst_1 # [1]opcode [3C] - 0001: istore_1 # []opcode [1B] - 0002: iload_1 # [1]opcode [1A] - 0003: iload_0 # [1, N]opcode [68] - 0004: imul # [1 * N]当执行imul指令时，就可以知道该指令使用栈s[0]、s[1]的值，做完计算后写回s[0]。所以，类似JVM中局部变量用数字来编号，我也为栈元素编号，这些编号的元素全部被视为局部变量，所以这些指令全部可以转换为基于局部变量的指令。为了和JVM中本身的局部变量统一，我们将栈元素编号从局部变量后面开始。假设以上函数有2个局部变量，那么栈元素从编号2开始，局部变量编号从0开始。以上指令可以翻译为：mov 1, $2 # 常量1写入变量2lod $2, $1 # 变量2写入变量1lod $1, $2 # 变量1写回变量2lod $0, $3 # 变量0写入变量3mul $3, $2 # 变量3与变量2相乘，写回变量2这里，我们定义了自己的中间指令集(IR)，这个中间指令集存在的意义在于，在将来翻译为某个平台的机器码时，它比JVM的指令集更容易理解。中间指令集是一种抽象，方便基于它们使用libjit或其他手段翻译成机器码。不过，我们看到上面的指令非常冗余。要优化掉这种冗余相对比较复杂，所以本文暂时不讨论这个问题。这个中间指令基于局部变量的方式，是利于JIT下游做各种具体实现的，例如是否直接转换为通用寄存器，即一定范围的局部变量数是可以直接使用寄存器实现，超出该范围的局部变量则放在栈上，用栈模拟；或者全部用栈模拟。注意在机器指令中栈元素是可以直接偏移访问的，不同于“基于栈的虚拟机”中的栈。以上指令，我们可以简单地为每条指令设定如何翻译为libjit的调用，例如mov指令：static void build_mov(BuildContext* context, const Instruction* inst) { jit_value_t c = jit_value_create_nint_constant(context-&gt;F, jit_type_int, inst-&gt;op1); jit_insn_store(context-&gt;F, context-&gt;vars[inst-&gt;op2], c);}例如mul指令：static void build_mul(BuildContext* context, const Instruction* inst) { // context-&gt;vars就是前面说的局部变量表，包含了JVM中的局部变量及操作数栈 jit_value_t tmp = jit_insn_mul(context-&gt;F, context-&gt;vars[inst-&gt;op1], context-&gt;vars[inst-&gt;op2]); jit_insn_store(context-&gt;F, context-&gt;vars[inst-&gt;op1], tmp);}接下来说另一个问题：跳转指令的标签。在机器指令中，跳转指令跳转的目标位置是一个绝对地址，或者像JVM中一样，是一个相对地址。但是在我们的中间指令集中，是没有地址的概念的，在翻译为机器指令时，也无法获取地址。所以，我们一般是增加了一个特殊指令label，用于打上一个标签，设置一个标签编号，相当于是一个地址。在后面的跳转指令中，则跳转的是这个标签编号。所以，我们需要在翻译JVM指令到我们的中间指令时，识别出哪些地方需要打标签；并且在翻译跳转类指令时，翻译为跳转到某个编号的标签。例如以下指令：opcode [04] - 0000: iconst_1opcode [3C] - 0001: istore_1opcode [1B] - 0002: iload_1 # 会被调整，需要在此打标签opcode [1A] - 0003: iload_0...opcode [1A] - 0010: iload_0opcode [9D] - 0011: ifgt -9 # pc-9，也就是跳转到0002位置为了打上标签，我们的翻译需要遍历两遍指令，第一遍用来找出所有标签，第二遍才做真正的翻译。 // 该函数遍历所有指令，找出所有需要打标签的指令位置 private List&lt;Integer&gt; createLabels(List&lt;InstParser.Instruction&gt; jbytecode) { List&lt;Integer&gt; labels = new LinkedList&lt;&gt;(); for (InstParser.Instruction i : jbytecode) { LabelParser labelParser = labelParsers.get(i.opcode); if (labelParser != null) { // 不为空时表示是跳转指令 int pc = labelParser.parse(i); // 不同的跳转指令地址解析不同，解析得到跳转的目标地址 labels.add(pc); // 保存起来返回 } } return labels; }然后在翻译指令的过程中，发现当前翻译的指令地址是跳转的目标位置时，则生成标签指令： List&lt;Integer&gt; labels = createLabels(jbytecode); ... Iterator&lt;InstParser.Instruction&gt; it = jbytecode.iterator(); while (it.hasNext()) { InstParser.Instruction inst = it.next(); int label = labels.indexOf(inst.pc); if (label &gt;= 0) { state.addIR(new Inst(op_label, label)); // 生成标签指令，label就是标签编号 }在处理跳转指令时，则填入标签编号：translators.put(Opcode.op_ifgt, (state, inst, iterator) -&gt; { short offset = (short)((inst.op1 &lt;&lt; 8) + inst.op2); int pc = inst.pc + offset; int label = state.findLabel(pc); // 找到标签编号 int var = state.popStack(); state.addIR(new Inst(op_jmp_gt, var, label));});我们的中间指令集中，跳转指令和标签指令就为：label #N // 打上标签Njmp_gt $var, #N // 如果$var&gt;0，跳转到标签#N看下使用libjit如何翻译以上两条指令：static void build_label(BuildContext* context, const Instruction* inst) { // 打上标签，inst-&gt;op1为标签编号N，对应写到context-&gt;labels[N]中 jit_insn_label(context-&gt;F, &amp;context-&gt;labels[inst-&gt;op1]);}static void build_jmp_gt(BuildContext* context, const Instruction* inst) { jit_value_t const0 = jit_value_create_nint_constant(context-&gt;F, jit_type_int, 0); // 是否&gt;0 jit_value_t cmp_v_0 = jit_insn_gt(context-&gt;F, context-&gt;vars[inst-&gt;op1], const0); // 大于0则跳转到标签inst-&gt;op2 jit_insn_branch_if(context-&gt;F, cmp_v_0, &amp;context-&gt;labels[inst-&gt;op2]);}代码贴得有点多，大概懂原理就行了。在JIT中还有个很重要的过程，就是判定哪些代码需要被JIT。这里只是简单地尝试对每一个函数进行JIT，发现所有指令都能够被JIT时就JIT。指令执行在上一篇文章中，执行每个JVM函数时，都会有一个Frame与之关联。所以，在这里只要函数被JIT了，对应的帧就会包含被编译的代码，也就是libjit中的jit_function_t。在该Frame被执行时，就调用libjit执行该函数： private void runNative() { int arg_cnt = getArgsCount(); int[] args = new int[arg_cnt]; for (int i = 0; i &lt; arg_cnt; ++i) { if (mLocals[i].type != Slot.Type.NUM) throw new RuntimeException(\"only supported number arg in jit\"); args[i] = mLocals[i].i; } int ret = mJIT.invoke(args); // mJIT后面会看到，主要就是将参数以数组形式传递到libjit中，并做JIT函数调用 mThread.popFrame(); if (hasReturnType() &amp;&amp; mThread.topFrame() != null) { mThread.topFrame().pushInt(ret); // 目前只支持int返回类型 } }实现以上就是整个JIT的过程，主要工作集中于JVM指令到中间指令，中间指令到libjit API调用。整个实现包含以下模块：+-----------+ +----------+| ASM | | libjit || | &lt;-----+ API call |+-----------+ +----+-----+ ^ |+-----------+ +----+-----+| JVM | | IR code || bytecode +-----&gt; | |+-----------+ +----------+JVM byte code及IR code的处理是在Java中完成的；处理完后将IR code输出为byte[]，通过JNI调用包装好的C API。这个C API则是基于libjit，将IR code翻译为libjit的API调用。指令翻译完后调用libjit的API得到最终的ASM机器指令。同样，要执行指令时，也是通过JNI调用这个C API。JNI交互全部包装在以下类中：public class ToyJIT { private long jitPtr = 0; public void initialize(byte[] bytes, int maxLocals, int maxLabels, int argCnt, int retType) { jitPtr = compile(bytes, maxLocals, maxLabels, argCnt, retType); } public int invoke(int... args) { return invoke(jitPtr, args); } static { System.loadLibrary(\"toyjit\"); } private static native long compile(byte[] bytes, int maxLocals, int maxLabels, int argCnt, int retType); private static native int invoke(long jitPtr, int[] args);即，libtoyjit.so 主要提供翻译接口 compile 及执行接口 invoke。性能对比简单测试了下一个阶乘计算函数： public static int fac2(int n) { int r = 1; do { r = r * n; n = n - 1; } while (n &gt; 0); return r; } ... int i = 0; for (; i &lt; 10000; ++i) { fac2(100); } ...fac2函数会被JIT，测试发现不开启JIT时需要16秒，开启后1秒，差距还是很明显的。最后奉上代码，toy_jit，就是前面说的C API部分，翻译IR到libjit API call，包装接口用于JNI调用。redhat 7.2下编译，需要先编译出libjit，我是直接clone的libjit master编译的。Java部分还是在toy_jvm中。" }, { "title": "写一个玩具Java虚拟机", "url": "/posts/toy-jvm/", "categories": "java", "tags": "jvm", "date": "2017-02-25 00:00:00 +0800", "snippet": "本文描述了一个用Java实现的玩具JVM，用Java实现的好处是可以不用处理JVM中的垃圾回收。Java虚拟机是基于栈的虚拟机。栈虚拟机的特点是所有临时操作数都存放在栈中。编译器生成的指令都会围绕着这个栈展开，相对而言，解释执行这些指令会比较容易。基于栈的虚拟机可能会生成如下指令：push 3 # 把立即数3压栈push 4 # 把立即数4压栈add # 从栈中弹出两个操作数进行相加，结果压回栈中Java .class文件存储的主要就是编译后的指令，一个玩具JVM，简单来说就是解释执行这里面的指令。接下来就说说为了让这个JVM跑起来需要实现哪些功能。class 文件解析推荐一下 Java class viewer，里面有个工具可以可视化class文件内容。另外我直接复用了他解析class文件的代码。class文件描述的信息是以class为单位的，一个类如果有嵌套类，这个嵌套类也会生成为单独的class文件。从c/c++程序员的视角来看，class文件的生成有点类似编译，编译器在编译期间只做依赖符号存在与否的检查。所有引用其他class的地方，不同于c/c++，java class的引用都是在运行期定位的。这里看看一个简单的类class文件结构是怎样的：package test;public class Simple { private int data; public int add(int a, int b) { return a + b; }}一个class文件比较重要的有： constant pool(常量池)：存储字符串字面量、函数原型描述、类成员描述、class引用描述。字节码中经常会引用常量池中的内容，例如要设置某个成员变量，字节码中的操作数就是常量池索引，从索引中获取出具体是哪个成员变量 fields：描述类成员变量 methods: 描述类成员函数 attributes: 分布在很多地方，可能嵌套，用于描述method字节码、调试符号信息等。常量池非常重要，这里看看class文件中是如何使用常量池的。例如，一个field描述：其中name_index和descriptor_index的值，指向的就是常量池索引，通过前面推荐的class viewer去常量池中找就会找到对应的值：descriptor_index描述field类型，I指的是整数。Java里有一套描述类型的规则，这个规则在函数定义的地方也会看到。methods只要有实现，就都会有一个Code attribute，也就是这个函数的具体实现字节码，例如前面的add函数字节码为：opcode [1B] - 0000: iload_1 # 将第1个局部变量值压栈opcode [1C] - 0001: iload_2 # 将第2个局部变量值压栈opcode [60] - 0002: iadd # 弹出2个操作数相加，结果压栈opcode [AC] - 0003: ireturn # 弹出1个操作数作为函数返回值解析出class文件中的信息后，玩具JVM就完成一半了。JVM指令JVM中已经有200多条指令了。但是这些指令很多都是相似的。具体实现这些指令时可以参考指令表。JVM指令就像x86指令一样，由操作码以及可选的操作数组成。操作码表示具体是哪条指令，占1个字节；操作数表示该操作码需要的参数，变长。class文件中字节码连续存放，像上一节的例子就是4条指令，每条指令只有操作码没有操作数，他们存放在class文件中就是：1B 1C 60 AC。JVM依次读取这些指令并解释执行。这个过程同真实计算机CPU执行过程类似。用代码描述为：while (true) { code = fetchOpCode() if (code == iload_1) { push(1) } elif (code == iadd) { i1 = pop() i2 = pop() push(i1 + i2) } elif (code == bipush) { // 需要操作数的指令 b = fetchOpValue() push(b) } ...}程序执行过程中有一个虚拟指针PC，用于指示当前字节码处理到哪个位置了。有些跳转指令会强制改变PC。不同于c/c++程序，JVM中跳转指令跳转的都是相对位移。JVM启动时，不同于c/c++，也没有地址重定位的过程(修正相对地址为实际地址)。执行环境线程执行环境JVM中每个线程都是独立的执行单元。但是对于类符号等信息则是全局共享，堆上创建的对象也是全局可访问的。单个线程中调用函数会产生帧(frame)，每一帧都有一个独立的栈用于存储该帧执行的临时数据。从main函数开始执行，每进入一个函数创建一个帧，函数退出(执行return系列指令)清除当前帧。这里的帧也可以被实现为一个栈，当这个栈里没有帧时就表示这个线程退出。这个过程可以描述为：while (thread.topFrame() != null) { thread.topFrame().run() // 内部实现就是从Code属性处不断地取指令执行}// 执行到return语句时，就弹出该帧if (code == op_return) { frame.getThread().popFrame()}// 遇到函数调用时，就根据目标函数创建出一帧if (code == op_invoke) { method = findMethod(ref) // 函数调用时操作数是常量池索引，需要加载目标类，获取目标方法 newFrame = createFrame(method) // 每个方法都会描述该方法内有多少局部变量，所需栈多大，根据这些信息初始化帧 frame.getThread().pushFrame(newFrame) }注释中提到了，class文件中method包含了“有多少局部变”、“需要多大的栈”等信息。局部变量的实现是一个数组，数组的下标表示局部变量是第几个。字节码中要访问局部变量时，全部是以这个下标来查找的。例如指令istore_1，表示从栈中弹出一个整数，并写到局部变量1中。全局环境由于使用Java实现，堆内存的管理完全不用操心。如果我们代码中创建了一个类对象，或者简单点调用了另一个类的静态方法，这个时候会发生什么以及如何处理？例如以下代码：int a = Simple2.inc(2);生成以下字节码：opcode [05] - 0004: iconst_2 # 压入常量2到栈，作为函数调用的参数opcode [B8] - 0005: invokestatic 2 [Methodref: test.Simple2.inc, parameter = (int), returns = int]可以看出调用静态函数invokestatic的操作数是2，指向的是常量池中的2。工具直接显示了常量池2是一个method，及该method的原型。遇到这样的指令时，我们就需要找到并加载目标类。所以，全局信息里需要维护类列表。考虑到Java中类与类之间是否相同，除了看类名（全限定名）外，还得看类的加载器(class loader)。所以，玩具JVM中也需要有class loader机制（至少是个简化版）。程序启动时设定一个默认的类加载器，加载主类，执行主类main方法，执行过程中遇到对其他类的引用时，就使用当前类加载器继续加载目标类，如果已经加载就直接返回。类加载及main方法前面已经提到了类加载。其实类加载本质上就是把目标class文件加载到内存，保存该class信息。在调用一个类的方法时，也是根据方法名(考虑到方法重载，还得考虑方法的原型，在class file中也就是descriptor)找到具体的方法，根据方法初始化调用帧，以及根据方法获得其要执行的字节码。所以，我们的JVM要跑起来，也就是找到并加载主类，然后找到主类中的main函数并执行。 public void run(String mainClass) { Class clazz = mRootLoader.loadClass(mainClass); MethodInfo method = clazz.findMethod(\"main\", \"([Ljava/lang/String;)V\"); Thread thread = new Thread(); thread.run(clazz, method); }当然，这个过程严格来说还得判定类访问控制、方法访问控制等。至此，这个玩具JVM就可以跑起来了。可以设定它的class path，加载类，从main方法开始执行，调用其他类的静态方法，写写阶乘的实现是没有问题了。但是Java中还有很多其他特性：类对象、调用类实例方法、异常处理、调用native方法等待。接下来我再讲讲这些特性的实现，一窥Java核心语法的实现。扩展实现类对象及实例方法调用类对象的创建通过new指令完成，本质上也就是分配个对象，并关联类信息到这个对象。我们的实现中自然会有一个类用来表示玩具JVM中所有的对象：// 为了与java.lang.Object区分开public class VObject { // 简单起见，直接以field名作为key，来保存该对象所有的成员变量 private Map&lt;String, Slot&gt; mFields; // 与之关联的类信息 private final Class mClazz; ...}注意这里的Class是我们自己定义的Class，而不是java.lang.Class。Slot类型用于存储整数或一个引用(其他对象)。new指令的大概实现：register(Opcode.op_new, (codes, frame) -&gt; { int b1 = codes.readByte(); int b2 = codes.readByte(); int idx = (b1 &lt;&lt; 8) + b2; // 常量池索引，指向一个类信息描述 String clazzName = frame.getClazz().resolveClassName(idx); // 根据这个类信息描述解析到具体的类名 Class clazz = frame.getClazz().getClassLoader().loadClass(clazzName); // 使用当前的类加载器加载该类 initClass(frame.getThread(), clazz); VObject object = new VObject(clazz); // 创建该类对应的对象，完成new指令的对象创建动作 frame.pushRef(object); // 根据new指令的语义，我们需要将创建好的对象引用压回栈中});需要注意的是，当我们在Java中写下代码 new SomeClass() 时，实际会产生两个功能的指令：a) 创建对象；b) 调用类的构造函数()opcode [BB] - 0004: name_new 2 [Class: test.Simple2] # new 指令，操作数是类信息常量池索引opcode [59] - 0007: dup opcode [B7] - 0008: invokespecial 3 [Methodref: test.Simple2. , parameter = (), returns = void] # 调用目标类的构造函数，也就是&lt;init&gt;方法调用类构造函数同普通类实例方法原理相同，都会先压入对象引用。invokespecial指令用于调用类对象实例方法，从栈顶依次出栈参数，最后出栈类对象实例引用。具体可以看看指令表里的描述。类静态区域初始化首次加载某个类时，会执行其static区域代码。这个写测试看下生成的代码就懂了，就是生成一个的静态方法，在加载类时先执行这个方法。异常处理当一个方法中有try/catch时，该方法就会生成出一个异常处理表，存储在Code属性中。如下图：异常处理表每一项都包含：start_pc、end_pc、handler_pc 及catch_type，表示在start_pc/end_pc间发现异常，且异常类型是catch_type时，则跳转到handler_pc处执行代码，也就是异常处理代码。其中catch_type也是常量池中的索引，当其为0时，则不是常量池索引，而是表示catch所有类型，其实就是finally块。从这里也可以看出，常量池索引是从1开始，而不是0。当异常发生时，JVM首先从当前帧对应的方法中的异常处理表查找异常处理代码，没有的话则弹出当前帧，回到上一帧，也就是调用者继续查找，直到找完所有调用帧。这个实现相对较多，就不列举代码了。调用本地方法前面实现的JVM都没有输出字符串的能力，要提供一个类似System.out.println的方法，就需要注册本地方法到JVM中。这里可以简单地为整个JVM设置一个本地方法表，在JVM启动时完成注册。类似以下代码：public static void native println(String s);也会在class文件中留下一个method，但这个method会被标记为native，自然也没有Code属性，没有字节码可执行。当执行invoke系列指令时，发现调用的是native方法，就需要从全局本地方法表中查找。注册本地方法类似：mMethods.put(makeKey(\"java/lang/System\", \"println\", \"(Ljava/lang/String;)V\"), (frame) -&gt; { String s = (String) frame.popRef(); System.out.println(s);});本地方法执行时，通过frame参数就可以取出调用该方法传入的参数。在实现了本地方法后，就可以给这个玩具JVM添加一些系统库，类似OpenJDK中jre目录下的lib。这些系统库可以包含java.lang.System.println、java.lang.String、java.lang.StringBuilder。简单起见，我实现的这些类和Java标准库有些不同。最后完整代码这里。实现的指令很有限，可以跑通test/AllTest.java中的代码。对于long/double等类型没有支持，各种限定访问的判断也没有。总之就是简单到仅仅可以一窥原理。基于java8，测试例子class文件java7编译(应该没关系)。祝玩得开心。" }, { "title": "RequireJS最简实现", "url": "/posts/mini-requirejs/", "categories": "javascript", "tags": "requirejs", "date": "2017-02-05 00:00:00 +0800", "snippet": "网上有不少解析RequireJS源码的文章，我觉得意义不大。阅读源代码的目的不是为了熟悉代码，而是为了学习核心实现原理。相对RequireJS的源码，kitty.js的实现更简单，更容易理解。本文正是抄了kitty.js的实现，是一个更精简的RequireJS，用于理解RequireJS的实现原理。github dummy-requirejs。这个实现仅支持核心feature：require(deps, callback) // deps 是依赖数组define(id, deps, factory) // factory是一个函数例子参考git中rect.js/main.js。从实现来看，require/define是基本一致的，require的callback等同于define的factory：都会要求deps被加载且被执行，获得deps的exports作为整个module传入callback/factory。不同的是，factory的返回值会被作为define出来的模块的export，可被视为模块本身；而callback返回值被忽略。从用法来看，define仅是定义了模块，这个模块可能被作为deps被其他模块依赖，但define传入的factory此时是不执行的；而require则会触发各个模块的factory执行。实现主要实现分为3部分内容，其中关键的地方在于模块载入。数据结构既然是模块加载器，并且需要处理模块之间的依赖问题，所以设置一个哈希表保存所有的模块。var mods = {} // &lt;id, Module&gt;function Module(id) { var mod = this mod.id = id mod.uri = id // 简单起见，根据id拼出uri: abc.js mod.deps = [] // 依赖的模块id列表 mod.factory = blank // 定义模块时的factory mod.callback = blank // 模块加载完毕后回调 mod.exports = {} // 模块导出的对象}define的实现就比较简单，主要就是往mods里添加一个Module对象，简单来说就是：function define(id, deps, factory) { var mod = getModule(id) // mods存在就返回，否则就往mods里新增 mod.deps = deps mod.factory = factory}模块载入遇到require时就会产生模块载入的动作。模块载入时可能发生以下动作： 往页面添加script标签以让浏览器从服务端拉取js文件 js文件中可能遇到define从而立即添加模块 (非AMD模块不考虑) define定义的模块可能有其他依赖模块，递归载入这些模块，直到所有模块载入完毕这里的模块载入只是把模块js文件载入到浏览器环境中。以上过程对应的大概代码为：Module.prototype.load = function() { var mod = this if (mod.status == STATUS.FETCHING) return if (mod.status == STATUS.UNFETCH) { return mod.fetch() // 添加script标签从服务端拉取文件 } mod.status = STATUS.LOADING mod.remain = mod.deps.length // 所有依赖载入完毕后通知回调 function callback() { mod.remain-- if (mod.remain === 0) { mod.onload() // 通知回调 } } each(mod.deps, function (dep) { var m = getModule(dep) // 获取依赖模块对象，依赖模块可能已经被载入也可能没有 if (m.status &gt;= STATUS.LOADED || m.status == STATUS.LOADING) { // 已经载入 mod.remain-- return } m.listeners.push(callback) if (m.status &lt; STATUS.LOADING) { m.load() } }) if (mod.remain == 0) { mod.onload() }}load的实现由于混合了异步问题，所以理解起来会有点难。fetch的实现就是一般的往页面添加script及设置回调的过程。在fetch完毕后会重新调用load以完成递归载入该模块的依赖：// 该函数回调时，该js文件已经被浏览器执行，其内容包含define则会添加模块（当然已经被添加过了）// 可以回头看上面的define调用的是getModule，此时会重新设置deps/factory等属性function onloadListener() { var readyState = script.readyState; if (typeof readyState === 'undefined' || /^(loaded|complete)$/.test(readyState)) { mod.status = STATUS.FETCHED mod.load() }}模块生效模块载入后模块其实还没生效，还无法使用模块中定义的各种符号。要让模块生效，就得执行模块定义的factory函数。在直接间接依赖的模块被全部载入完成后，最终回调到我们的callback。此时可以看看require的实现：// 前面提到require/define实现类似，所以这里创建了Module对象，只是复用代码function require(deps, callback) { var mod = new Module(getId()) mod.deps = deps mod.factory = callback mod.callback = function () { mod.exec() } mod.status = STATUS.FETCHED mod.load()}就是简单地调用了load，完成后调用了exec。exec又是一个涉及到递归的函数，它会递归执行所有模块的factory。factory的执行需要各个模块的exports对象，只有模块exec后才会得到exports对象。Module.prototype.exec = function() { var mod = this if (mod.status &gt;= STATUS.EXECUTED) { return mod.exports } // 获取依赖模块的exports列表 var args = mod.getDepsExport() var ret = mod.factory.apply(null, args) // factory 返回值作为该模块的exports mod.exports = ret mod.status = STATUS.EXECUTED return mod.exports}上面的代码主要是实现这样的功能：// 将依赖[d1, d2]的exports作为参数d1,d2传入define('my-module', ['d1', 'd2'], function (d1, d2) { return {func: function() {}}})getDepsExport就是一个取依赖模块exports的过程：Module.prototype.getDepsExport = function() { var mod = this var exports = [] var deps = mod.deps var argsLen = mod.factory.length &lt; deps.length ? mod.factory.length : deps.length for (var i = 0; i &lt; argsLen; i++) { exports.push(mod.require(deps[i])) } return exports}Module.require(id)用于exec目标模块并返回其exports：Module.prototype.require = function(dep) { // 由于之前已经递归载入过所有模块，所以该依赖模块必然是已经存在的，可以被exec的 var mod = getModule(dep) return mod.exec()}于是又回到了exec，实现了递归执行所有依赖模块的功能。exec主要是获取依赖模块exports并调用factory，所以最初的require将用户的callback作为factory传入那个临时Module，最终使得调用到用户的callback。通过以上过程，实际上就已经走通了从define到require实现的整个过程。整个代码不到200行。基于此可以添加更多RequireJS的附加功能。完。" }, { "title": "ReactJS项目中基于webpack实现页面插件", "url": "/posts/react-plugin/", "categories": "javascript", "tags": "reactjs", "date": "2017-01-08 00:00:00 +0800", "snippet": "整个Web页面是基于ReactJS的，js打包用的webpack，现在想在Web页面端实现一种插件机制，可以动态载入第三方写的js插件。这个插件有一个约定的入口，插件被载入后调用该入口函数，插件内部实现渲染逻辑。插件的实现也使用了ReactJS，当然理论上也可以不使用。预期的交互关系是这样的：// 主页面load('/plugin/my-plugin.js', function (plugin) { plugin.init($('#plugin-main'), args)})// 基于ReactJS的插件function init($elem, args) { ReactDOM.render((&lt;Index /&gt;), $elem)}export {init}在主页面上支持这种插件机制，有点类似一个应用市场，主页面作为应用平台，插件就是应用，用户可以在主页面上选用各种插件。问题目前主页面里ReactJS被webpack打包进了bundle.js，如果插件也把ReactjS打包进去，最终在载入插件后，浏览器环境中就会初始化两次ReactJS。而ReactJS是不能被初始化多次的。此外，为了插件编写方便，我把一些可重用的组件打包成一个单独的库，让主页面和插件都去依赖。这个库自然也不能把ReactJS打包进来。何况还有很多三方库，例如underscore、ReactDOM最好也能避免重复打包，从而可以去除重复的内容。所以，这里就涉及到如何在webpack中拆分这些库。需要解决的问题： 拆分三方库，避免打包进bundle.js 动态载入js文件，且能拿到其module，或者至少能知道js什么时候被载入，才能调用其入口函数关于第二个问题，我选用了RequireJS，但其实它不是用于我这种场景的，不过我不想自己写一个js载入器。用RequireJS在我这种场景下会带来一些问题：webpack在打包js文件时会检查是否有AMD模块加载器，如果有则会把打包的代码作为AMD模块来加载。对于三方库的依赖就需要做一些适配。实现开始做这件事时我是不熟悉RequireJS/AMD的，导致踩了不少坑。过程不表，这里就记录一些关键步骤。公共组件库及插件是必须要打包为library的，否则没有导出符号：// webpack.config.jsconfig.output = { filename: 'drogo_components.js', path: path.join(__dirname, 'dist'), libraryTarget: 'umd', library: 'drogo_components'};此外，为了不打包三方库进bundle.js，需要设置：// webpack.config.jsconfig.externals = { 'react': 'React', 'underscore': '_',};externals中key为代码中require或import xxx from 'xxx'中的名字，value为输出代码中的名字。以上设置后，webpack打包出来的代码类似于：(function webpackUniversalModuleDefinition(root, factory) { if(typeof exports === 'object' &amp;&amp; typeof module === 'object') module.exports = factory(require(\"React\"), require(\"_\")); else if(typeof define === 'function' &amp;&amp; define.amd) define([\"React\", \"_\"], factory);...了解了RequireJS后就能看懂上面的代码，意思是定义我这里说的插件或公共库为一个模块，其依赖React及_模块。插件及公共库如何编写？// 入口main.js中import React from 'react'import ReactDOM from 'react-dom'import Test from './components/test'import Index from './components/index'function init($elem, data) { ReactDOM.render((&lt;Index biz={data.biz} /&gt;), $elem)}export {Index, Test, init}入口js中export的内容就会成为这个library被require载入后能拿到的符号。这个库在webpack中引用时同理。注意需要设置库的入口文件：// package.json \"main\": \"static/js/main.bundle.js\",对于本地库，可以通过以下方法在本地使用：// 打包本地库，生成库.tgz文件npm pack// 切换到要使用该库的工程下安装npm install ../xxx/xxx.tgzpackage.json中也不需要依赖该文件，如果不自己install，也是可以在package.json中依赖的，类似：\"xxxx\": \"file:../xxx/xxx.tgz\"经过以上步骤后，在主页面中载入插件打包的bundle.js时，会得到错误，说找不到React模块。我这里并没有完全改造为RequireJS的模块，所以我在页面中是静态引入react的，即：&lt;script src=\"static/js/react-with-addons.js\"&gt;&lt;/script&gt;&lt;script src=\"static/js/react-dom.min.js\"&gt;&lt;/script&gt;当执行插件后，RequireJS会去重新载入react.js，如果能load成功，就又会导致浏览器环境中出现两份ReactJS，解决方法是：define('react', [], function() { return React})define('react-dom', [], function() { return ReactDOM})define('_', [], function () { return _})即，因为react被静态引入，就会存在全局变量window.React，所以这里是告诉RequireJS我们定义react模块就是全局变量React。此时webpack中打出的文件中require(['react'], xx时，就不会导致RequireJS再去从服务端载入react.js文件。使用RequireJS后，要动态载入插件，代码就类似于：window.require(['/api/plug/content/1'], function (m) { m.init($('#app-main')[0], args)})最后，之所以没有把页面全部改造为RequireJS，例如通过require载入主页面，主页面依赖react、公共组件库等，是因为我发现RequireJS的载入顺序与项目中使用的部分界面库有冲突，导致一些&lt;a&gt;的事件监听丢失（如下拉菜单不可用），根本原因还没找到。" }, { "title": "一次逆向网页内容加密", "url": "/posts/reverse_html/", "categories": "other", "tags": "html", "date": "2016-08-16 00:00:00 +0800", "snippet": "最近写一个爬虫要从这个网页爬取内容。以往爬取网页内容复杂点的，一般就是处理下页面内容动态载入，动态载入的内容可能会要求复杂奇怪的参数，或者找到这个动态载入的HTTP接口在哪里麻烦点。但是这个网页不同。类似：&lt;td&gt;&lt;span name=\"record_yijiaof:feiyongzldm\" title=\"pos||\"&gt;&lt;span id=\"5d299905633d4aa288b65f5bf74e414c\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;专&lt;/span&gt;&lt;span id=\"546c73d012f74931aa5d45707121eb50\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;实&lt;/span&gt;&lt;span id=\"e0285e05974b4577b23b2ced8e453005\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;新&lt;/span&gt;&lt;span id=\"82b9e003de4e4577aa7617681a0d3777\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;用&lt;/span&gt;&lt;span id=\"417aaf4c6ad14b7781db02a688a4f885\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;用&lt;/span&gt;&lt;span id=\"a3f326efa35e4fe898d2f751e77d6777\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;新&lt;/span&gt;&lt;span id=\"c6c5135b931c48c09c6529735f4c6434\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;型&lt;/span&gt;&lt;span id=\"8c55b119929147ddbe178776903554e5\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;专&lt;/span&gt;&lt;span id=\"f8e47702c9f5420198a6f9b9aa132c9c\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;利&lt;/span&gt;&lt;span id=\"60cc2e23682e4ca2b850a92f55029458\" class=\"nlkfqirnlfjerldfgzxcyiuro\"&gt;第9年年费&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;最终希望得到的内容其实是实用新型专利第9年年费，但是得到的网页确实乱序后的字符串，并且每次刷新得到的乱序还不一样，试过几次也看不出规律。按照以往的思路，猜测肯定是某个js文件中包含了还原算法，我的目的，就是找出这个算法，在爬虫程序中实现这个算法，以还原出可读的字符串。js中要完成这样的事，首先得找到网页元素，包括：根据外层span name=record_yijiaof:feiyongzldm；根据再外层的table；根据内层span class='nlkfqirnlfjerldfgzxcyiuro'。以前我一直想要个工具，可以在某网页载入的所有js文件中搜索特定字符串，从而帮助逆向，但是一直没有这个工具。所以这次也只有人肉看每个js。根据js的名字猜测这个逻辑会放在哪里。看了几个可能的js文件，在文件中都没有搜索出我认为可能的字符串。于是我又人肉搜索其他不太可能的js文件，均未果。此时陷入死胡同。网页文件末尾会有个超长id的span元素，类似：&lt;span style=\"display: none\" id=\"3535346033366237393b6c3c38343d3e71702777202021272f28282a797f2b2f0c1910411d4016171b4d4f1f49191b18075053040204010100085b0b580e0908776d2370227674712d2f2b7879287a2935696b6b306730606d683f6c6b39686857564e00520653565b5c08525f5c0d5b4812424a17434345414e494e1a491d49b4b2b6afbce6b3b2eab8bbb2b5bfb7bea4a6f6f7f6f0a7a0a0aeadada5adadaa9595c79688c39ec29c9e9d9b9ece97c985858083858c8ed68edf83d985dcdf8ef3f3a1faa7e9f0f7abaaf8aefefef8f7e2b4e6b0b5e7b4efede9bbe2eebbebead0d3dbd7d1ddcad2d0d88fdfd88fdddc9695c6c79693c595cd9fcbcacb989f9b32303a373236372b3039383f3e34683a71262b2120237722207b2279792c2d2d1043411b131017170411181a48151a4b0307570a01015255015b5e5e5e0d0f0624767374222377232d65282f2a282c2d69656a35626362663b3d633f3f39673e53555a015c04545f505a460d5f585a5a13464015174c14434f4a49434845184fb5b9e6b5e7e4e5e1bbbdeca7eab9bdb6f6a5a4f1a4a3a0f6acaaaaadfda5aea890c4c6c696c6c797999d92c980cbc89ad5828383848dd2828e8dd88ed984d88aa1a4f0a0a5a3a3f6abf8acaaf5e1fcfce2e3b0b5edb6e6efeabbeeeabebee6eb8685d0d186848486dbd18edcd8dfc2d7c39593cac6cdc7cecaccc9cfcb9e9f9d31623b3a61303465383132336a3f372322297322702d21717a782b7d287c287e194041161417431e104d4c124e491b181c005355025153540d09025d5e090b5d727973717d75277278797c7a2f7b792a347d6061306630606d6e696d3e386a3a58575a01545351515c5b09095c0f0a5744175e10454743144a1d42484948484be3b8b5bbb7e3bfb5bdebbebdbdebb9b8a6a7f3bff2f7a3a5abffaffdafacfdab9494c193c5929196c99bcb9c94c89c9dd2818ad5988c8680d98d8fda8b8b8adca6f5f4a6a2a7a5a1faadabfcaaf8f9adb2e2b0b2e5f这个字符串不像base64加密，看这个网页带了md5的js，怀疑跟md5有关，但md5不应该用来加密字符内容，js文件中也未看到可能的API。后来发现乱序的字符串中有些字符是不显示的，通过这个css控制：nlkfqirnlfjerldfgzxcyiuro { display: none!important; visibility: hidden!important;}网页载入经过js处理后，显示出来的字符看起来是相同的css class nlkfqirnlfjer1dfgzxcyiuro，开始觉得奇怪，研究了下这个的差异。折腾了好久发现被人戏弄了：nlkfqirnlfjer1dfgzxcyiuro与nlkfqirnlfjerldfgzxcyiuro，前一个是r1d后一个是rld，分别是数字1和字母L！WTF原始网页中所有字符的css class都是不显示的，所以可以推测js中经过一定算法将需要显示的字符改了css class。但是此刻还是没有思路。后来尝试了chrome的DOM breakpoint，可以在DOM元素被改变时断点，但是用起来不是特别好用，没有带来任何帮助。绝望之际把整个网页另存下来，另存下来的网页是经过js处理后的，手工将css改回原始内容，本地载入网页发现还是可以正常显示，证明处理逻辑真的还在js文件中。然后我逐个删除每一个js文件，还是想找出具体是哪个js文件包含了这个还原算法。然后发现竟然是jquery-1.7.2.min.js。但我想这不能说明问题，因为作者肯定是通过jQuery来获取元素的，删除jQuery.js作者的代码不能work，当然就显示不出来。这个时候我开始清理html中的js代码，发现所有js代码都被清除完后，网页内容依然可以还原，所以断定还原算法就在jQuery.js中。然而这个文件是min版本的，网上找了个还原工具，其实就是重新格式化方便阅读。但是此刻发现在这个文件中依然搜索不到可能的字符串，例如前面提到的找元素的一些线索，如span css，如span name等等。此时重新通过chrome的DOM断点来获取调用堆栈。这次直接断css class会被改变的span元素，竟然发现可行。此时无非是断点，看效果，继续下更精确的断点，最后发现源头： b(function() { b.mix() }); ... mix: function() { var b0 = bF(\"s\" + \"p\" + \"a\" + \"n\"); if (b0 &amp;&amp; b0[b0.length - 1]) { var b5 = b0[b0.length - 1].getAttribute(\"i\" + \"d\"); if (!b5) { return } var b2 = \"\"; var b4 = 0; for (var b3 = 0; b3 &lt; b5.length; b3 += 2) { if (b4 &gt; 255) { b4 = 0 } var b1 = parseInt(parseInt(b5.substring(b3, b3 + 2), 16) ^ b4++); b2 += String.fromCharCode(b1) } if (b2) { // ... 省略首先看到的是\"s\" + \"p\" + \"a\" + \"n\"，这不就是span！看前面几行代码很快就明白这是在取网页的最后一个span元素，也就是那个包含超长id属性的span元素。此时需要提下，之前也是对这个页尾span元素做过实验，发现必须是span元素且为最后一个元素才能正确还原网页内容，可以推断这个span是多么关键的一个线索。感兴趣的可以把这个网页的jQuery-1.7.2.min.js还原后查看mix函数实现。翻译过来还原函数非常简单，写一个java版本：public static String parseSipoIds(String enStr) { int b4 = 0; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; enStr.length(); i += 2) { if (b4 &gt; 255) b4 = 0; int c = Integer.parseInt(enStr.substring(i, i + 2), 16) ^ b4++; sb.append((char)c); } return sb.toString();}即这个span元素就是需要显示出来的span元素id集合，以逗号分隔。以前还爬过一个日本政府网站，防爬也是做得很过分，不过主要是配合服务器，每一个网页的url是动态变化的，且需要从最原始的网页经过一定的操作才能获得。流程复杂让人痛苦不堪，最后还是一路携带cookie，真的模拟人的操作流程走下来。具体也记不清了。最后吐槽一下，作者把还原算法写到jQuery.js里，也真是苦费心机。" }, { "title": "记一次线程局部存储与动态库引起的core", "url": "/posts/tls_so_coredump/", "categories": "c/c++", "tags": "TLS", "date": "2016-05-08 00:00:00 +0800", "snippet": "线上的服务退出时coredump，显示堆栈为：google一下发现有人遇到过，产生这个core的条件为： 使用TLS时注册了destructor (pthread_key_create)，这个回调函数会在线程退出时被调用 这个destructor符号位于.so中 在线程退出时，这个.so已经被dlclose我们的程序模型中，类似于一个Web App server，有一个线程池包装了IO处理，将请求派发给应用插件，处理完后回应给客户端。应用插件是一个.so，被动态载入(dlopen)，该.so由于实现需要引入了较多的第三方.so(隐式载入)。初步排查时，整个实现是没有问题的，线程池是在.so close前关闭的。没有线索，于是尝试找到该TLS是哪个模块引入的。通过gdb断pthread_key_create，以及不为空的destructor回调可以确定几个模块，但范围不够小，这些模块基本还是些基础模块，如zookeeper/mxml以及网络模块。多看了几个core，发现这个回调的偏移地址都是固定的960，如上图中的0x7f0f26c9f960。.so被载入时，基址是会变的，但偏移是不会变的，例如通过nm查看.so中的符号时：$nm lib/libsp_kit.so | grep loadConfig00000000002de170 T _ZN8sp_basic14SortRailConfig10loadConfigEPKc其中2de170中170是确定不变的。所以范围可以进一步缩小，destructor是pthread_key_create第二个参数，每次断点触发时查看rsi寄存器的值就可以确定，然后发现落在了mxml库里的符号：程序在启动时载入配置，触发了mxml在当前线程创建了TLS，这个线程是程序主线程。主线程当然是在.so被close后才退出的。如果这是问题，那应该很早前就会暴露。这是一个问题，后面会解释。但是问题排查到这个地方，又陷入了僵局。回头再看下core环境，可以从线程环境确定是哪个模块：core的线程31956和线程31955靠近，查看31955堆栈，发现是我们内部的rpc库(arpc)线程。那可以确定core的线程有可能和arpc有关系。函数在调用时，返回地址留在堆栈中，堆栈不一定会被其他内容覆盖，所以可以查看线程堆栈里的符号地址，大概确定是什么模块。x/200a $rsp-0x300查看core线程堆栈：可以看到其中确实有arpc库里的符号信息，综合线程号关系，基本可以确定core的线程是arpc线程。这个时候就突然灵关一闪，想起我们程序中有热切换机制。该机制会在收到arpc请求时，重新载入所有配置，而这个动作是发生在arpc开的线程里。查看相关代码，发现arpc资源释放确实是晚于.so的close的。于是做了下实验，程序开启后进行一次热切换，退出后果然必core。程序在生产环境时，只在业务上线时进行一次热切换，而每天又会被自动重启，重启后并不进行热切换，所以线上基本上没有暴露出来，只在部分灰度环境偶尔触发(连续两次业务上线)。回过头来，主线程问题怎么解释？google一圈发现，主线程退出，是不会调用TLS destructor的。参考这里，这里，以及这里。但是可以在主线程中显示调用pthread_exit来触发，普通线程会默认调用pthread_exit。完。" }, { "title": "Java中隔离容器的实现", "url": "/posts/java-lightweight-container/", "categories": "java", "tags": "class, loader", "date": "2015-09-05 00:00:00 +0800", "snippet": "Java中隔离容器用于隔离各个依赖库环境，解决Jar包冲突问题。问题应用App依赖库LibA和LibB，而LibA和LibB又同时依赖LibBase，而LibA和LibB都是其他团队开发的，其中LibA发布了一个重要的修复版本，但是依赖LibBase v2.0，而LibB还没有升级版本，LibBase还不是兼容的，那么此时升级就会面临困难。在生产环境中这种情况往往更恶劣，可能是好几层的间接依赖关系。隔离容器用于解决这种问题。它把LibA和LibB的环境完全隔离开来，LibBase即使类名完全相同也不互相冲突，使得LibA和LibB的升级互不影响。众所周知，Java中判定两个类是否相同，看的是类名和其对应的class loader，两者同时相同才表示相等。隔离容器正是利用这种特性实现的。KContainer这里我实现了一个demo，称为KContainer，源码见github kcontainer。这个container模仿了一些OSGI的东西，这里把LibA和LibB看成是两个bundle，bundle之间是互相隔离的，每个bundle有自己所依赖的第三方库，bundle之间的第三方库完全对外隐藏。bundle可以导出一些类给其他bundle用，bundle可以开启自己的服务。由于是个demo，我只实现关键的部分。KContainer的目录结构类似：.|-- bundle |-- test1 |-- test1.prop |-- classes |-- lib |-- a.jar |-- b.jar |-- test2 |-- test2.prop |-- classes|-- lib |-- kcontainer.jar |-- kcontainer.interface.jarbundle目录存放了所有会被自动载入的bundle。每一个bundle都有一个配置文件bundle-name.prop，用于描述自己导出哪些类，例如：init=com.codemacro.test.Bexport-class=com.codemacro.test.Export; com.codemacro.test.Export2init指定bundle启动时需要调用的类，用户可以在这个类里开启自己的服务；export-class描述需要导出的类列表。bundle之间的所有类都是隔离的，但export-class会被统一放置，作为所有bundle共享的类。后面会描述KContainer如何处理类加载问题，这也是隔离容器的主要内容。bundle依赖的类可以直接以*.class文件存放到classes目录，也可以作为*.jar放到lib目录。作为extra pratice，我还会把*.jar中的jar解压同时作为类加载的路径。KContainer本身可以作为一个framework被使用。为了示例，我写了一个入口类，加载启动完所有bundle后就退出了，这个仅作为例子，用不了生产。隔离的核心实现隔离的目的是分开各个bundle中的类。利用的语言特性包括： class的区分由class name和载入其的class loader共同决定 当在class A中使用了class B时，JVM默认会用class A的class loader去加载class B class loader中的双亲委托机制 URLClassLoader会从指定的目录及*.jar中加载类KContainer的主要任务，就是为bundle实现一个自定义的class loader。当KContainer加载一个bundle时，在处理其export-class或init时，都是需要加载bundle中的类的。在这之前，我给每一个bundle关联一个独立的BundleClassLoader。然后用这个class loader去加载bundle中的类，利用class loader传递特性，使得一个bundle中的所有类都是由其关联的class loader加载的，从而实现bundle之间类隔离效果。实现class loader时，是实现loadClass还是findClass？通过实现loadClass我们可以改变class loader的双亲委托模式，制定加载类的具体顺序。但我的目的仅仅是隔离bundle，想了下其实实现findClass就可以达成目的。关于loadClass和findClass的区别可以参考这里 (实现自己的类加载时，重写方法loadClass与findClass的区别)。简单来说，就是findClass只有在类确实找不到的情况下才会被调用，在此之前，loadClass默认都是走的双亲委托模式。BundleClassLoader派生于URLClassLoader，默认的parent class loader就是system class loader (app class loader)。这使得KContainer中的bundle类加载有三层选择：自己的class path；其他bundle共享的classes；jvm的class path。通过实现findClass，在默认路径都无法加载到类时，才尝试bundle共享的class，优先级最低。其实现大概为：public class BundleClassLoader extends URLClassLoader { public BundleClassLoader(File home, SharedClassList sharedClasses) { // getClassPath将bundle目录下的classes和各个jar作为class path传给URLClassLoader super(getClassPath(home)); this.sharedClasses = sharedClasses; } @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { logger.debug(\"try find class {}\", name); Class&lt;?&gt; claz = null; try { claz = super.findClass(name); } catch (ClassNotFoundException e) { claz = null; } if (claz != null) { logger.debug(\"load from class path for {}\", name); return claz; } claz = sharedClasses.get(name); if (claz != null) { logger.debug(\"load from shared class for {}\", name); return claz; } logger.warn(\"not found class {}\", name); throw new ClassNotFoundException(name); }}完整代码参看BundleClassLoader.java创建bundle时，会为其创建自己的class loader，并使用这个class loader来载入export-class和init-class： public static Bundle create(File home, String name, SharedClassList sharedClasses, BundleConf conf) { BundleClassLoader loader = new BundleClassLoader(home, sharedClasses); List&lt;String&gt; exports = conf.getExportClassNames(); if (exports != null) { logger.info(\"load exported classes for {}\", name); loadExports(loader, sharedClasses, exports); } return new Bundle(name, conf.getInitClassName(), loader); } private static void loadExports(ClassLoader loader, SharedClassList sharedClasses, List&lt;String&gt; exports) { for (String claz_name: exports) { try { Class&lt;?&gt; claz = loader.loadClass(claz_name); // 载入class sharedClasses.put(claz_name, claz); } catch (ClassNotFoundException e) { logger.warn(\"load class {} failed\", claz_name); } } }以上。扩展扩展的地方有很多，例如支持导出package，导出一个完整的jar。当然可能需要实现loadClass，以改变类加载的优先级，让共享类的优先级高于jvm class path的优先级。其他线程ContextClassLoader提到class loader，我们看下最常接触的几类： XX.class.getClassLoader，获取加载类XX的class loader Thread.currentThread().getContextClassLoader()，获取当前线程的ContextClassLoader ClassLoader.getSystemClassLoader()，获取system class loadersystem class loader的parent就是ext class loader，再上面就是bootstrap class loader了 (不是java类，实际获取不到)。默认情况下以上三个class loader都是一个：System.out.println(ClassLoader.getSystemClassLoader());System.out.println(Main.class.getClassLoader());System.out.println(Thread.currentThread().getContextClassLoader());Output:sun.misc.Launcher$AppClassLoader@157c2bdsun.misc.Launcher$AppClassLoader@157c2bdsun.misc.Launcher$AppClassLoader@157c2bd创建线程时，新的线程ContextClassLoader就是父线程的ContextClassLoader。在载入一个新的class时，推荐优先使用线程context class loader，例如框架Jodd中包装的。关于线程context class loader和Class.getClassLoader这里有个解释算是相对合理：ContextClassLoader浅析即，当你把一个对象A传递到另一个线程中，这个线程由对象B创建，A/B两个对象对应的类关联的class loader不同，在B的线程中调用A.some_method，some_method加载资源或类时，如果使用了Class.getClassLoader或Class.forName时，实际使用的是A的class loader，而这个行为可能不是预期的。这个时候就需要将代码改为Thread.currentThread().getContextClassLoader()。完。" }, { "title": "Java GC总结", "url": "/posts/java-gc-summary/", "categories": "java", "tags": "GC", "date": "2015-08-10 00:00:00 +0800", "snippet": "Java GC相关的文章有很多，本文只做概要性总结，主要内容来源于。对象存活性判定对象存活性判定用于确定一个对象是死是活，死掉的对象则需要被垃圾回收。主要包括的方法： 引用计数 可达性分析可达性分析的基本思想是： 通过一系列的称为”GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链项链时，则证明此对象是不可用的。在Java中有很多种类的对象可以作为GC Roots，例如类静态属性引用的对象。垃圾收集算法确定了哪些对象是需要回收之后，就可以运用各种垃圾收集算法收集这些对象，例如直接回收内存，或者回收并移动整理内存。主要包括： 标记清除(Mark-Sweep)算法：首先标记出需要回收的对象，然后统一回收被标记的对象 复制(Copying)算法：将可用内存分块，当一块内存用完后将存活对象复制到其他块，并统一回收不使用的块。Java中新生代对象一般使用该方法 标记整理(Mark-Compact)算法：基本同标记清除，不同的是回收时是把可用对象进行移动，以避免内存碎片问题 分代收集，将内存分区域，不同区域采用不同的算法，例如Java中的新生代及老年代如上，Java Hotspot虚拟机实现中将堆内存分为3大区域，即新生代、老年代、永久代。新生代中又分了eden、survivor0及survivor1，采用复制算法；老年代则采用标记清除及标记整理；永久代存放加载的类，类似于代码段，但同样会发生GC。垃圾收集器垃圾收集算法在实现时会略有不同，不同的实现称为垃圾收集器。不同的垃圾收集器适用的范围还不一样，有些收集器仅能用于新生代，有些用于老年代，有些新生代老年代都可以被使用。垃圾收集器可通过JVM启动参数指定。上图中展示了新生代（年轻代）和老年代可用的各种垃圾收集器，图中的连线表示两种收集器可以配合使用。 Serial收集器，单线程收集，复制算法 ParNew收集器，Serial收集器的多线程版本 Parallel Scavenge收集器，复制算法，吞吐量优先的收集器，更高效率地利用CPU时间，适合用于服务器程序 Serial Old收集器，单线程收集，标记整理算法 Parallel Old收集器，标记整理算法，Parallel Scavenge收集器的老年代版本 CMS(Concurrent Mark Sweep)收集器，标记清除算法，以获取最短停顿时间为目标的收集器 G1收集器，较新的收集器实现JVM有些参数组合了各种收集器，例如： UseConcMarkSweepGC：使用ParNew + CMS + Serial Old收集器 UseParallelGC，运行在server模式下的默认值，使用Parallel Scavenge + Serial Old 收集器GC日志生产服务器一般会配置GC日志，以在故障时能够分析问题所在，一般的应用可配置以下JVM参数：-XX:+UseParallelGC -XX:+DisableExplicitGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:./logs/gc.log 输出日志类似：1456772.057: [GC [PSYoungGen: 33824K-&gt;96K(33920K)] 53841K-&gt;20113K(102208K), 0.0025050 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]1456863.534: [GC [PSYoungGen: 33824K-&gt;96K(33920K)] 53841K-&gt;20113K(102208K), 0.0020050 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]1456962.061: [GC [PSYoungGen: 33824K-&gt;128K(33920K)] 53841K-&gt;20145K(102208K), 0.0014150 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 1456772.057，自JVM启动后的时间值 GC 表示本次进行的是一次minor GC，即年轻代中的GC PSYoungGen 垃圾收集器类型，这里是Parallel Scavenge 33824K-&gt;96K(33920K)，收集前后新生代大小，33920K为新生代总大小(eden+ 1 survivor) 53841K-&gt;20113K(102208K)，堆总大小及GC前后大小 0.0025050 secs，GC时停顿时间常见策略JVM GC相关的有一些策略值得注意： 对象优先在eden分配，当回收时（Eden区可用内存不够），将Eden和当前Survivor还存活着的对象一次性复制到另外一块Survivor，最后清理Eden和刚才用过的Survivor。这个过程称为一次MinorGC，每次MinorGC就会增加活着对象的年龄，当年龄超过某值(-XX:MaxTenuringThreashold)时，就会被转移到老年代(Tenured)。老年代发生GC时被称为FullGC 每一次发生MinorGC而存活下来的对象其年龄都会加1，较老的对象会进入老年代 当分配大对象(&gt; PretenureSizeThreshold)时，其就会直接进入老年代 当年轻代(Eden+Survivor)不足以容纳存活对象时，这些对象会被全部放入老年代(分配担保机制)" }, { "title": "写了一个分布式名字服务JCM", "url": "/posts/jcm/", "categories": "java", "tags": "jcm", "date": "2015-07-04 00:00:00 +0800", "snippet": "之前在公司里维护了一个名字服务，这个名字服务日常管理了近4000台机器，有4000个左右的客户端连接上来获取机器信息，由于其基本是一个单点服务，所以某些模块接近瓶颈。后来倒是有重构计划，详细设计做了，代码都写了一部分，结果由于某些原因重构就被终止了。JCM是我业余时间用Java重写的一个版本，功能上目前只实现了基础功能。由于它是个完全分布式的架构，所以理论上可以横向扩展，大大增强系统的服务能力。名字服务在分布式系统中，某个服务为了提升整体服务能力，通常部署了很多实例。这里我把这些提供相同服务的实例统称为集群(cluster)，每个实例称为一个节点(Node)。一个应用可能会使用很多cluster，每次访问一个cluster时，就通过名字服务获取该cluster下一个可用的node。那么，名字服务至少需要包含的功能： 根据cluster名字获取可用的node 对管理的所有cluster下的所有node进行健康度的检测，以保证始终返回可用的node有些名字服务仅对node管理，不参与应用与node间的通信，而有些则可能作为应用与node间的通信转发器。虽然名字服务功能简单，但是要做一个分布式的名字服务还是比较复杂的，因为数据一旦分布式了，就会存在同步、一致性问题的考虑等。What’s JCMJCM围绕前面说的名字服务基础功能实现。包含的功能： 管理cluster到node的映射 分布式架构，可水平扩展以实现管理10,000个node的能力，足以管理一般公司的后台服务集群 对每个node进行健康检查，健康检查可基于HTTP协议层的检测或TCP连接检测 持久化cluster/node数据，通过zookeeper保证数据一致性 提供JSON HTTP API管理cluster/node数据，后续可提供Web管理系统 以库的形式提供与server的交互，库本身提供各种负载均衡策略，保证对一个cluster下node的访问达到负载均衡项目地址git jcmJCM主要包含两部分： jcm.server，JCM名字服务，需要连接zookeeper以持久化数据 jcm.subscriber，客户端库，负责与jcm.server交互，提供包装了负载均衡的API给应用使用架构基于JCM的系统整体架构如下：cluster本身是不需要依赖JCM的，要通过JCM使用这些cluster，只需要通过JCM HTTP API注册这些cluster到jcm.server上。要通过jcm.server使用这些cluster，则是通过jcm.subscriber来完成。使用可参考git READMe.md需要jre1.7+ 启动zookeeper 下载jcm.server git jcm.server-0.1.0.jar 在jcm.server-0.1.0.jar目录下建立config/application.properties文件进行配置，参考config/application.properties 启动jcm.server java -jar jcm.server-0.1.0.jar 注册需要管理的集群，参考cluster描述：doc/cluster_sample.json，通过HTTP API注册： curl -i -X POST http://10.181.97.106:8080/c -H \"Content-Type:application/json\" --data-binary @./doc/cluster_sample.json 部署好了jcm.server，并注册了cluster后，就可以通过jcm.subscriber使用：// 传入需要使用的集群名hello9/hello，以及传入jcm.server地址，可以多个：127.0.0.1:8080Subscriber subscriber = new Subscriber( Arrays.asList(\"127.0.0.1:8080\"), Arrays.asList(\"hello9\", \"hello\"));// 使用轮询负载均衡策略RRAllocator rr = new RRAllocator();subscriber.addListener(rr);subscriber.startup();for (int i = 0; i &lt; 2; ++i) { // rr.alloc 根据cluster名字获取可用的node System.out.println(rr.alloc(\"hello9\", ProtoType.HTTP));}subscriber.shutdown();JCM实现JCM目前的实现比较简单，参考模块图： model，即cluster/node这些数据结构的描述，同时被jcm.server和jcm.subscriber依赖 storage，持久化数据到zookeeper，同时包含jcm.server实例之间的数据同步 health check，健康检查模块，对各个node进行健康检查以上模块都不依赖Spring，基于以上模块又有： http api，使用spring-mvc，包装了一些JSON HTTP API Application，基于spring-boot，将各个基础模块组装起来，提供standalone的模式启动，不用部署到tomcat之类的servlet容器中jcm.subscriber的实现更简单，主要是负责与jcm.server进行通信，以更新自己当前的model层数据，同时提供各种负载均衡策略接口： subscriber，与jcm.server通信，定期增量拉取数据 node allocator，通过listener方式从subscriber中获取数据，同时实现各种负载均衡策略，对外统一提供alloc node的接口接下来看看关键功能的实现数据同步既然jcm.server是分布式的，每一个jcm.server instance(实例)都是支持数据读和写的，那么当jcm.server管理着一堆cluster上万个node时，每一个instance是如何进行数据同步的？jcm.server中的数据主要有两类： cluster本身的数据，包括cluster/node的描述，例如cluster name、node IP、及其他附属数据 node健康检查的数据对于cluster数据，因为cluster对node的管理是一个两层的树状结构，而对cluster有增删node的操作，所以并不能在每一个instance上都提供真正的数据写入，这样会导致数据丢失。假设同一时刻在instance A和instance B上同时对cluster c1添加节点N1和N2，那么instance A写入c1(N1)，而instance B还没等到数据同步就写入c1(N2)，那么c1(N1)就被覆盖为c1(N2)，从而导致添加的节点N1丢失。所以，jcm.server instance是分为leader和follower的，真正的写入操作只有leader进行，follower收到写操作请求时转发给leader。leader写数据优先更新内存中的数据再写入zookeeper，内存中的数据更新当然是需要加锁互斥的，从而保证数据的正确性。leader和follower是如何确定角色的？这个很简单，标准的利用zookeeper来进行主从选举的实现。jcm.server instance数据间的同步是基于zookeeper watch机制的。这个可以算做是一个JCM的一个瓶颈，每一个instance都会作为一个watch，使得实际上jcm.server并不能无限水平扩展，扩展到一定程度后，watch的效率就可能不足以满足性能了，参考zookeeper节点数与watch的性能测试 (那个时候我就在考虑对我们系统的重构了) 。jcm.server中对node健康检查的数据采用同样的同步机制，但node健康检查数据是每一个instance都会写入的，下面看看jcm.server是如何通过分布式架构来分担压力的。健康检查jcm.server的另一个主要功能的是对node的健康检查，jcm.server集群可以管理几万的node，既然已经是分布式了，那么显然是要把node均分到多个instance的。这里我是以cluster来分配的，方法就是简单的使用一致性哈希。通过一致性哈希，决定一个cluster是否属于某个instance负责。每个instance都有一个server spec，也就是该instance对外提供服务的地址(IP+port)，这样在任何一个instance上，它看到的所有instance server spec都是相同的，从而保证在每一个instance上计算cluster的分配得到的结果都是一致的。健康检查按cluster划分，可以简化数据的写冲突问题，在正常情况下，每个instance写入的健康检查结果都是不同的。健康检查一般以1秒的频率进行，jcm.server做了优化，当检查结果和上一次一样时，并不写入zookeeper。写入的数据包含了node的完整key (IP+Port+Spec)，这样可以简化很多地方的数据同步问题，但会增加写入数据的大小，写入数据的大小是会影响zookeeper的性能的，所以这里简单地对数据进行了压缩。健康检查是可以支持多种检查实现的，目前只实现了HTTP协议层的检查。健康检查自身是单个线程，在该线程中基于异步HTTP库，发起异步请求，实际的请求在其他线程中发出。jcm.subscriber通信jcm.subscriber与jcm.server通信，主要是为了获取最新的cluster数据。subscriber初始化时会拿到一个jcm.server instance的地址列表，访问时使用轮询策略以平衡jcm.server在处理请求时的负载。subscriber每秒都会请求一次数据，请求中描述了本次请求想获取哪些cluster数据，同时携带一个cluster的version。每次cluster在server变更时，version就变更（时间戳）。server回复请求时，如果version已最新，只需要回复node的状态。subscriber可以拿到所有状态的node，后面可以考虑只拿正常状态的node，进一步减少数据大小。压力测试目前只对健康检查部分做了压测，详细参考test/benchmark.md。在A7服务器上测试，发现写zookeeper及zookeeper的watch足以满足要求，jcm.server发起的HTTP请求是主要的性能热点，单jcm.server instance大概可以承载20000个node的健康监测。网络带宽：Time ---------------------traffic--------------------Time bytin bytout pktin pktout pkterr pktdrp01/07/15-21:30:48 3.2M 4.1M 33.5K 34.4K 0.00 0.0001/07/15-21:30:50 3.3M 4.2M 33.7K 35.9K 0.00 0.0001/07/15-21:30:52 2.8M 4.1M 32.6K 41.6K 0.00 0.00CPU，通过jstack查看主要的CPU消耗在HTTP库实现层，以及健康检查线程： PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND13301 admin 20 0 13.1g 1.1g 12m R 76.6 2.3 2:40.74 java httpchecker13300 admin 20 0 13.1g 1.1g 12m S 72.9 2.3 0:48.31 java13275 admin 20 0 13.1g 1.1g 12m S 20.1 2.3 0:18.49 java代码中增加了些状态监控：checker HttpChecker stat count 20 avg check cost(ms) 542.05, avg flush cost(ms) 41.35表示平均每次检查耗时542毫秒，写数据因为开启了cache没有参考价值。虽然还可以从我自己的代码中做不少优化，但既然单机可以承载20000个节点的检测，一般的应用远远足够了。总结名字服务在分布式系统中虽然是基础服务，但往往承担了非常重要的角色，数据同步出现错误、节点状态出现瞬时的错误，都可能对整套系统造成较大影响，业务上出现较大故障。所以名字服务的健壮性、可用性非常重要。实现中需要考虑很多异常情况，包括网络不稳定、应用层的错误等。为了提高足够的可用性，一般还会加多层的数据cache，例如subscriber端的本地cache，server端的本地cache，以保证在任何情况下都不会影响应用层的服务。" }, { "title": "基于servlet实现一个web框架", "url": "/posts/servlet-web-framework/", "categories": "java", "tags": "servlet", "date": "2015-06-07 00:00:00 +0800", "snippet": "servlet作为一个web规范，其本身就算做一个web开发框架，但是其web action (响应某个URI的实现)的实现都是基于类的，不是很方便，并且3.0之前的版本还必须通过web.xml配置来增加新的action。servlet中有一个filter的功能，可以配置所有URI的功能都经过filter。我们可以基于filter的功能来实现一个简单的web框架。在这个框架中，主要改进URI action的映射，就像play framework中route的配置：GET /hello com.codemacro.webdemo.test.TestController.helloGET /route com.codemacro.webdemo.test.TestController.routePOST /hello com.codemacro.webdemo.test.TestController.sayHello即把某个URI映射到类接口级别。基于servlet实现web框架的好处不仅实现简单，还能运行在所有支持servlet容器规范的web server上，例如Tomcat、Jetty。本文提到的web framework demo可以从我的github 上取得：servlet-web-framework-demo功能这个web framework URI action部分（或者说URI routing）如同前面描述，action的编写如：public class TestController extends BaseController { // 返回字符串 public Result index() { return ok(\"hello world\"); } // HTTP 404 public Result code404() { return status(404, \"not found\"); } // 使用JSP模板渲染 public Result template() { String[] langs = new String[] {\"c++\", \"java\", \"python\"}; return ok(jsp(\"index.jsp\") .put(\"name\", \"kevin\") .put(\"langs\", langs) ); }}有了action之后，配置route文件映射URI即可：GET /index com.codemacro.webdemo.test.TestController.indexGET /404 com.codemacro.webdemo.test.TestController.code404GET /index.jsp com.codemacro.webdemo.test.TestController.template然后配置web.xml，增加一个filter：&lt;filter&gt; &lt;filter-name&gt;MyWebFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.codemacro.webdemo.MyServletFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;MyWebFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;最后以war的形式部署到Jetty webapps下即可运行。想想下次要再找个什么lightweight Java web framework，直接用这个demo就够了。接下来讲讲一些关键部分的实现。servlet basic基于servlet开发的话，引入servlet api是必须的：&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;servlet filter的接口包含：public class MyServletFilter implements Filter { // web app启动时调用一次，可用于web框架初始化 public void init(FilterConfig conf) throws ServletException { } // 满足filter url-pattern时就会调用；req/res分别对应HTTP请求和回应 public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException { } public void destroy() { }}init接口可用于启动时载入routes配置文件，并建立URI到action的映射。action managerActionManager负责启动时载入routes配置，建立URI到action的映射。一个URI包含了HTTP method和URI String，例如GET /index。action既然映射到了类接口上，那么可以在启动时就同过Java反射找到对应的类及接口。简单起见，每次收到URI的请求时，就创建这个类对应的对象，然后调用映射的接口即可。// 例如：registerAction(\"com.codemacro.webdemo.test.TestController\", \"index\", \"/index\", \"GET\");public void registerAction(String clazName, String methodName, String uri, String method) { try { uri = \"/\" + appName + uri; // 载入对应的class Class&lt;? extends BaseController&gt; clazz = (Class&lt;? extends BaseController&gt;) loadClass(clazName); // 取得对应的接口 Method m = clazz.getMethod(methodName, (Class&lt;?&gt;[])null); // 接口要求必须返回Result if (m.getReturnType() != Result.class) { throw new RuntimeException(\"action method return type mismatch: \" + uri); } ActionKey k = new ActionKey(uri, getMethod(method)); ActionValue v = new ActionValue(clazz, m); logger.debug(\"register action {} {} {} {}\", clazName, methodName, uri, method); // 建立映射 actions.put(k, v); } catch (Exception e) { throw new RuntimeException(\"registerAction failed: \" + uri, e); }}controller都要求派生于BaseController，这样才可以利用BaseController更方便地获取请求数据之类，例如query string/cookie 等。收到请求时，就需要根据请求的HTTP Method和URI string取得之前建立的映射，并调用之：public boolean invoke(HttpServletRequest req, HttpServletResponse resp) throws IOException { String uri = req.getRequestURI(); String method = req.getMethod().toUpperCase(); try { // 取得之前建立的映射，Map查找 ActionValue v = getAction(uri, method); // 创建新的controller对象 BaseController ctl = (BaseController) v.clazz.newInstance(); ctl.init(req, resp, this); logger.debug(\"invoke action {}\", uri); // 调用绑定的接口 Result result = (Result) v.method.invoke(ctl, (Object[]) null); // 渲染结果 result.render(); } catch (Exception e) { ... }}结果渲染结果渲染无非就是把框架用户返回的结果渲染为字符串，写进HttpServletResponse。这个渲染过程可以是直接的Object.toString，或者经过模板引擎渲染，或者格式化为JSON。通过实现具体的Result类，可以扩展不同的渲染方式，例如最基础的Result就是调用返回对象的toString：public class Result { public void render() throws IOException, ServletException { PrintWriter writer = response.getWriter(); // result是controller action里返回的 writer.append(result.toString()); writer.close(); }}为了简单，不引入第三方库，可以直接通过JSP来完成。JSP本身在servlet容器中就会被编译成一个servlet对象。public class JSPResult extends Result { ... @Override public void render() throws IOException, ServletException { // 传入一些对象到模板中 for (Map.Entry&lt;String, Object&gt; entry : content.entrySet()) { request.setAttribute(entry.getKey(), entry.getValue()); } // 委托给JSP来完成渲染 request.getRequestDispatcher(file).forward(request, response); }}JSP中可以使用传统的scriptlets表达式，也可以使用新的EL方式，例如：&lt;%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\"%&gt;&lt;h4&gt;By EL&lt;/h4&gt;&lt;c:forEach var=\"lang\" items=\"${langs}\"&gt; &lt;span&gt;${lang}&lt;/span&gt;|&lt;/c:forEach&gt;&lt;% String[] langs = (String[]) request.getAttribute(\"langs\"); %&gt;&lt;% if (langs != null) { %&gt;&lt;% for (String lang : langs) { %&gt; &lt;span&gt;&lt;%= lang %&gt;&lt;/span&gt;|&lt;% } } %&gt;使用EL的话需要引入&lt;%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\"%&gt;BaseControllerBaseController是一种template pattern实现，其包装了一些方便的接口给具体的controller使用，例如：public class BaseController { // 取得/index?name=kevin中的name参数值 protected String getQueryString(String key) { return request.getParameter(key); } protected Result status(int code, String text) { response.setStatus(code); return new Result(response, text); } // 默认是HTTP 200 protected Result ok(Object obj) { return new Result(response, obj); } protected Result ok(Result result) { return result; } protected JSPResult jsp(String file) { return new JSPResult(request, response, file, actionMgr); }}Reverse routingReverse routing指的是在开发web过程中，要引入某个URL时，我们不是直接写这个URL字符串，而是写其映射的接口，以使代码更易维护（因为URL可能会随着项目进展而改变）。并且，servlet app部署后URL会带上这个app的名字前缀，例如/web-demo/index中的/web-demo。在模板文件中，例如要链接到其他URI，更好的方式当然是直接写/index。这里的实现比较丑陋，还是基于字符串的形式，例如：&lt;a href='&lt;route:reverse action=\"com.codemacro.webdemo.test.TestController.hello\" name=\"kevin\"/&gt;'&gt;index&lt;/a&gt;通过自定义一个EL function reverse来实现。这里需要引入一个JSP的库：&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;首先实现一个SimpleTagSupport，为了支持?name=kevin这种动态参数，还需要implements DynamicAttributes：public class JSPRouteTag extends SimpleTagSupport implements DynamicAttributes { @Override // 输出最终的URL public void doTag() throws IOException { JspContext context = getJspContext(); ActionManager actionMgr = (ActionManager) context.findAttribute(ACTION_MGR); JspWriter out = context.getOut(); String uri = actionMgr.getReverseAction(action, attrMap); out.println(uri); } @Override // name=\"kevin\" 时调用 public void setDynamicAttribute(String uri, String name, Object value) throws JspException { attrMap.put(name, value); } // `action=\"xxx\"` 时会调用`setAction` public void setAction(String action) { this.action = action; }}为了访问到ActionManager，这里是通过写到Request context中实现的，相当hack。public JSPResult(HttpServletRequest req, HttpServletResponse resp, String file, ActionManager actionMgr) { super(resp, null); .. put(JSPRouteTag.ACTION_MGR, actionMgr);}第二步增加一个描述这个新tag的文件 WEB-INF/route_tag.tld：&lt;taglib&gt; &lt;tlibversion&gt;1.0&lt;/tlibversion&gt; &lt;jspversion&gt;1.1&lt;/jspversion&gt; &lt;shortname&gt;URLRouteTags&lt;/shortname&gt; &lt;uri&gt;/myweb-router&lt;/uri&gt; &lt;info&gt;&lt;/info&gt; &lt;tag&gt; &lt;name&gt;reverse&lt;/name&gt; &lt;tagclass&gt;com.codemacro.webdemo.result.JSPRouteTag&lt;/tagclass&gt; &lt;bodycontent&gt;&lt;/bodycontent&gt; &lt;info&gt;&lt;/info&gt; &lt;attribute&gt; &lt;name&gt;action&lt;/name&gt; &lt;required&gt;true&lt;/required&gt; &lt;/attribute&gt; &lt;dynamic-attributes&gt;true&lt;/dynamic-attributes&gt; &lt;/tag&gt;&lt;/taglib&gt;最后在需要使用的JSP中引入这个自定义tag：&lt;%@ taglib prefix=\"route\" uri=\"/myweb-router\" %&gt;参考资料 Servlet生命周期与工作原理 JSP/Servlet工作原理 EL表达式 使用Servlet、JSP开发Web程序 Java Web笔记 – Servlet中的Filter过滤器的介绍和使用 编写过滤器 实现一个简单的Servlet容器" }, { "title": "Java中的反射及Bean容器的实现", "url": "/posts/java-refect-ioc/", "categories": "java", "tags": "refect, bean, ioc", "date": "2015-05-31 00:00:00 +0800", "snippet": "编程语言中的反射(Refection)指的是可以在程序运行期动态加载一个类。与之相关的是自省(Introspection)，这个指的是程序自己可以获取一个类型的描述信息，例如获取一个类的所有接口定义、一个接口的所有形参。当编程语言有了这些语言特性之后，可以在很大程度上解决代码耦合问题，所以在Java的世界里，可以看到很多库/框架使用了反射技术。类似Spring的Bean容器实现就是大量运用了反射机制。Bean容器维护了一些Bean对象，简单来说就是一些普通对象。Bean容器可以根据配置创建这些对象，创建时如果这些对象依赖了其他对象，Bean容器还会负责将依赖的对象注入到目标对象中，也就是所谓的依赖注入(dependence injection)。放在模块设计中，又衍生出控制反转(IoC, Inverse of Control)概念，用于描述应用程序在使用一个框架时，不是框架来控制/限制应用程序的架构模式，而是由应用程序来控制框架。本文就简单描述下Bean容器是如何使用反射来实现的，最终代码参考github ioc-sample类的动态加载可以简单地使用Class.forName，传入某个class的完整名：public Class&lt;?&gt; loadClass(String fullName) throws ClassNotFoundException { return Class.forName(fullName);}类的加载涉及到class loader，这块内容是可以进一步深化的。加载了类之后就可以创建出类的实例，但还没有完成依赖注入的功能：Class&lt;?&gt; c = loadClass(\"com.codemacro.bean.test.Test1\");Object o = c.newInstance();通过set接口注入我们的类可以包含set接口，用于设置某个成员：public class Test2 { public Test1 test1; public void setTest1(Test1 t) { test1 = t; }}那么可以通过setXXX接口将Test1注入到Test2中：// props指定哪些成员需要注入，例如{\"Test1\", \"test1\"}，Test1指的是setTest1，test1指的是bean名字public Object buildWithSetters(String name, Class&lt;?&gt; c, Map&lt;String, String&gt; props) { try { // ClassSetMethods 类获取Class&lt;?&gt;中所有setXX这种接口 ClassSetMethods setMethods = new ClassSetMethods(c); Object obj = c.newInstance(); for (Map.Entry&lt;String, String&gt; entrys : props.entrySet()) { String pname = entrys.getKey(); String beanName = entrys.getValue(); // 取得setXXX这个Method Method m = setMethods.get(pname); Object val = getBean(beanName); // 调用 m.invoke(obj, val); } beans.put(name, obj); return obj; } catch (Exception e) { throw new RuntimeException(\"build bean failed\", e); }} ClassSetMethod自省出一个Class中所有的setXXX(xx)接口：public ClassSetMethods(Class&lt;?&gt; c) { Method[] methods = c.getMethods(); for (Method m : methods) { String mname = m.getName(); Class&lt;?&gt;[] ptypes = m.getParameterTypes(); if (mname.startsWith(\"set\") &amp;&amp; ptypes.length == 1 &amp;&amp; m.getReturnType() == Void.TYPE) { String name = mname.substring(\"set\".length()); this.methods.put(name, m); } }}以上就可以看出Java中的自省能力，例如Class&lt;?&gt;.getMethods、Method.getReturnType、Method.getParameterTypes。通过构造函数注入类似于Spring中的：&lt;bean id=\"exampleBean\" class=\"examples.ExampleBean\"&gt; &lt;constructor-arg type=\"int\" value=\"2001\"/&gt; &lt;constructor-arg type=\"java.lang.String\" value=\"Zara\"/&gt;&lt;/bean&gt;可以将依赖的Bean通过构造函数参数注入到目标对象中：List&lt;String&gt; params = new ArrayList&lt;String&gt;();params.add(\"test1\");bf.buildWithConstructor(\"test2\", Test2.class, params);其实现：public Object buildWithConstructor(String name, Class&lt;?&gt; c, List&lt;String&gt; beanNames) { try { Constructor&lt;?&gt;[] ctors = c.getConstructors(); // 取得Class构造函数列表 assert ctors.length == 1; Constructor&lt;?&gt; cc = ctors[0]; Class&lt;?&gt;[] ptypes = cc.getParameterTypes(); // 取得构造函数参数类型列表 assert ptypes.length == beans.size(); Object[] args = new Object[ptypes.length]; for (int i = 0; i &lt; beanNames.size(); ++i) { args[i] = getBean(beanNames.get(i)); // 构造调用构造函数的实参列表 } Object obj = cc.newInstance(args); // 通过构造函数创建对象 beans.put(name, obj); return obj; } catch (Exception e) { throw new RuntimeException(\"build bean failed\", e); }}这个接口的使用约定beanNames保存的是bean名称，并与构造函数参数一一对应。通过注解注入我们可以通过注解标注某个数据成员是需要被自动注入的。我这里简单地获取注解标注的成员类型，找到该类型对应的Bean作为注入对象。当然复杂点还可以指定要注入Bean的名字，或自动查找类型的派生类实现。一个空的注解即可：@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)public @interface Inject {}实现：public Object buildWithInject(String name, Class&lt;?&gt; c) { try { Object obj = c.newInstance(); Field[] fields = c.getDeclaredFields(); // 获取该类所有定义的成员 for (Field f :fields) { Inject inject = f.getAnnotation(Inject.class); // 获取数据成员的注解 if (inject != null) { // 如果被Inject注解标注 Object bean = getBeanByType(f.getType()); // 根据成员的类型找到对应的Bean f.set(obj, bean); // 注入 } else { throw new RuntimeException(\"not found bean \" + f.getName()); } } beans.put(name, obj); return obj; } catch (Exception e) { throw new RuntimeException(\"build bean failed\", e); }}getBeanByType就是根据Class匹配所有的Bean。使用时：public class Test2 { @Inject public Test1 test1; ...}完。" }, { "title": "Drill中实现HTTP storage plugin", "url": "/posts/drill-http-plugin/", "categories": "java", "tags": "drill", "date": "2015-05-30 00:00:00 +0800", "snippet": "Apache Drill可用于大数据的实时分析，引用一段介绍： 受到Google Dremel启发，Apache的Drill项目是对大数据集进行交互式分析的分布式系统。Drill并不会试图取代已有的大数据批处理框架（Big Data batch processing framework），如Hadoop MapReduce或流处理框架（stream processing framework），如S4和Storm。相反，它是要填充现有空白的——对大数据集的实时交互式处理简单来说，Drill可接收SQL查询语句，然后后端从多个数据源例如HDFS、MongoDB等获取数据并分析产出分析结果。在一次分析中，它可以汇集多个数据源的数据。而且基于分布式的架构，可以支持秒级查询。Drill在架构上是比较灵活的，它的前端可以不一定是SQL查询语言，后端数据源也可以接入Storage plugin来支持其他数据来源。这里我就实现了一个从HTTP服务获取数据的Storage plugin demo。这个demo可以接入基于GET请求，返回JSON格式的HTTP服务。源码可从我的Github获取：drill-storage-http例子包括：select name, length from http.`/e/api:search` where $p=2 and $q='avi'select name, length from http.`/e/api:search?q=avi&amp;p=2` where length &gt; 0 实现要实现一个自己的storage plugin，目前Drill这方面文档几乎没有，只能从已有的其他storage plugin源码入手，例如mongodb的，参考Drill子项目drill-mongo-storage。实现的storage plugin打包为jar放到jars目录，Drill启动时会自动载入，然后web上配置指定类型即可。主要需要实现的类包括：AbstractStoragePluginStoragePluginConfigSchemaFactoryBatchCreatorAbstractRecordReaderAbstractGroupScan &lt;!-- more --&gt; ### AbstraceStoragePluginStoragePluginConfig用于配置plugin，例如：{ \"type\" : \"http\", \"connection\" : \"http://xxx.com:8000\", \"resultKey\" : \"results\", \"enabled\" : true}它必须是可JSON序列化/反序列化的，Drill会把storage配置存储到/tmp/drill/sys.storage_plugins中，例如windows下D:\\tmp\\drill\\sys.storage_plugins。AbstractStoragePlugin 是plugin的主类，它必须配合StoragePluginConfig，实现这个类时，构造函数必须遵循参数约定，例如：public HttpStoragePlugin(HttpStoragePluginConfig httpConfig, DrillbitContext context, String name)Drill启动时会自动扫描AbstractStoragePlugin实现类(StoragePluginRegistry)，并建立StoragePluginConfig.class到AbstractStoragePlugin constructor的映射。AbstractStoragePlugin需要实现的接口包括： // 相应地需要实现AbstraceGroupScan // selection包含了database name和table name，可用可不用 public AbstractGroupScan getPhysicalScan(String userName, JSONOptions selection) // 注册schema public void registerSchemas(SchemaConfig schemaConfig, SchemaPlus parent) throws IOException // StoragePluginOptimizerRule 用于优化Drill生成的plan，可实现也可不实现 public Set&lt;StoragePluginOptimizerRule&gt; getOptimizerRules() Drill中的schema用于描述一个database，以及处理table之类的事务，必须要实现，否则任意一个SQL查询都会被认为是找不到对应的table。AbstraceGroupScan用于一次查询中提供信息，例如查询哪些columns。Drill在查询时，有一种中间数据结构(基于JSON)叫Plan，其中又分为Logic Plan和Physical Plan。Logic Plan是第一层中间结构，用于完整表达一次查询，是SQL或其他前端查询语言转换后的中间结构。完了后还要被转换为Physical Plan，又称为Exectuion Plan，这个Plan是被优化后的Plan，可用于与数据源交互进行真正的查询。StoragePluginOptimizerRule就是用于优化Physical Plan的。这些Plan最终对应的结构有点类似于语法树，毕竟SQL也可以被认为是一种程序语言。StoragePluginOptimizerRule可以被理解为改写这些语法树的。例如Mongo storage plugin就实现了这个类，它会把where中的filter转换为mongodb自己的filter(如{‘$gt’: 2})，从而优化查询。这里又牵扯出Apache的另一个项目：calcite，前身就是OptiQ。Drill中整个关于SQL的执行，主要是依靠这个项目。要玩转Plan的优化是比较难的，也是因为文档欠缺，相关代码较多。SchemaFactoryregisterSchemas主要还是调用SchemaFactory.registerSchemas接口。Drill中的Schema是一种树状结构，所以可以看到registerSchemas实际就是往parent中添加child： public void registerSchemas(SchemaConfig schemaConfig, SchemaPlus parent) throws IOException { HttpSchema schema = new HttpSchema(schemaName); parent.add(schema.getName(), schema); }HttpSchema派生于AbstractSchema，主要需要实现接口getTable，因为我这个http storage plugin中的table实际就是传给HTTP service的query，所以table是动态的，所以getTable的实现比较简单： public Table getTable(String tableName) { // table name can be any of string HttpScanSpec spec = new HttpScanSpec(tableName); // will be pass to getPhysicalScan return new DynamicDrillTable(plugin, schemaName, null, spec); }这里的HttpScanSpec用于保存查询中的一些参数，例如这里保存了table name，也就是HTTP service的query，例如/e/api:search?q=avi&amp;p=2。它会被传到AbstraceStoragePlugin.getPhysicalScan中的JSONOptions： public AbstractGroupScan getPhysicalScan(String userName, JSONOptions selection) throws IOException { HttpScanSpec spec = selection.getListWith(new ObjectMapper(), new TypeReference&lt;HttpScanSpec&gt;() {}); return new HttpGroupScan(userName, httpConfig, spec); }HttpGroupScan后面会看到用处。AbstractRecordReaderAbstractRecordReader负责真正地读取数据并返回给Drill。BatchCreator则是用于创建AbstractRecordReader。 public class HttpScanBatchCreator implements BatchCreator&lt;HttpSubScan&gt; { @Override public CloseableRecordBatch getBatch(FragmentContext context, HttpSubScan config, List&lt;RecordBatch&gt; children) throws ExecutionSetupException { List&lt;RecordReader&gt; readers = Lists.newArrayList(); readers.add(new HttpRecordReader(context, config)); return new ScanBatch(config, context, readers.iterator()); } }既然AbstractRecordReader负责真正读取数据，那么它肯定是需要知道传给HTTP service的query的，但这个query最早是在HttpScanSpec中，然后传给了HttpGroupScan，所以马上会看到HttpGroupScan又把参数信息传给了HttpSubScan。Drill也会自动扫描BatchCreator的实现类，所以这里就不用关心HttpScanBatchCreator的来历了。HttpSubScan的实现比较简单，主要是用来存储HttpScanSpec的：public class HttpSubScan extends AbstractBase implements SubScan // 需要实现SubScan回到HttpGroupScan，必须实现的接口： public SubScan getSpecificScan(int minorFragmentId) { // pass to HttpScanBatchCreator return new HttpSubScan(config, scanSpec); // 最终会被传递到HttpScanBatchCreator.getBatch接口 }最终query被传递到HttpRecordReader，该类需要实现的接口包括：setup和next，有点类似于迭代器。setup中查询出数据，然后next中转换数据给Drill。转换给Drill时可以使用到VectorContainerWriter和JsonReader。这里也就是Drill中传说的vector数据格式，也就是列存储数据。总结以上，就包含了plugin本身的创建，及查询中query的传递。查询中类似select titile, name 中的columns会被传递到HttpGroupScan.clone接口，只不过我这里并不关注。实现了这些，就可以通过Drill查询HTTP service中的数据了。而select * from xx where xx中的where filter，Drill自己会对查询出来的数据做过滤。如果要像mongo plugin中构造mongodb的filter，则需要实现StoragePluginOptimizerRule。我这里实现的HTTP storage plugin，本意是觉得传给HTTP service的query可能会动态构建，例如：select name, length from http.`/e/api:search` where $p=2 and $q='avi' # p=2&amp;q=avi 就是动态构建，其值可以来源于其他查询结果select name, length from http.`/e/api:search?q=avi&amp;p=2` where length &gt; 0 # 这里就是静态的第一条查询就需要借助StoragePluginOptimizerRule，它会收集所有where中的filter，最终作为HTTP serivce的query。但这里的实现还不完善。总体而言，由于Drill项目相对较新，要进行扩展还是比较困难的。尤其是Plan优化部分。" }, { "title": "无锁有序链表的实现", "url": "/posts/lock_free_list/", "categories": "c/c++", "tags": "lock, free, linked, list", "date": "2015-05-05 00:00:00 +0800", "snippet": "无锁有序链表可以保证元素的唯一性，使其可用于哈希表的桶，甚至直接作为一个效率不那么高的map。普通链表的无锁实现相对简单点，因为插入元素可以在表头插，而有序链表的插入则是任意位置。本文主要基于论文High Performance Dynamic Lock-Free Hash Tables实现。主要问题链表的主要操作包含insert和remove，先简单实现一个版本，就会看到问题所在，以下代码只用作示例： struct node_t { key_t key; value_t val; node_t *next; }; int l_find(node_t **pred_ptr, node_t **item_ptr, node_t *head, key_t key) { node_t *pred = head; node_t *item = head-&gt;next; while (item) { int d = KEY_CMP(item-&gt;key, key); if (d &gt;= 0) { *pred_ptr = pred; *item_ptr = item; return d == 0 ? TRUE : FALSE; } pred = item; item = item-&gt;next; } *pred_ptr = pred; *item_ptr = NULL; return FALSE; } int l_insert(node_t *head, key_t key, value_t val) { node_t *pred, *item, *new_item; while (TRUE) { if (l_find(&amp;pred, &amp;item, head, key)) { return FALSE; } new_item = (node_t*) malloc(sizeof(node_t)); new_item-&gt;key = key; new_item-&gt;val = val; new_item-&gt;next = item; // A. 如果pred本身被移除了 if (CAS(&amp;pred-&gt;next, item, new_item)) { return TRUE; } free(new_item); } } int l_remove(node_t *head, key_t key) { node_t *pred, *item; while (TRUE) { if (!l_find(&amp;pred, &amp;item, head, key)) { return TRUE; } // B. 如果pred被移除；如果item也被移除 if (CAS(&amp;pred-&gt;next, item, item-&gt;next)) { haz_free(item); return TRUE; } } }l_find函数返回查找到的前序元素和元素本身，代码A和B虽然拿到了pred和item，但在CAS的时候，其可能被其他线程移除。甚至，在l_find过程中，其每一个元素都可能被移除。问题在于，任何时候拿到一个元素时，都不确定其是否还有效。元素的有效性包括其是否还在链表中，其指向的内存是否还有效。解决方案通过为元素指针增加一个有效性标志位，配合CAS操作的互斥性，就可以解决元素有效性判定问题。因为node_t放在内存中是会对齐的，所以指向node_t的指针值低几位是不会用到的，从而可以在低几位里设置标志，这样在做CAS的时候，就实现了DCAS的效果，相当于将两个逻辑上的操作变成了一个原子操作。想象下引用计数对象的线程安全性，其内包装的指针是线程安全的，但对象本身不是。CAS的互斥性，在若干个线程CAS相同的对象时，只有一个线程会成功，失败的线程就可以以此判定目标对象发生了变更。改进后的代码（代码仅做示例用，不保证正确）： typedef size_t markable_t; // 最低位置1，表示元素被删除 #define HAS_MARK(p) ((markable_t)p &amp; 0x01) #define MARK(p) ((markable_t)p | 0x01) #define STRIP_MARK(p) ((markable_t)p &amp; ~0x01) int l_insert(node_t *head, key_t key, value_t val) { node_t *pred, *item, *new_item; while (TRUE) { if (l_find(&amp;pred, &amp;item, head, key)) { return FALSE; } new_item = (node_t*) malloc(sizeof(node_t)); new_item-&gt;key = key; new_item-&gt;val = val; new_item-&gt;next = item; // A. 虽然find拿到了合法的pred，但是在以下代码之前pred可能被删除，此时pred-&gt;next被标记 // pred-&gt;next != item，该CAS会失败，失败后重试 if (CAS(&amp;pred-&gt;next, item, new_item)) { return TRUE; } free(new_item); } return FALSE; } int l_remove(node_t *head, key_t key) { node_t *pred, *item; while (TRUE) { if (!l_find(&amp;pred, &amp;item, head, key)) { return FALSE; } node_t *inext = item-&gt;next; // B. 删除item前先标记item-&gt;next，如果CAS失败，那么情况同insert一样，有其他线程在find之后 // 删除了item，失败后重试 if (!CAS(&amp;item-&gt;next, inext, MARK(inext))) { continue; } // C. 对同一个元素item删除时，只会有一个线程成功走到这里 if (CAS(&amp;pred-&gt;next, item, STRIP_MARK(item-&gt;next))) { haz_defer_free(item); return TRUE; } } return FALSE; } int l_find(node_t **pred_ptr, node_t **item_ptr, node_t *head, key_t key) { node_t *pred = head; node_t *item = head-&gt;next; hazard_t *hp1 = haz_get(0); hazard_t *hp2 = haz_get(1); while (item) { haz_set_ptr(hp1, pred); haz_set_ptr(hp2, item); /* 如果已被标记，那么紧接着item可能被移除链表甚至释放，所以需要重头查找 */ if (HAS_MARK(item-&gt;next)) { return l_find(pred_ptr, item_ptr, head, key); } int d = KEY_CMP(item-&gt;key, key); if (d &gt;= 0) { *pred_ptr = pred; *item_ptr = item; return d == 0 ? TRUE : FALSE; } pred = item; item = item-&gt;next; } *pred_ptr = pred; *item_ptr = NULL; return FALSE; }haz_get、haz_set_ptr之类的函数是一个hazard pointer实现，用于支持多线程下内存的GC。上面的代码中，要删除一个元素item时，会标记item-&gt;next，从而使得insert时中那个CAS不需要做任何调整。总结下这里的线程竞争情况： insert中find到正常的pred及item，pred-&gt;next == item，然后在CAS前有线程删除了pred，此时pred-&gt;next == MARK(item)，CAS失败，重试；删除分为2种情况：a) 从链表移除，得到标记，pred可继续访问；b) pred可能被释放内存，此时再使用pred会错误。为了处理情况b，所以引入了类似hazard pointer的机制，可以有效保障任意一个指针p只要还有线程在使用它，它的内存就不会被真正释放 insert中有多个线程在pred后插入元素，此时同样由insert中的CAS保证，这个不多说 remove中情况同insert，find拿到了有效的pred和next，但在CAS的时候pred被其他线程删除，此时情况同insert，CAS失败，重试 任何时候改变链表结构时，无论是remove还是insert，都需要重试该操作 find中遍历时，可能会遇到被标记删除的item，此时item根据remove的实现很可能被删除，所以需要重头开始遍历ABA问题ABA问题还是存在的，insert中： if (CAS(&amp;pred-&gt;next, item, new_item)) { return TRUE; }如果CAS之前，pred后的item被移除，又以相同的地址值加进来，但其value变了，此时CAS会成功，但链表可能就不是有序的了。pred-&gt;val &lt; new_item-&gt;val &gt; item-&gt;val为了解决这个问题，可以利用指针值地址对齐的其他位来存储一个计数，用于表示pred-&gt;next的改变次数。当insert拿到pred时，pred-&gt;next中存储的计数假设是0，CAS之前其他线程移除了pred-&gt;next又新增回了item，此时pred-&gt;next中的计数增加，从而导致insert中CAS失败。 // 最低位留作删除标志 #define MASK ((sizeof(node_t) - 1) &amp; ~0x01) #define GET_TAG(p) ((markable_t)p &amp; MASK) #define TAG(p, tag) ((markable_t)p | (tag)) #define MARK(p) ((markable_t)p | 0x01) #define HAS_MARK(p) ((markable_t)p &amp; 0x01) #define STRIP_MARK(p) ((node_t*)((markable_t)p &amp; ~(MASK | 0x01)))remove的实现： /* 先标记再删除 */ if (!CAS(&amp;sitem-&gt;next, inext, MARK(inext))) { continue; } int tag = GET_TAG(pred-&gt;next) + 1; if (CAS(&amp;pred-&gt;next, item, TAG(STRIP_MARK(sitem-&gt;next), tag))) { haz_defer_free(sitem); return TRUE; }insert中也可以更新pred-&gt;next的计数。总结无锁的实现，本质上都会依赖于CAS的互斥性。从头实现一个lock free的数据结构，可以深刻感受到lock free实现的tricky。最终代码可以从这里github获取。代码中为了简单，实现了一个不是很强大的hazard pointer，可以参考之前的博文。" }, { "title": "并行编程中的内存回收Hazard Pointer", "url": "/posts/hazard-pointer/", "categories": "c/c++", "tags": "hazard, pointer", "date": "2015-05-03 00:00:00 +0800", "snippet": "接上篇使用RCU技术实现读写线程无锁，在没有GC机制的语言中，要实现Lock free的算法，就免不了要自己处理内存回收的问题。Hazard Pointer是另一种处理这个问题的算法，而且相比起来不但简单，功能也很强大。锁无关的数据结构与Hazard指针中讲得很好，Wikipedia Hazard pointer也描述得比较清楚，所以我这里就不讲那么细了。一个简单的实现可以参考我的github haz_ptr.c原理基本原理无非也是读线程对指针进行标识，指针(指向的内存)要释放时都会缓存起来延迟到确认没有读线程了才对其真正释放。&lt;Lock-Free Data Structures with Hazard Pointers&gt;中的描述： Each reader thread owns a single-writer/multi-reader shared pointer called “hazard pointer.” When a reader thread assigns the address of a map to its hazard pointer, it is basically announcing to other threads (writers), “I am reading this map. You can replace it if you want, but don’t change its contents and certainly keep your deleteing hands off it.”关键的结构包括：Hazard pointer、Thread Free listHazard pointer：一个读线程要使用一个指针时，就会创建一个Hazard pointer包装这个指针。一个Hazard pointer会被一个线程写，多个线程读。 struct HazardPointer { void *real_ptr; // 包装的指针 ... // 不同的实现有不同的成员 }; void func() { HazardPointer *hp = accquire(_real_ptr); ... // use _real_ptr release(hp); }Thread Free List：每个线程都有一个这样的列表，保存着将要释放的指针列表，这个列表仅对应的线程读写 void defer_free(void *ptr) { _free_list.push_back(ptr); }当某个线程要尝试释放Free List中的指针时，例如指针ptr，就检查所有其他线程使用的Hazard pointer，检查是否存在包装了ptr的Hazard pointer，如果没有则说明没有读线程正在使用ptr，可以安全释放ptr。 void gc() { for(ptr in _free_list) { conflict = false for (hp in _all_hazard_pointers) { if (hp-&gt;_real_ptr == ptr) { confilict = true break } } if (!conflict) delete ptr } }以上，其实就是Hazard Pointer的主要内容。Hazard Pointer的管理上面的代码中没有提到_all_hazard_pointers及accquire的具体实现，这就是Hazard Pointer的管理问题。《锁无关的数据结构与Hazard指针》文中创建了一个Lock free的链表来表示这个全局的Hazard Pointer List。每个Hazard Pointer有一个成员标识其是否可用。这个List中也就保存了已经被使用的Hazard Pointer集合和未被使用的Hazard Pointer集合，当所有Hazard Pointer都被使用时，就会新分配一个加进这个List。当读线程不使用指针时，需要归还Hazard Pointer，直接设置可用成员标识即可。要gc()时，就直接遍历这个List。要实现一个Lock free的链表，并且仅需要实现头插入，还是非常简单的。本身Hazard Pointer标识某个指针时，都是用了后立即标识，所以这个实现直接支持了动态线程，支持线程的挂起等。在nbds项目中也有一个Hazard Pointer的实现，相对要弱一点。它为每个线程都设置了自己的Hazard Pointer池，写线程要释放指针时，就访问所有其他线程的Hazard Pointer池。 typedef struct haz_local { // Free List pending_t *pending; // to be freed int pending_size; int pending_count; // Hazard Pointer 池，动态和静态两种 haz_t static_haz[STATIC_HAZ_PER_THREAD]; haz_t **dynamic; int dynamic_size; int dynamic_count; } __attribute__ ((aligned(CACHE_LINE_SIZE))) haz_local_t; static haz_local_t haz_local_[MAX_NUM_THREADS] = {};每个线程当然就涉及到haz_local_索引(ID)的分配，就像使用RCU技术实现读写线程无锁中的一样。这个实现为了支持线程动态创建，就需要一套线程ID的重用机制，相对复杂多了。附录最后，附上一些并行编程中的一些概念。Lock Free &amp; Wait Free常常看到Lock Free和Wait Free的概念，这些概念用于衡量一个系统或者说一段代码的并行级别，并行级别可参考并行编程——并发级别。总之Wait Free是一个比Lock Free更牛逼的级别。我自己的理解，例如《锁无关的数据结构与Hazard指针》中实现的Hazard Pointer链表就可以说是Lock Free的，注意它在插入新元素到链表头时，因为使用CAS，总免不了一个busy loop，有这个特征的情况下就算是Lock Free，虽然没锁，但某个线程的执行情况也受其他线程的影响。相对而言，Wait Free则是每个线程的执行都是独立的，例如《锁无关的数据结构与Hazard指针》中的Scan函数。“每个线程的执行时间都不依赖于其它任何线程的行为” 锁无关(Lock-Free)意味着系统中总存在某个线程能够得以继续执行；而等待无关(Wait-Free)则是一个更强的条件，它意味着所有线程都能往下进行。ABA问题在实现Lock Free算法的过程中，总是要使用CAS原语的，而CAS就会带来ABA问题。 在进行CAS操作的时候，因为在更改V之前，CAS主要询问“V的值是否仍然为A”，所以在第一次读取V之后以及对V执行CAS操作之前，如果将值从A改为B，然后再改回A，会使基于CAS的算法混乱。在这种情况下，CAS操作会成功。这类问题称为ABA问题。Wiki Hazard Pointer提到了一个ABA问题的好例子：在一个Lock free的栈实现中，现在要出栈，栈里的元素是[A, B, C]，head指向栈顶，那么就有compare_and_swap(target=&amp;head, newvalue=B, expected=A)。但是在这个操作中，其他线程把A B都出栈，且删除了B，又把A压入栈中，即[A, C]。那么前一个线程的compare_and_swap能够成功，此时head指向了一个已经被删除的B。stackoverflow上也有个例子 Real-world examples for ABA in multithreading 对于CAS产生的这个ABA问题，通常的解决方案是采用CAS的一个变种DCAS。DCAS，是对于每一个V增加一个引用的表示修改次数的标记符。对于每个V，如果引用修改了一次，这个计数器就加1。然后再这个变量需要update的时候，就同时检查变量的值和计数器的值。但也早有人提出DCAS也不是ABA problem 的银弹。" }, { "title": "使用RCU技术实现读写线程无锁", "url": "/posts/rw_thread_gc/", "categories": "c/c++", "tags": "rcu", "date": "2015-04-19 00:00:00 +0800", "snippet": "在一个系统中有一个写线程和若干个读线程，读写线程通过一个指针共用了一个数据结构，写线程改写这个结构，读线程读取该结构。在写线程改写这个数据结构的过程中，加锁情况下读线程由于等待锁耗时会增加。可以利用RCU (Read Copy Update What is rcu)的思想来去除这个锁。本文提到的主要实现代码：gistRCURCU可以说是一种替代读写锁的方法。其基于一个事实：当写线程在改变一个指针时，读线程获取这个指针，要么获取到老的值，要么获取到新的值。RCU的基本思想其实很简单，参考What is RCU中Toy implementation可以很容易理解。一种简单的RCU流程可以描述为：写线程：old_ptr = _ptrtmp_ptr = copy(_ptr) // copychange(tmp_ptr) // change _ptr = tmp_ptr // updatesynchroize(tmp_ptr)写线程要更新_ptr指向的内容时，先复制一份新的，基于新的进行改变，更新_ptr指针，最后同步释放老的内存。读线程：tmp_ptr = _ptruse(tmp_ptr)dereference(tmp_ptr)读线程直接使用_ptr，使用完后需要告诉写线程自己不再使用_ptr。读线程获取_ptr时，可能会获取到老的也可能获取到新的，无论哪种RCU都需要保证这块内存是有效的。重点在synchroize和dereference。synchroize会等待所有使用老的_ptr的线程dereference，对于新的_ptr使用者其不需要等待。这个问题说白了就是写线程如何知道old_ptr没有任何读线程在使用，可以安全地释放。这个问题实际上在wait-free的各种实现中有好些解法，how-when-to-release-memory-in-wait-free-algorithms这里有人总结了几种方法，例如Hazard pointers、Quiescence period based reclamation。简单地使用引用计数智能指针是无法解决这个问题的，因为智能指针自己不是线程安全的，例如：tmp_ptr = _ptr // 1tmp_ptr-&gt;addRef() // 2usetmp_ptr-&gt;release()代码1/2行不是原子的，所以当取得tmp_ptr准备addRef时，tmp_ptr可能刚好被释放了。Quiescence period based reclamation方法指的是读线程需要声明自己处于Quiescence period，也就是不使用_ptr的时候，当其使用_ptr的时候实际是进入了一个逻辑上的临界区，当所有读线程都不再使用_ptr的时候，写线程就可以对内存进行安全地释放。本文正是描述了一种Quiescence period based reclamation实现。这个实现可以用于有一个写线程和多个读线程共用若干个数据的场景。实现该方法本质上把数据同步分解为基本的内存单元读写。使用方式上可描述为：读线程：tmp_ptr = _ptruseupdate() // 标识自己不再使用任何共享数据写线程：old_ptr = _ptrtmp_ptr = copy(_ptr)change(tmp_ptr)_ptr = tmp_ptrgc()defer_free(old_ptr)以下具体描述读写线程的实现。写线程写线程负责标识内存需要被释放，以及检查何时可以真正释放内存。其维护了一个释放内存队列： void *_pending[8] uint64_t _head, _tail void defer_free(void *p) { _head ++ _pending[PENDING_POS(_head)] = p } gc() { for (_tail -&gt; find_free_pos()) free(_pending[_tail]) }find_free_pos找到一个可释放内存位置，在[_tail, find_free_pos())这个区间内所有内存是可以安全被释放的。队列位置_head/_tail一直增大，PENDING_POS就是对这个位置取模，限定在队列大小范围内也是可行的，无论哪种方式，_head从逻辑上说一直&gt;=_tail，但在实际中可能小于_tail，所以实现时不使用大小判定，而是： gc() { pos = find_free_pos() while (_tail != pos) { free(_pending[PENDING_POS(_tail)]) _tail ++ } }读线程读线程不再使用共享内存时，就标识自己： update() { static __thread int tid _tmark[tid] = _head }读线程的状态会影响写线程的回收逻辑，其状态分为： 初始 活跃，会调用到update 暂停，其他地方同步，或被挂起 退出读线程处于活跃状态时，它会不断地更新自己可释放内存位置(_tmark[tid])。写线程检查所有读线程的_tmark[tid]，[_tail, min(_tmark[]))是所有读线程都不再使用的内存区间，可以被安全释放。 find_free_pos() { min = MAX_INTEGER pos = 0 for (tid = 0; tid &lt; max_threads; ++tid) { tpos = _tmark[tid] offset = tpos - tail if (offset &lt; min) { min = offset pos = tpos } } return pos }当读线程暂停时，其_tmark[tid]可能会在很长一段时间里得不到更新，此时会阻碍写线程释放内存。所以需要方法来标识读线程是否进入暂停状态。通过设置一个上次释放内存位置_tfreeds[tid]，标识每个线程当前内存释放到的位置。如果一个线程处于暂停状态了，那么在一定时间后，_tfreeds[tid] == _tmark[tid]。在查找可释放位置时，就需要忽略暂停状态的读线程： find_free_pos() { min = MAX_INTEGER pos = _head for (tid = 0; tid &lt; max_threads; ++tid) { tpos = _tmark[tid] if (tpos == _tfreeds[tid]) continue offset = tpos - tail if (offset &lt; min) { min = offset pos = tpos } } for (tid = 0; tid &lt; max_threads; ++tid) { if (_tfreeds[tid] != _tmark[tid]) _tfreeds[tid] = pos } return pos }但是当所有线程都处于暂停状态时，写线程可能还在工作，上面的实现就会返回_head，此时写线程依然可以正常释放内存。小结，该方法原理可用下图表示：线程动态增加/减少如果读线程可能中途退出，中途动态增加，那么_tmark[]就需要被复用，此时线程tid的分配调整为动态的即可： class ThreadIdPool { public: // 动态获取一个线程tid，某线程每次调用该接口返回相同的值 int get() // 线程退出时回收该tid void put(int id) }ThreadIdPool的实现无非就是利用TLS，以及在线程退出时得到通知以回收tid。那么对于读线程的update实现变为： update() { tid = _idPool-&gt;get() _tmark[tid] = _head }当某个线程退出时，_tmark[tid]和_tfreeds[tid]不需要做任何处理，当新创建的线程复用了该tid时，可以立即复用_tmark[tid]和_tfreeds[tid]，此时这2个值必然是相等的。以上，就是整个方法的实现。线程可读可写以上方法适用场景还是不够通用。在nbds项目（实现了一些无锁数据结构的toy project）中有一份虽然简单但也有启发的实现(rcu.c)。该实现支持任意线程defer_free，所有线程update。update除了声明不再使用任何共享内存外，还可能回收内存。任意线程都可能维护一些待释放的内存，任意一块内存可能被任意其他线程使用。那么它是如何内存回收的？本文描述的方法是所有读线程自己声明自己，然后由写线程主动来检查。不同于此方法， nbds的实现，基于一种通知扩散的方式。该方式以这样一种方式工作：当某个线程尝试内存回收时，它需要知道所有其他线程的空闲位置（相当于_tmark[tid]），它通知下一个线程我需要释放的范围。当下一个线程update时（离开临界区），它会将上个线程的通知继续告诉下一个线程，直到最后这个通知回到发起线程。那么对于发起线程而言，这个释放请求在所有线程中走了一遍，得到了大家的认可，可以安全释放。每个线程都以这样的方式工作。 void rcu_defer_free (void *x) { ... rcu_[next_thread_id][tid_] = rcu_last_posted_[tid_][tid_] = pending_[tid_]-&gt;head; ... } void rcu_update (void) { ... for (i = 0; i &lt; num_threads_; ++i) { ... uint64_t x = rcu_[tid_][i]; // 其它线程发给自己的通知 rcu_[next_thread_id][i] = rcu_last_posted_[tid_][i] = x; // 扩散出去 ... } ... while (q-&gt;tail != rcu_[tid_][tid_]) { free } ... }这个实现相对简单，不支持线程暂停，以及线程动态增加和减少。" }, { "title": "记一次tcmalloc分配内存引起的coredump", "url": "/posts/tcmalloc-getstacktrace/", "categories": "c/c++", "tags": "", "date": "2015-04-06 00:00:00 +0800", "snippet": "现象线上的服务出现coredump，堆栈为：#0 0x000000000045d145 in GetStackTrace(void**, int, int) ()#1 0x000000000045ec22 in tcmalloc::PageHeap::GrowHeap(unsigned long) ()#2 0x000000000045eeb3 in tcmalloc::PageHeap::New(unsigned long) ()#3 0x0000000000459ee8 in tcmalloc::CentralFreeList::Populate() ()#4 0x000000000045a088 in tcmalloc::CentralFreeList::FetchFromSpansSafe() ()#5 0x000000000045a10a in tcmalloc::CentralFreeList::RemoveRange(void**, void**, int) ()#6 0x000000000045c282 in tcmalloc::ThreadCache::FetchFromCentralCache(unsigned long, unsigned long) ()#7 0x0000000000470766 in tc_malloc ()#8 0x00007f75532cd4c2 in __conhash_get_rbnode (node=0x22c86870, hash=30) at build/release64/cm_sub/conhash/conhash_inter.c:88#9 0x00007f75532cd76e in __conhash_add_replicas (conhash=0x24fbc7e0, iden=&lt;value optimized out&gt;) at build/release64/cm_sub/conhash/conhash_inter.c:45#10 0x00007f75532cd1fa in conhash_add_node (conhash=0x24fbc7e0, iden=0) at build/release64/cm_sub/conhash/conhash.c:72#11 0x00007f75532c651b in cm_sub::TopoCluster::initLBPolicyInfo (this=0x2593a400) at build/release64/cm_sub/topo_cluster.cpp:114#12 0x00007f75532cad73 in cm_sub::TopoClusterManager::processClusterMapTable (this=0xa219e0, ref=0x267ea8c0) at build/release64/cm_sub/topo_cluster_manager.cpp:396#13 0x00007f75532c5a93 in cm_sub::SubRespMsgProcess::reinitCluster (this=0x9c2f00, msg=0x4e738ed0) at build/release64/cm_sub/sub_resp_msg_process.cpp:157...查看了应用层相关数据结构，基本数据都是没有问题的。所以最初怀疑是tcmalloc内部维护了错误的内存，在分配内存时出错，这个堆栈只是问题的表象。几天后，线上的另一个服务，基于同样的库，也core了，堆栈还是一样的。最初定位问题都是从最近更新的东西入手，包括依赖的server环境，但都没有明显的问题，所以最后只能从core的直接原因入手。分析GetStackTrace确认core的详细位置：# core在该指令0x000000000045d145 &lt;_Z13GetStackTracePPvii+21&gt;: mov 0x8(%rax),%r9(gdb) p/x $rip # core 的指令位置$9 = 0x45d145(gdb) p/x $rax $10 = 0x4e73aa58(gdb) x/1a $rax+0x8 # rax + 8 = 0x4e73aa600x4e73aa60: 0x0该指令尝试从[0x4e73aa60]处读取内容，然后出错，这个内存单元不可读。但是具体这个指令在代码中是什么意思，需要将这个指令对应到代码中。获取tcmalloc的源码，发现GetStackTrace根据编译选项有很多实现，所以这里选择最可能的实现，然后对比汇编以确认代码是否匹配。最初选择的是stacktrace_x86-64-inl.h，后来发现完全不匹配，又选择了stacktrace_x86-inl.h。这个实现版本里也有对64位平台的支持。stacktrace_x86-inl.h里使用了一些宏来生成函数名和参数，精简后代码大概为： int GET_STACK_TRACE_OR_FRAMES { void **sp; unsigned long rbp; __asm__ volatile (\"mov %%rbp, %0\" : \"=r\" (rbp)); sp = (void **) rbp; int n = 0; while (sp &amp;&amp; n &lt; max_depth) { if (*(sp+1) == reinterpret_cast&lt;void *&gt;(0)) { break; } void **next_sp = NextStackFrame&lt;!IS_STACK_FRAMES, IS_WITH_CONTEXT&gt;(sp, ucp); if (skip_count &gt; 0) { skip_count--; } else { result[n] = *(sp+1); n++; } sp = next_sp; } return n; }NextStackFrame是一个模板函数，包含一大堆代码，精简后非常简单： template&lt;bool STRICT_UNWINDING, bool WITH_CONTEXT&gt; static void **NextStackFrame(void **old_sp, const void *uc) { void **new_sp = (void **) *old_sp; if (STRICT_UNWINDING) { if (new_sp &lt;= old_sp) return NULL; if ((uintptr_t)new_sp - (uintptr_t)old_sp &gt; 100000) return NULL; } else { if (new_sp == old_sp) return NULL; if ((new_sp &gt; old_sp) &amp;&amp; ((uintptr_t)new_sp - (uintptr_t)old_sp &gt; 1000000)) return NULL; } if ((uintptr_t)new_sp &amp; (sizeof(void *) - 1)) return NULL; return new_sp; }上面这个代码到汇编的对比过程还是花了些时间，其中汇编中出现的一些常量可以大大缩短对比时间，例如上面出现了100000，汇编中就有：0x000000000045d176 &lt;_Z13GetStackTracePPvii+70&gt;: cmp $0x186a0,%rbx # 100000=0x186a0注意NextStackFrame中的 if (STRICT_UNWINDING)使用的是模板参数，这导致生成的代码中根本没有else部分，也就没有1000000这个常量在对比代码的过程中，可以知道关键的几个寄存器、内存位置对应到代码中的变量，从而可以还原core时的现场环境。分析过程中不一定要从第一行汇编读，可以从较明显的位置读，从而还原整个代码，函数返回指令、跳转指令、比较指令、读内存指令、参数寄存器等都是比较明显对应的地方。另外注意GetStackTrace在RecordGrowth中调用，传入了3个参数：GetStackTrace(t-&gt;stack, kMaxStackDepth-1, 3); // kMaxStackDepth = 31以下是我分析的简单注解：(gdb) disassembleDump of assembler code for function _Z13GetStackTracePPvii:0x000000000045d130 &lt;_Z13GetStackTracePPvii+0&gt;: push %rbp0x000000000045d131 &lt;_Z13GetStackTracePPvii+1&gt;: mov %rsp,%rbp0x000000000045d134 &lt;_Z13GetStackTracePPvii+4&gt;: push %rbx0x000000000045d135 &lt;_Z13GetStackTracePPvii+5&gt;: mov %rbp,%rax0x000000000045d138 &lt;_Z13GetStackTracePPvii+8&gt;: xor %r8d,%r8d0x000000000045d13b &lt;_Z13GetStackTracePPvii+11&gt;: test %rax,%rax0x000000000045d13e &lt;_Z13GetStackTracePPvii+14&gt;: je 0x45d167 &lt;_Z13GetStackTracePPvii+55&gt;0x000000000045d140 &lt;_Z13GetStackTracePPvii+16&gt;: cmp %esi,%r8d # while ( .. max_depth &gt; n ?0x000000000045d143 &lt;_Z13GetStackTracePPvii+19&gt;: jge 0x45d167 &lt;_Z13GetStackTracePPvii+55&gt;0x000000000045d145 &lt;_Z13GetStackTracePPvii+21&gt;: mov 0x8(%rax),%r9 # 关键位置：*(sp+1) -&gt; r9, rax 对应 sp变量0x000000000045d149 &lt;_Z13GetStackTracePPvii+25&gt;: test %r9,%r9 # *(sp+1) == 0 ?0x000000000045d14c &lt;_Z13GetStackTracePPvii+28&gt;: je 0x45d167 &lt;_Z13GetStackTracePPvii+55&gt;0x000000000045d14e &lt;_Z13GetStackTracePPvii+30&gt;: mov (%rax),%rcx # new_sp = *old_sp，这里已经是NextStackFrame的代码0x000000000045d151 &lt;_Z13GetStackTracePPvii+33&gt;: cmp %rcx,%rax # new_sp &lt;= old_sp ? 0x000000000045d154 &lt;_Z13GetStackTracePPvii+36&gt;: jb 0x45d170 &lt;_Z13GetStackTracePPvii+64&gt; # new_sp &gt; old_sp 跳转0x000000000045d156 &lt;_Z13GetStackTracePPvii+38&gt;: xor %ecx,%ecx0x000000000045d158 &lt;_Z13GetStackTracePPvii+40&gt;: test %edx,%edx # skip_count &gt; 0 ?0x000000000045d15a &lt;_Z13GetStackTracePPvii+42&gt;: jle 0x45d186 &lt;_Z13GetStackTracePPvii+86&gt;0x000000000045d15c &lt;_Z13GetStackTracePPvii+44&gt;: sub $0x1,%edx # skip_count--0x000000000045d15f &lt;_Z13GetStackTracePPvii+47&gt;: mov %rcx,%rax 0x000000000045d162 &lt;_Z13GetStackTracePPvii+50&gt;: test %rax,%rax # while (sp ?0x000000000045d165 &lt;_Z13GetStackTracePPvii+53&gt;: jne 0x45d140 &lt;_Z13GetStackTracePPvii+16&gt;0x000000000045d167 &lt;_Z13GetStackTracePPvii+55&gt;: pop %rbx0x000000000045d168 &lt;_Z13GetStackTracePPvii+56&gt;: leaveq 0x000000000045d169 &lt;_Z13GetStackTracePPvii+57&gt;: mov %r8d,%eax # r8 存储了返回值，r8=n0x000000000045d16c &lt;_Z13GetStackTracePPvii+60&gt;: retq # return n0x000000000045d16d &lt;_Z13GetStackTracePPvii+61&gt;: nopl (%rax)0x000000000045d170 &lt;_Z13GetStackTracePPvii+64&gt;: mov %rcx,%rbx 0x000000000045d173 &lt;_Z13GetStackTracePPvii+67&gt;: sub %rax,%rbx # offset = new_sp - old_sp0x000000000045d176 &lt;_Z13GetStackTracePPvii+70&gt;: cmp $0x186a0,%rbx # offset &gt; 100000 ?0x000000000045d17d &lt;_Z13GetStackTracePPvii+77&gt;: ja 0x45d156 &lt;_Z13GetStackTracePPvii+38&gt; # return NULL0x000000000045d17f &lt;_Z13GetStackTracePPvii+79&gt;: test $0x7,%cl # new_sp &amp; (sizeof(void*) - 1)0x000000000045d182 &lt;_Z13GetStackTracePPvii+82&gt;: je 0x45d158 &lt;_Z13GetStackTracePPvii+40&gt;0x000000000045d184 &lt;_Z13GetStackTracePPvii+84&gt;: jmp 0x45d156 &lt;_Z13GetStackTracePPvii+38&gt;0x000000000045d186 &lt;_Z13GetStackTracePPvii+86&gt;: movslq %r8d,%rax # rax = n0x000000000045d189 &lt;_Z13GetStackTracePPvii+89&gt;: add $0x1,%r8d # n++0x000000000045d18d &lt;_Z13GetStackTracePPvii+93&gt;: mov %r9,(%rdi,%rax,8)# 关键位置：result[n] = *(sp+1)0x000000000045d191 &lt;_Z13GetStackTracePPvii+97&gt;: jmp 0x45d15f &lt;_Z13GetStackTracePPvii+47&gt;分析过程比较耗时，同时还可以分析下GetStackTrace函数的实现原理，其实就是利用RBP寄存器不断回溯，从而得到整个调用堆栈各个函数的地址（严格来说是返回地址）。简单示意下函数调用中RBP的情况： ...saved registers # i.e push rbxlocal variabes # i.e sub 0x10, rspreturn address # call xxxlast func RBP # push rbp; mov rsp, rbpsaved registerslocal variables return addresslast func RBP... # rsp总之，一般情况下，任何一个函数中，RBP寄存器指向了当前函数的栈基址，该栈基址中又存储了调用者的栈基址，同时该栈基址前面还存储了调用者的返回地址。所以，GetStackTrace的实现，简单来说大概就是： sp = rbp // 取得当前函数GetStackTrace的栈基址 while (n &lt; max_depth) { new_sp = *sp result[n] = *(new_sp+1) n++ }以上，最终就知道了以下关键信息： r8 对应变量 n，表示当前取到第几个栈帧了 rax 对应变量 sp，代码core在 *(sp+1) rdi 对应变量 result，用于存储取得的各个地址然后可以看看现场是怎样的：(gdb) x/10a $rdi0x1ffc9b98: 0x45a088 &lt;_ZN8tcmalloc15CentralFreeList18FetchFromSpansSafeEv+40&gt; 0x45a10a &lt;_ZN8tcmalloc15CentralFreeList11RemoveRangeEPPvS2_i+106&gt;0x1ffc9ba8: 0x45c282 &lt;_ZN8tcmalloc11ThreadCache21FetchFromCentralCacheEmm+114&gt; 0x470766 &lt;tc_malloc+790&gt;0x1ffc9bb8: 0x7f75532cd4c2 &lt;__conhash_get_rbnode+34&gt; 0x00x1ffc9bc8: 0x0 0x00x1ffc9bd8: 0x0 0x0(gdb) p/x $r8$3 = 0x5(gdb) p/x $rax$4 = 0x4e73aa58小结：GetStackTrace在取调用__conhash_get_rbnode的函数时出错，取得了5个函数地址。当前使用的RBP为0x4e73aa58。错误的RBPRBP也是从堆栈中取出来的，既然这个地址有问题，首先想到的就是有代码局部变量/数组写越界。例如sprintf的使用。而且，一般写越界破坏堆栈，都可能是把调用者的堆栈破坏了，例如：char s[32];memcpy(s, p, 1024);因为写入都是从低地址往高地址写，而调用者的堆栈在高地址。当然，也会遇到写坏调用者的调用者的堆栈，也就是跨栈帧越界写，例如以前遇到的：len = vsnprintf(buf, sizeof(buf), fmt, wtf-long-string);buf[len] = 0;__conhash_get_rbnode的RBP是在tcmalloc的堆栈中取的：(gdb) f 7#7 0x0000000000470766 in tc_malloc ()(gdb) x/10a $rsp0x4e738b80: 0x4e73aa58 0x22c868700x4e738b90: 0x4e738bd0 0x850x4e738ba0: 0x4e73aa58 0x7f75532cd4c2 &lt;__conhash_get_rbnode+34&gt; # 0x4e73aa58所以这里就会怀疑是tcmalloc这个函数里有把堆栈破坏，这个时候就是读代码，看看有没有疑似危险的地方，未果。这里就陷入了僵局，怀疑又遇到了跨栈帧破坏的情况，这个时候就只能__conhash_get_rbnode调用栈中周围的函数翻翻，例如调用__conhash_get_rbnode的函数__conhash_add_replicas中恰好有字符串操作： void __conhash_add_replicas(conhash_t *conhash, int32_t iden) { node_t* node = __conhash_create_node(iden, conhash-&gt;replica); ... char buf[buf_len]; // buf_len = 64 ... snprintf(buf, buf_len, VIRT_NODE_HASH_FMT, node-&gt;iden, i); uint32_t hash = conhash-&gt;cb_hashfunc(buf); if(util_rbtree_search(&amp;(conhash-&gt;vnode_tree), hash) == NULL) { util_rbtree_node_t* rbnode = __conhash_get_rbnode(node, hash); ... 这段代码最终发现是没有问题的，这里又耗费了不少时间。后来发现若干个函数里的RBP都有点奇怪，这个调用栈比较正常的范围是：0x4e738c90(gdb) f 8#8 0x00007f75532cd4c2 in __conhash_get_rbnode (node=0x22c86870, hash=30)(gdb) p/x $rbp$6 = 0x4e73aa58 # 这个还不算特别可疑(gdb) f 9#9 0x00007f75532cd76e in __conhash_add_replicas (conhash=0x24fbc7e0, iden=&lt;value optimized out&gt;)(gdb) p/x $rbp$7 = 0x4e738c60 # 这个也不算特别可疑(gdb) f 10#10 0x00007f75532cd1fa in conhash_add_node (conhash=0x24fbc7e0, iden=0) at build/release64/cm_sub/conhash/conhash.c:72(gdb) p/x $rbp # 可疑$8 = 0x0(gdb) f 11#11 0x00007f75532c651b in cm_sub::TopoCluster::initLBPolicyInfo (this=0x2593a400)(gdb) p/x $rbp # 可疑$9 = 0x2598fef0为什么很多函数中RBP都看起来不正常？ 想了想真要是代码里把堆栈破坏了，这错误得发生得多巧妙？错误RBP的来源然后转机来了，脑海中突然闪出-fomit-frame-pointer。编译器生成的代码中是可以不需要栈基址指针的，也就是RBP寄存器不作为栈基址寄存器。大部分函数或者说开启了frame-pointer的函数，其函数头都会有以下指令：push %rbpmov %rsp,%rbp...表示保存调用者的栈基址到栈中，以及设置自己的栈基址。看下__conhash系列函数；Dump of assembler code for function __conhash_get_rbnode:0x00007f75532cd4a0 &lt;__conhash_get_rbnode+0&gt;: mov %rbx,-0x18(%rsp)0x00007f75532cd4a5 &lt;__conhash_get_rbnode+5&gt;: mov %rbp,-0x10(%rsp)...这个库是单独编译的，没有显示指定-fno-omit-frame-pointer，查阅gcc手册，o2优化是开启了omit-frame-pinter 的。在没有RBP的情况下，tcmalloc的GetStackTrace尝试读RBP取获取调用返回地址，自然是有问题的。但是，如果整个调用栈中的函数，要么有RBP，要么没有RBP，那么GetStackTrace取出的结果最多就是跳过一些栈帧，不会出错。 除非，这中间的某个函数把RBP寄存器另作他用（编译器省出这个寄存器肯定是要另作他用的）。所以这里继续追查这个错误地址0x4e73aa58的来源。来源已经比较明显，肯定是__conhash_get_rbnode中设置的，因为这个函数的RBP是在被调用者tcmalloc中保存的。Dump of assembler code for function __conhash_get_rbnode:0x00007f75532cd4a0 &lt;__conhash_get_rbnode+0&gt;: mov %rbx,-0x18(%rsp)0x00007f75532cd4a5 &lt;__conhash_get_rbnode+5&gt;: mov %rbp,-0x10(%rsp)0x00007f75532cd4aa &lt;__conhash_get_rbnode+10&gt;: mov %esi,%ebp # 改写了RBP0x00007f75532cd4ac &lt;__conhash_get_rbnode+12&gt;: mov %r12,-0x8(%rsp)0x00007f75532cd4b1 &lt;__conhash_get_rbnode+17&gt;: sub $0x18,%rsp0x00007f75532cd4b5 &lt;__conhash_get_rbnode+21&gt;: mov %rdi,%r120x00007f75532cd4b8 &lt;__conhash_get_rbnode+24&gt;: mov $0x30,%edi0x00007f75532cd4bd &lt;__conhash_get_rbnode+29&gt;: callq 0x7f75532b98c8 &lt;malloc@plt&gt; # 调用tcmalloc，汇编到这里即可这里打印RSI寄存器的值可能会被误导，因为任何时候打印寄存器的值可能都是错的，除非它有被显示保存。不过这里可以看出RSI的值来源于参数(RSI对应第二个参数)： void __conhash_add_replicas(conhash_t *conhash, int32_t iden) { node_t* node = __conhash_create_node(iden, conhash-&gt;replica); ... char buf[buf_len]; // buf_len = 64 ... snprintf(buf, buf_len, VIRT_NODE_HASH_FMT, node-&gt;iden, i); uint32_t hash = conhash-&gt;cb_hashfunc(buf); // hash值由一个字符串哈希函数计算 if(util_rbtree_search(&amp;(conhash-&gt;vnode_tree), hash) == NULL) { util_rbtree_node_t* rbnode = __conhash_get_rbnode(node, hash); // hash值 ... 追到__conhash_add_replicas：0x00007f75532cd764 &lt;__conhash_add_replicas+164&gt;: mov %ebx,%esi # 来源于rbx0x00007f75532cd766 &lt;__conhash_add_replicas+166&gt;: mov %r15,%rdi0x00007f75532cd769 &lt;__conhash_add_replicas+169&gt;: callq 0x7f75532b9e48 &lt;__conhash_get_rbnode@plt&gt;(gdb) p/x $rbx$11 = 0x4e73aa58(gdb) p/x hash$12 = 0x4e73aa58 # 0x4e73aa58找到了0x4e73aa58的来源。这个地址值竟然是一个字符串哈希算法算出来的！这里还可以看看这个字符串的内容：(gdb) x/1s $rsp0x4e738bd0: \"conhash-00000-00133\"这个碉堡的哈希函数是conhash_hash_def。coredump的条件以上，既然只要某个库omit-frame-pointer，那tcmalloc就可能出错，为什么发生的频率并不高呢？这个可以回到GetStackTrace尤其是NextStackFrame的实现，其中包含了几个合法RBP的判定： if (new_sp &lt;= old_sp) return NULL; // 上一个栈帧的RBP肯定比当前的大 if ((uintptr_t)new_sp - (uintptr_t)old_sp &gt; 100000) return NULL; // 指针值范围还必须在100000内 ... if ((uintptr_t)new_sp &amp; (sizeof(void *) - 1)) return NULL; // 由于本身保存的是指针，所以还必须是sizeof(void*)的整数倍，对齐有了以上条件，才使得这个core几率变得很低。总结最后，如果你很熟悉tcmalloc，整个问题估计就被秒解了：tcmalloc INSTALL附另外附上另一个有意思的东西。在分析__conhash_add_replicas时，其内定义了一个64字节的字符数组，查看其堆栈：(gdb) x/20a $rsp0x4e738bd0: 0x2d687361686e6f63 0x30302d3030303030 # 这些是字符串conhash-00000-001330x4e738be0: 0x333331 0x00x4e738bf0: 0x0 0x7f75532cd69e &lt;__conhash_create_node+78&gt;0x4e738c00: 0x24fbc7e0 0x4e738c600x4e738c10: 0x24fbc7e0 0x7f75532cd6e3 &lt;__conhash_add_replicas+35&gt;0x4e738c20: 0x0 0x24fbc7e80x4e738c30: 0x4e738c20 0x24fbc7e00x4e738c40: 0x22324360 0x246632c00x4e738c50: 0x0 0x00x4e738c60: 0x0 0x7f75532cd1fa &lt;conhash_add_node+74&gt;最开始我觉得buf占64字节，也就是整个[0x4e738bd0, 0x4e738c10)内存，但是这块内存里居然有函数地址，这一度使我怀疑这里有问题。后来醒悟这些地址是定义buf前调用__conhash_create_node产生的，调用过程中写到堆栈里，调用完后栈指针改变，但并不需要清空栈中的内容。" }, { "title": "初识JVM byte code", "url": "/posts/intro-java-bytecode/", "categories": "java", "tags": "", "date": "2015-03-31 00:00:00 +0800", "snippet": "关于JVM和其上的byte code，网上其实有足够多的资料了，我这里就简单做个提纲和介绍，权当记录吧。stack-based VMJava byte code运行在JVM上，就像机器指令运行在物理机上，是需要遵循这个机器的指令规范的。所以认识JVM byte code，是需要稍微了解下JVM的。JVM是一个基于栈(stack-based)的虚拟机。很久以前我还写过类似简单的虚拟机。基于栈的虚拟机其操作数和指令运算的中间结果全部都在一个虚拟栈中，与之对应的是基于寄存器(register-based)的虚拟机，其操作数和指令运算结果会存放在若干个寄存器（也就是存储单元）里。x86机器就可以理解为基于寄存器的机器。byte code其实和x86汇编代码本质一样，无非是对应机器制定的一堆指令，这里可以举例说明下两类虚拟机的不同：# stack-based push 1 # 压立即数1到栈顶push 2 # 压立即数2到栈顶add # 弹出栈顶2个数相加，将结果3压到栈顶# register-basedmov ax, 1 # 写立即数到寄存器axadd ax, 2 # 取ax中的值1与立即数2进行相加，存放结果到ax关于两类实现的比较，网上也有不少资料，例如Dalvik 虚拟机和 Sun JVM 在架构和执行方面有什么本质区别？。至于有人说基于栈的虚拟机更利于移植，我不是很理解，因为即使是基于寄存器的实现，也不一定真的必须把这些寄存器映射到物理机CPU上的寄存器，使用内存来模拟性能上跟基于栈的方式不是八九不离十吗？了解了JVM的这个特点，JVM上的各种指令就可以更好地理解，如果要理解JVM如何运行byte code的，那还需要了解JVM内部的各种结构，例如符号解析、class loader、内存分配甚至垃圾回收等。这个以后再谈。byte-code*.class文件就已经是编译好的byte code文件，就像C/C++编译出来的目标文件一样，已经是各种二进制指令了。这个时候可以通过JDK中带的javap工具来反汇编，以查看对应的byte code。 // Test.java public class Test { public static void main(String[] args) { int a = 0xae; int b = 0x10; int c = a + b; int d = c + 1; String s; s = \"hello\"; } }编译该文件：javac Test.java得到Test.class，然后javap -c Test即得到：Compiled from \"Test.java\"public class Test { public Test(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return public static void main(java.lang.String[]); Code: 0: sipush 174 # push a short onto the stack 0xae=174 3: istore_1 # store int value into variable 1: a = 0xae 4: bipush 16 # push a byte onto the stack 0x10=16 6: istore_2 # store int value into variable 2: b = 0x10 7: iload_1 # load value from variable 1 and push onto the stack 8: iload_2 9: iadd # add two ints: a + b 10: istore_3 # c = a + b 11: iload_3 12: iconst_1 # 1 13: iadd # c + 1 14: istore 4 # d = c + 1 16: ldc #2 // String hello 18: astore 5 20: return}这个时候对照着JVM指令表看上面的代码，比起x86汇编浅显易懂多了，秒懂，参考Java bytecode instruction listings。JVM中每个指令只占一个字节，操作数是变长的，所以其一条完整的指令（操作码+操作数）也是变长的。上面每条指令前都有一个偏移，实际是按字节来偏移的。想起Lua VM的指令竟然是以bit来干的从上面的byte code中，以x86汇编的角度来看会发现一些不同的东西： 局部变量竟是以索引来区分：istore_1 写第一个局部变量，istore_2写第二个局部变量，第4个局部变量则需要用操作数来指定了：istore 4 函数调用invokespecial #1竟然也是类似的索引，这里调用的是Object基类构造函数 常量字符串也是类似的索引：ldc #2 *.class中是不是也分了常量数据段和代码段呢以上需要我们进一步了解*.class文件的格式。class file formatclass 文件格式网上也有讲得很详细的了，例如这篇Java Class文件详解。整个class文件完全可以用以下结构来描述：ClassFile { u4 magic; //魔数 u2 minor_version; //次版本号 u2 major_version; //主版本号 u2 constant_pool_count; //常量池大小 cp_info constant_pool[constant_pool_count-1]; //常量池 u2 access_flags; //类和接口层次的访问标志（通过|运算得到） u2 this_class; //类索引（指向常量池中的类常量） u2 super_class; //父类索引（指向常量池中的类常量） u2 interfaces_count; //接口索引计数器 u2 interfaces[interfaces_count]; //接口索引集合 u2 fields_count; //字段数量计数器 field_info fields[fields_count]; //字段表集合 u2 methods_count; //方法数量计数器 method_info methods[methods_count]; //方法表集合 u2 attributes_count; //属性个数 attribute_info attributes[attributes_count]; //属性表}这明显已经不是以区段来分的格式了，上面提到的函数索引、常量字符串索引，都是保存在constant_pool常量池中。常量池中存储了很多信息，包括： 各种字面常量，例如字符串 类、数据成员、接口引用常量池的索引从1开始。对于上面例子Test.java，可以使用javap -v Test来查看其中的常量池，例如：Constant pool: #1 = Methodref #4.#13 // java/lang/Object.\"&lt;init&gt;\":()V #2 = String #14 // hello #3 = Class #15 // Test #4 = Class #16 // java/lang/Object #5 = Utf8 &lt;init&gt; #6 = Utf8 ()V #7 = Utf8 Code #8 = Utf8 LineNumberTable #9 = Utf8 main #10 = Utf8 ([Ljava/lang/String;)V #11 = Utf8 SourceFile #12 = Utf8 Test.java #13 = NameAndType #5:#6 // \"&lt;init&gt;\":()V #14 = Utf8 hello #15 = Utf8 Test #16 = Utf8 java/lang/Object每一个类都会有一个常量池。summary要想了解JVM运行byte code，还需要了解更多JVM本身的东西，例如符号解析，内存管理等，可参考： JVM Internals Understanding JVM Internals" }, { "title": "基于内存查看STL常用容器内容", "url": "/posts/gdb_stl/", "categories": "c/c++", "tags": "stl", "date": "2014-12-03 00:00:00 +0800", "snippet": "有时候在线上使用gdb调试程序core问题时，可能没有符号文件，拿到的仅是一个内存地址，如果这个指向的是一个STL对象，那么如何查看这个对象的内容呢？只需要知道STL各个容器的数据结构实现，就可以查看其内容。本文描述了SGI STL实现中常用容器的数据结构，以及如何在gdb中查看其内容。stringstring，即basic_string bits/basic_string.h： mutable _Alloc_hider _M_dataplus; ... const _CharT* c_str() const { return _M_data(); } ... _CharT* _M_data() const { return _M_dataplus._M_p; } ... struct _Alloc_hider : _Alloc { _Alloc_hider(_CharT* __dat, const _Alloc&amp; __a) : _Alloc(__a), _M_p(__dat) { } _CharT* _M_p; // The actual data. }; size_type length() const { return _M_rep()-&gt;_M_length; } _Rep* _M_rep() const { return &amp;((reinterpret_cast&lt;_Rep*&gt; (_M_data()))[-1]); } ... struct _Rep_base { size_type _M_length; size_type _M_capacity; _Atomic_word _M_refcount; }; struct _Rep : _Rep_base即，string内有一个指针，指向实际的字符串位置，这个位置前面有一个_Rep结构，其内保存了字符串的长度、可用内存以及引用计数。当我们拿到一个string对象的地址时，可以通过以下代码获取相关值： void ds_str_i(void *p) { char **raw = (char**)p; char *s = *raw; size_t len = *(size_t*)(s - sizeof(size_t) * 3); printf(\"str: %s (%zd)\\n\", s, len); } size_t ds_str() { std::string s = \"hello\"; ds_str_i(&amp;s); return s.size(); }在gdb中拿到一个string的地址时，可以以下打印出该字符串及长度：(gdb) x/1a p0x7fffffffe3a0: 0x606028(gdb) p (char*)0x606028$2 = 0x606028 \"hello\"(gdb) x/1dg 0x606028-240x606010: 5vector众所周知vector实现就是一块连续的内存，bits/stl_vector.h。 template&lt;typename _Tp, typename _Alloc = std::allocator&lt;_Tp&gt; &gt; class vector : protected _Vector_base&lt;_Tp, _Alloc&gt; ... template&lt;typename _Tp, typename _Alloc&gt; struct _Vector_base { typedef typename _Alloc::template rebind&lt;_Tp&gt;::other _Tp_alloc_type; struct _Vector_impl : public _Tp_alloc_type { _Tp* _M_start; _Tp* _M_finish; _Tp* _M_end_of_storage; _Vector_impl(_Tp_alloc_type const&amp; __a) : _Tp_alloc_type(__a), _M_start(0), _M_finish(0), _M_end_of_storage(0) { } }; _Vector_impl _M_impl;可以看出sizeof(vector&lt;xxx&gt;)=24，其内也就是3个指针，_M_start指向首元素地址，_M_finish指向最后一个节点+1，_M_end_of_storage是可用空间最后的位置。 iterator end() { return iterator (this-&gt;_M_impl._M_finish); } const_iterator ... begin() const { return const_iterator (this-&gt;_M_impl._M_start); } ... size_type capacity() const { return size_type(const_iterator(this-&gt;_M_impl._M_end_of_storage) - begin()); }可以通过代码从一个vector对象地址输出其信息： template &lt;typename T&gt; void ds_vec_i(void *p) { T *start = *(T**)p; T *finish = *(T**)((char*)p + sizeof(void*)); T *end_storage = *(T**)((char*)p + 2 * sizeof(void*)); printf(\"vec size: %ld, avaiable size: %ld\\n\", finish - start, end_storage - start); } size_t ds_vec() { std::vector&lt;int&gt; vec; vec.push_back(0x11); vec.push_back(0x22); vec.push_back(0x33); ds_vec_i&lt;int&gt;(&amp;vec); return vec.size(); }使用gdb输出一个vector中的内容：(gdb) p p$3 = (void *) 0x7fffffffe380(gdb) x/1a p0x7fffffffe380: 0x606080(gdb) x/3xw 0x6060800x606080: 0x00000011 0x00000022 0x00000033list众所周知list被实现为一个链表。准确来说是一个双向链表。list本身是一个特殊节点，其代表end，其指向的下一个元素才是list真正的第一个节点：bits/stl_list.h bool empty() const { return this-&gt;_M_impl._M_node._M_next == &amp;this-&gt;_M_impl._M_node; } const_iterator begin() const { return const_iterator(this-&gt;_M_impl._M_node._M_next); } iterator end() { return iterator(&amp;this-&gt;_M_impl._M_node); } ... struct _List_node_base { _List_node_base* _M_next; ///&lt; Self-explanatory _List_node_base* _M_prev; ///&lt; Self-explanatory ... }; template&lt;typename _Tp&gt; struct _List_node : public _List_node_base { _Tp _M_data; ///&lt; User's data. }; template&lt;typename _Tp, typename _Alloc&gt; class _List_base { ... struct _List_impl : public _Node_alloc_type { _List_node_base _M_node; ... }; _List_impl _M_impl; template&lt;typename _Tp, typename _Alloc = std::allocator&lt;_Tp&gt; &gt; class list : protected _List_base&lt;_Tp, _Alloc&gt;所以sizeof(list&lt;xx&gt;)=16，两个指针。每一个真正的节点首先是包含两个指针，然后是元素内容(_List_node)。通过代码输出list的内容： #define NEXT(ptr, T) do { \\ void *n = *(char**)ptr; \\ T val = *(T*)((char**)ptr + 2); \\ printf(\"list item %p val: 0x%x\\n\", ptr, val); \\ ptr = n; \\ } while (0) template &lt;typename T&gt; void ds_list_i(void *p) { void *ptr = *(char**)p; NEXT(ptr, T); NEXT(ptr, T); NEXT(ptr, T); } size_t ds_list() { std::list&lt;int&gt; lst; lst.push_back(0x11); lst.push_back(0x22); lst.push_back(0x33); ds_list_i&lt;int&gt;(&amp;lst); return lst.size(); }在gdb中可以以下方式遍历该list：(gdb) p p$4 = (void *) 0x7fffffffe390(gdb) x/1a p0x7fffffffe390: 0x606080(gdb) x/1xw 0x606080+16 # 元素1 0x606090: 0x00000011(gdb) x/1a 0x6060800x606080: 0x6060a0(gdb) x/1xw 0x6060a0+16 # 元素20x6060b0: 0x00000022mapmap使用的是红黑树实现，实际使用的是stl_tree.h实现：bits/stl_map.h typedef _Rb_tree&lt;key_type, value_type, _Select1st&lt;value_type&gt;, key_compare, _Pair_alloc_type&gt; _Rep_type; ... _Rep_type _M_t; ... iterator begin() { return _M_t.begin(); }bits/stl_tree.h struct _Rb_tree_node_base { typedef _Rb_tree_node_base* _Base_ptr; typedef const _Rb_tree_node_base* _Const_Base_ptr; _Rb_tree_color _M_color; _Base_ptr _M_parent; _Base_ptr _M_left; _Base_ptr _M_right; ... }; template&lt;typename _Val&gt; struct _Rb_tree_node : public _Rb_tree_node_base { typedef _Rb_tree_node&lt;_Val&gt;* _Link_type; _Val _M_value_field; }; template&lt;typename _Key_compare, bool _Is_pod_comparator = std::__is_pod&lt;_Key_compare&gt;::__value&gt; struct _Rb_tree_impl : public _Node_allocator { _Key_compare _M_key_compare; _Rb_tree_node_base _M_header; size_type _M_node_count; // Keeps track of size of tree. ... } _Rb_tree_impl&lt;_Compare&gt; _M_impl; ... iterator begin() { return iterator(static_cast&lt;_Link_type&gt; (this-&gt;_M_impl._M_header._M_left)); }所以可以看出，大部分时候(取决于_M_key_compare) sizeof(map&lt;xx&gt;)=48，主要的元素是： _Rb_tree_color _M_color; // 节点颜色 _Base_ptr _M_parent; // 父节点 _Base_ptr _M_left; // 左节点 _Base_ptr _M_right; // 右节点 _Val _M_value_field // 同list中节点技巧一致，后面是实际的元素同list中的实现一致，map本身作为一个节点，其不是一个存储数据的节点，_Rb_tree::end iterator end() { return iterator(static_cast&lt;_Link_type&gt;(&amp;this-&gt;_M_impl._M_header)); }由于节点值在_Rb_tree_node_base后，所以任意时候拿到节点就可以偏移这个结构体拿到节点值，节点的值是一个pair，包含了key和value。在gdb中打印以下map的内容： size_t ds_map() { std::map&lt;std::string, int&gt; imap; imap[\"abc\"] = 0xbbb; return imap.size(); }(gdb) p/x &amp;imap$7 = 0x7fffffffe370(gdb) x/1a (char*)&amp;imap+24 # _M_left 真正的节点0x7fffffffe388: 0x606040 (gdb) x/1xw 0x606040+32+8 # 偏移32字节是节点值的地址，再偏移8则是value的地址0x606068: 0x00000bbb(gdb) p *(char**)(0x606040+32) # 偏移32字节是string的地址$8 = 0x606028 \"abc\"或者很多时候没有必要这么装逼+蛋疼：(gdb) p *(char**)(imap._M_t._M_impl._M_header._M_left+1)$9 = 0x606028 \"abc\"(gdb) x/1xw (char*)(imap._M_t._M_impl._M_header._M_left+1)+80x606068: 0x00000bbb完" }, { "title": "linux动态库的种种要点", "url": "/posts/linux-dynamic-library/", "categories": "c/c++", "tags": "dynamic, library", "date": "2014-11-04 00:00:00 +0800", "snippet": "linux下使用动态库，基本用起来还是很容易。但如果我们的程序中大量使用动态库来实现各种框架/插件，那么就会遇到一些坑，掌握这些坑才有利于程序更稳健地运行。本篇先谈谈动态库符号方面的问题。测试代码可以在github上找到符号查找一个应用程序test会链接一个动态库libdy.so，如果一个符号，例如函数callfn定义于libdy.so中，test要使用该函数，简单地声明即可：// dy.cpp libdy.sovoid callfn() { ...}// main.cpp testextern void callfn();callfn(); 在链接test的时候，链接器会统一进行检查。同样，在libdy.so中有相同的规则，它可以使用一个外部的符号，在它被链接/载入进一个可执行程序时才会进行符号存在与否的检查。这个符号甚至可以定义在test中，形成一种双向依赖，或定义在其他动态库中：// dy.cpp libdy.soextern void mfunc();mfunc();// main.cpp testvoid mfunc() { ...}在生成libdy.so时mfunc可以找不到，此时mfunc为未定义：$ nm libdy.so | grep mfunU _Z5mfuncv但在libdy.so被链接进test时则会进行检查，试着把mfunc函数的定义去掉，就会得到一个链接错误：./libdy.so: undefined reference to `mfunc()'同样，如果我们动态载入libdy.so，此时当然可以链接通过，但是在载入时同样得到找不到符号的错误：#ifdef DY_LOAD void *dp = dlopen(\"./libdy.so\", RTLD_LAZY); typedef void (*callfn)(); callfn f = (callfn) dlsym(dp, \"callfn\"); f(); dlclose(dp);#else callfn();#endif得到错误：./test: symbol lookup error: ./libdy.so: undefined symbol: _Z5mfuncv结论：基于以上，我们知道，如果一个动态库依赖了一些外部符号，这些外部符号可以位于其他动态库甚至应用程序中。我们可以再链接这个动态库的时候就把依赖的其他库也链接上，或者推迟到链接应用程序时再链接。而动态加载的库，则要保证在加载该库时，进程中加载的其他动态库里已经存在该符号。例如，通过LD_PRELOAD环境变量可以让一个进程先加载指定的动态库，上面那个动态加载启动失败的例子，可以通过预先加载包含mfunc符号的动态库解决：$ LD_PRELOAD=libmfun.so ./test...但是如果这个符号存在于可执行程序中则不行：$ nm test | grep mfunc0000000000400a00 T _Z5mfuncv$ nm test | grep mfunc0000000000400a00 T _Z5mfuncv$ ./test..../test: symbol lookup error: ./libdy.so: undefined symbol: _Z5mfuncv符号覆盖前面主要讲的是符号缺少的情况，如果同一个符号存在多分，则更能引发问题。这里谈到的符号都是全局符号，一个进程中某个全局符号始终是全局唯一的。为了保证这一点，在链接或动态载入动态库时，就会出现忽略重复符号的情况。这里就不提同一个链接单位（如可执行程序、动态库）里符号重复的问题了函数当动态库和libdy.so可执行程序test中包含同名的函数时会怎样？根据是否动态加载情况还有所不同。当直接链接动态库时，libdy.so和test都会链接包含func函数的fun.o，为了区分，我把func按照条件编译得到不同的版本：// fun.cpp#ifdef V2extern \"C\" void func() { printf(\"func v2\\n\");}#elseextern \"C\" void func() { printf(\"func v1\\n\");}#endif// Makefiletest: libdy obj.o mainfn g++ -g -Wall -c fun.cpp -o fun.o # 编译为fun.o g++ -g -Wall -c main.cpp #-DDY_LOAD g++ -g -Wall -o test main.o obj.o fun.o -ldl mfun.o -ldy -L.libdy: obj g++ -Wall -fPIC -c fun.cpp -DV2 -o fun-dy.o # 定义V2宏，编译为fun-dy.o g++ -Wall -fPIC -shared -o libdy.so dy.cpp -g obj.o fun-dy.o这样，test中的func就会输出func v1；libdy.so中的func就会输出func v2。test和libdy.o确实都有func符号：$ nm libdy.so | grep func0000000000000a60 T func$nm test | grep func0000000000400a80 T func在test和libdy.so中都会调用func函数：// main.cpp testint main(int argc, char **argv) { func(); ... callfn(); // 调用libdy.so中的函数 ...}// dy.cpp libdy.soextern \"C\" void callfn() { ... printf(\"callfn\\n\"); func(); ...}运行后发现，都调用的是同一个func：$ ./test...func v1...callfnfunc v1结论，直接链接动态库时，整个程序运行的时候符号会发生覆盖，只有一个符号被使用。在实践中，如果程序和链接的动态库都依赖了一个静态库，而后他们链接的这个静态库版本不同，则很有可能因为符号发生了覆盖而导致问题。(静态库同普通的.o性质一样，参考浅析静态库链接原理)更复杂的情况中，多个动态库和程序都有相同的符号，情况也是一样，会发生符号覆盖。如果程序里没有这个符号，而多个动态库里有相同的符号，也会覆盖。但是对于动态载入的情况则不同，同样的libdy.so我们在test中不链接，而是动态载入：int main(int argc, char **argv) { func();#ifdef DY_LOAD void *dp = dlopen(\"./libdy.so\", RTLD_LAZY); typedef void (*callfn)(); callfn f = (callfn) dlsym(dp, \"callfn\"); f(); func(); dlclose(dp);#else callfn();#endif return 0;}运行得到：$ ./testfunc v1...callfnfunc v2func v1都正确地调用到各自链接的func。结论，实践中，动态载入的动态库一般会作为插件使用，那么其同程序链接不同版本的静态库（相同符号不同实现），是没有问题的。变量变量本质上也是符号(symbol)，但其处理规则和函数还有点不一样(是不是有点想吐槽了)。// object.hclass Object {public: Object() {#ifdef DF s = malloc(32); printf(\"s addr %p\\n\", s);#endif printf(\"ctor %p\\n\", this); } ~Object() { printf(\"dtor %p\\n\", this);#ifdef DF printf(\"s addr %p\\n\", s); free(s);#endif } void *s;};extern Object g_obj;我们的程序test和动态库libdy.so都会链接object.o。首先测试test链接libdy.so，test和libdy.so中都会有g_obj这个符号：// B g_obj 表示g_obj位于BSS段，未初始化段$ nm test | grep g_obj0000000000400a14 t _GLOBAL__I_g_obj00000000006012c8 B g_obj$ nm libdy.so | grep g_obj000000000000097c t _GLOBAL__I_g_obj0000000000200f30 B g_obj运行：$ ./testctor 0x6012c8ctor 0x6012c8...dtor 0x6012c8dtor 0x6012c8g_obj被构造了两次，但地址一样。全局变量只有一个实例，似乎在情理之中。动态载入libdy.so，变量地址还是相同的：$ ./testctor 0x6012a8...ctor 0x6012a8...dtor 0x6012a8dtor 0x6012a8结论，不同于函数，全局变量符号重复时，不论动态库是动态载入还是直接链接，变量始终只有一个。但诡异的情况是，对象被构造和析构了两次。构造两次倒无所谓，浪费点空间，但是析构两次就有问题。因为析构时都操作的是同一个对象，那么如果这个对象内部有分配的内存，那就会对这块内存造成double free，因为指针相同。打开DF宏实验下：$ ./tests addr 0x20de010ctor 0x6012b8s addr 0x20de040ctor 0x6012b8...dtor 0x6012b8s addr 0x20de040dtor 0x6012b8s addr 0x20de040因为析构的两次都是同一个对象，所以其成员s指向的内存被释放了两次，从而产生了double free，让程序coredump了。总结，全局变量符号重复时，始终会只使用一个，并且会被初始化/释放两次，是一种较危险的情况，应当避免在使用动态库的过程中使用全局变量。完" }, { "title": "图解zookeeper FastLeader选举算法", "url": "/posts/zk-fastleaderelection/", "categories": "network", "tags": "zookeeper", "date": "2014-10-19 00:00:00 +0800", "snippet": "zookeeper配置为集群模式时，在启动或异常情况时会选举出一个实例作为Leader。其默认选举算法为FastLeaderElection。不知道zookeeper的可以考虑这样一个问题：某个服务可以配置为多个实例共同构成一个集群对外提供服务。其每一个实例本地都存有冗余数据，每一个实例都可以直接对外提供读写服务。在这个集群中为了保证数据的一致性，需要有一个Leader来协调一些事务。那么问题来了：如何确定哪一个实例是Leader呢？问题的难点在于： 没有一个仲裁者来选定Leader 每一个实例本地可能已经存在数据，不确定哪个实例上的数据是最新的分布式选举算法正是用来解决这个问题的。本文基于zookeeper 3.4.6 的源码进行分析。FastLeaderElection算法的源码全部位于FastLeaderElection.java文件中，其对外接口为FastLeaderElection.lookForLeader，该接口是一个同步接口，直到选举结束才会返回。同样由于网上已有类似文章，所以我就从图示的角度来阐述。阅读一些其他文章有利于获得初步印象： 深入浅出Zookeeper之五 Leader选举，代码导读 zookeeper3.3.3源码分析(二)FastLeader选举算法，文字描述较细主要流程阅读代码和以上推荐文章可以把整个流程梳理清楚。实现上，包括了一个消息处理主循环，也是选举的主要逻辑，以及一个消息发送队列处理线程和消息解码线程。主要流程可概括为下图：推荐对照着推荐的文章及代码理解，不赘述。我们从感性上来理解这个算法。每一个节点，相当于一个选民，他们都有自己的推荐人，最开始他们都推荐自己。谁更适合成为Leader有一个简单的规则，例如sid够大（配置）、持有的数据够新(zxid够大)。每个选民都告诉其他选民自己目前的推荐人是谁，类似于出去搞宣传拉拢其他选民。每一个选民发现有比自己更适合的人时就转而推荐这个更适合的人。最后，大部分人意见一致时，就可以结束选举。就这么简单。总体上有一种不断演化逼近结果的感觉。当然，会有些特殊情况的处理。例如总共3个选民，1和2已经确定3是Leader，但3还不知情，此时就走入LEADING/FOLLOWING的分支，选民3只是接收结果。代码中不是所有逻辑都在这个大流程中完成的。在接收消息线程中，还可能单独地回应某个节点(WorkerReceiver.run)：从这里可以看出，当某个节点已经确定选举结果不再处于LOOKING状态时，其收到LOOKING消息时都会直接回应选举的最终结果。结合上面那个比方，相当于某次选举结束了，这个时候来了选民4又发起一次新的选举，那么其他选民就直接告诉它当前的Leader情况。相当于，在这个集群主从已经就绪的情况下，又开启了一个实例，这个实例就会直接使用当前的选举结果。状态转换每个节点上有一些关键的数据结构： 当前推荐人，初始推荐自己，每次收到其他更好的推荐人时就更新 其他人的投票集合，用于确定何时选举结束每次推荐人更新时就会进行广播，正是这个不断地广播驱动整个算法趋向于结果。假设有3个节点A/B/C，其都还没有数据，按照sid关系为C&gt;B&gt;A，那么按照规则，C更可能成为Leader，其各个节点的状态转换为：图中，v(A)表示当前推荐人为A；r[]表示收到的投票集合。需要注意一个细节，初始投票集合里包含了自己的投票，代码中自己会将推荐人推荐给自己，网络模块(QuorumCnxManager)直接将该消息放入接收队列。可以看看当其他节点已经确定投票结果时，即不再是LOOKING时的状态：代码中有一个特殊的投票集合outofelection，我理解为选举已结束的那些投票，这些投票仅用于表征选举结果。当一个新启动的节点加入集群时，它对集群内其他节点发出投票请求，而其他节点已不处于LOOKING状态，此时其他节点回应选举结果，该节点收集这些结果到outofelection中，最终在收到合法LEADER消息且这些选票也构成选举结束条件时，该节点就结束自己的选举行为。注意到代码中会logicalclock = n.electionEpoch;更新选举轮数完" }, { "title": "图解分布式一致性协议Paxos", "url": "/posts/explain-poxos/", "categories": "network", "tags": "paxos", "date": "2014-10-15 00:00:00 +0800", "snippet": "Paxos协议/算法是分布式系统中比较重要的协议，它有多重要呢？[](http://coolshell.cn/articles/10910.html)： Google Chubby的作者Mike Burrows说过这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品。[](http://book.douban.com/subject/25723658/)： 理解了这两个分布式协议之后(Paxos/2PC)，学习其他分布式协议会变得相当容易。学习Paxos算法有两部分：a) 算法的原理/证明；b) 算法的理解/运作。理解这个算法的运作过程其实基本就可以用于工程实践。而且理解这个过程相对来说也容易得多。网上我觉得讲Paxos讲的好的属于这篇：paxos图解及Paxos算法详解，我这里就结合wiki上的实例进一步阐述。一些paxos基础通过这里提到的两篇文章，以及wiki上的内容基本可以理解。算法内容Paxos在原作者的《Paxos Made Simple》中内容是比较精简的： Phase 1 (a) A proposer selects a proposal number n and sends a prepare request with number n to a majority of acceptors. (b) If an acceptor receives a prepare request with number n greater than that of any prepare request to which it has already responded, then it responds to the request with a promise not to accept any more proposals numbered less than n and with the highest-numbered pro-posal (if any) that it has accepted. Phase 2 (a) If the proposer receives a response to its prepare requests (numbered n) from a majority of acceptors, then it sends an accept request to each of those acceptors for a proposal numbered n with a value v , where v is the value of the highest-numbered proposal among the responses, or is any value if the responses reported no proposals. (b) If an acceptor receives an accept request for a proposal numbered n, it accepts the proposal unless it has already responded to a prepare request having a number greater than n.借用paxos图解文中的流程图可概括为：实例及详解Paxos中有三类角色Proposer、Acceptor及Learner，主要交互过程在Proposer和Acceptor之间。Proposer与Acceptor之间的交互主要有4类消息通信，如下图：这4类消息对应于paxos算法的两个阶段4个过程： phase 1 a) proposer向网络内超过半数的acceptor发送prepare消息 b) acceptor正常情况下回复promise消息 phase 2 a) 在有足够多acceptor回复promise消息时，proposer发送accept消息 b) 正常情况下acceptor回复accepted消息 因为在整个过程中可能有其他proposer针对同一件事情发出以上请求，所以在每个过程中都会有些特殊情况处理，这也是为了达成一致性所做的事情。如果在整个过程中没有其他proposer来竞争，那么这个操作的结果就是确定无异议的。但是如果有其他proposer的话，情况就不一样了。以paxos中文wiki上的例子为例。简单来说该例子以若干个议员提议税收，确定最终通过的法案税收比例。以下图中基本只画出proposer与一个acceptor的交互。时间标志T2总是在T1后面。propose number简称N。情况之一如下图：A3在T1发出accepted给A1，然后在T2收到A5的prepare，在T3的时候A1才通知A5最终结果(税率10%)。这里会有两种情况： A5发来的N5小于A1发出去的N1，那么A3直接拒绝(reject)A5 A5发来的N5大于A1发出去的N1，那么A3回复promise，但带上A1的(N1, 10%)这里可以与paxos流程图对应起来，更好理解。acceptor会记录(MaxN, AcceptN, AcceptV)。A5在收到promise后，后续的流程可以顺利进行。但是发出accept时，因为收到了(AcceptN, AcceptV)，所以会取最大的AcceptN对应的AcceptV，例子中也就是A1的10%作为AcceptV。如果在收到promise时没有发现有其他已记录的AcceptV，则其值可以由自己决定。针对以上A1和A5冲突的情况，最终A1和A5都会广播接受的值为10%。其实4个过程中对于acceptor而言，在回复promise和accepted时由于都可能因为其他proposer的介入而导致特殊处理。所以基本上看在这两个时间点收到其他proposer的请求时就可以了解整个算法了。例如在回复promise时则可能因为proposer发来的N不够大而reject：如果在发accepted消息时，对其他更大N的proposer发出过promise，那么也会reject该proposer发出的accept，如图：这个对应于Phase 2 b)： it accepts the proposal unless it has already responded to a prepare request having a number greater than n.总结Leslie Lamport没有用数学描述Paxos，但是他用英文阐述得很清晰。将Paxos的两个Phase的内容理解清楚，整个算法过程还是不复杂的。至于Paxos中一直提到的一个全局唯一且递增的proposer number，其如何实现，引用如下： 如何产生唯一的编号呢？在《Paxos made simple》中提到的是让所有的Proposer都从不相交的数据集合中进行选择，例如系统有5个Proposer，则可为每一个Proposer分配一个标识j(0~4)，则每一个proposer每次提出决议的编号可以为5*i + j(i可以用来表示提出议案的次数)参考文档 paxos图解, http://coderxy.com/archives/121 Paxos算法详解, http://coderxy.com/archives/136 Paxos算法 wiki, http://zh.wikipedia.org/zh-cn/Paxos%E7%AE%97%E6%B3%95#.E5.AE.9E.E4.BE.8B" }, { "title": "淘宝分布式配置管理服务Diamond", "url": "/posts/diamond/", "categories": "network", "tags": "diamond", "date": "2014-10-12 00:00:00 +0800", "snippet": "在一个分布式环境中，同类型的服务往往会部署很多实例。这些实例使用了一些配置，为了更好地维护这些配置就产生了配置管理服务。通过这个服务可以轻松地管理这些应用服务的配置问题。应用场景可概括为：zookeeper的一种应用就是分布式配置管理(基于ZooKeeper的配置信息存储方案的设计与实现)。百度也有类似的实现：disconf。Diamond则是淘宝开源的一种分布式配置管理服务的实现。Diamond本质上是一个Java写的Web应用，其对外提供接口都是基于HTTP协议的，在阅读代码时可以从实现各个接口的controller入手。分布式配置管理分布式配置管理的本质基本上就是一种推送-订阅模式的运用。配置的应用方是订阅者，配置管理服务则是推送方。概括为下图：其中，客户端包括管理人员publish数据到配置管理服务，可以理解为添加/更新数据；配置管理服务notify数据到订阅者，可以理解为推送。配置管理服务往往会封装一个客户端库，应用方则是基于该库与配置管理服务进行交互。在实际实现时，客户端库可能是主动拉取(pull)数据，但对于应用方而言，一般是一种事件通知方式。Diamond中的数据是简单的key-value结构。应用方订阅数据则是基于key来订阅，未订阅的数据当然不会被推送。数据从类型上又划分为聚合和非聚合。因为数据推送者可能很多，在整个分布式环境中，可能有多个推送者在推送相同key的数据，这些数据如果是聚合的，那么所有这些推送者推送的数据会被合并在一起；反之如果是非聚合的，则会出现覆盖。数据的来源可能是人工通过管理端录入，也可能是其他服务通过配置管理服务的推送接口自动录入。架构及实现Diamond服务是一个集群，是一个去除了单点的协作集群。如图：图中可分为以下部分讲解：服务之间同步Diamond服务集群每一个实例都可以对外完整地提供服务，那么意味着每个实例上都有整个集群维护的数据。Diamond有两种方式保证这一点： 任何一个实例都有其他实例的地址；任何一个实例上的数据变更时，都会将改变的数据同步到mysql上，然后通知其他所有实例从mysql上进行一次数据拉取(DumpService::dump)，这个过程只拉取改变了的数据 任何一个实例启动后都会以较长的时间间隔（几小时），从mysql进行一次全量的数据拉取(DumpAllProcessor)实现上为了一致性，通知其他实例实际上也包含自己。以服务器收到添加聚合数据为例，处理过程大致为：DatumController::addDatum // /datum.do?method=addDatum PersistService::addAggrConfigInfo MergeDatumService::addMergeTask // 添加一个MergeDataTask，异步处理MergeTaskProcessor::process PersistService::insertOrUpdate EventDispatcher.fireEvent(new ConfigDataChangeEvent // 派发一个ConfigDataChangeEvent事件NotifyService::onEvent // 接收事件并处理 TaskManager::addTask(..., new NotifyTask // 由此，当数据发生变动，则最终创建了一个NoticyTask// NotifyTask同样异步处理NotifyTaskProcessor::process foreach server in serverList // 包含自己 notifyToDump // 调用 /notify.do?method=notifyConfigInfo 从mysql更新变动的数据虽然Diamond去除了单点问题，不过问题都下降到了mysql上。但由于其作为配置管理的定位，其数据量就mysql的应用而言算小的了，所以可以一定程度上保证整个服务的可用性。数据一致性由于Diamond服务器没有master，任何一个实例都可以读写数据，那么针对同一个key的数据则可能面临冲突。这里应该是通过mysql来保证数据的一致性。每一次客户端请求写数据时，Diamond都将写请求投递给mysql，然后通知集群内所有Diamond实例（包括自己）从mysql拉取数据。当然，拉取数据则可能不是每一次写入都能拉出来，也就是最终一致性。Diamond中没有把数据放入内存，但会放到本地文件。对于客户端的读操作而言，则是直接返回本地文件里的数据。服务实例列表Diamond服务实例列表是一份静态数据，直接将每个实例的地址存放在一个web server上。无论是Diamond服务还是客户端都从该web server上取出实例列表。对于客户端而言，当其取出了该列表后，则是随机选择一个节点(ServerListManager.java)，以后的请求都会发往该节点。数据同步客户端库中以固定时间间隔从服务器拉取数据(ClientWorker::ClientWorker，ClientWorker::checkServerConfigInfo)。只有应用方关心的数据才可能被拉取。另外，为了数据推送的及时，Diamond还使用了一种long polling的技术，其实也是为了突破HTTP协议的局限性。如果整个服务是基于TCP的自定义协议，客户端与服务器保持长连接则没有这些问题。数据的变更Diamond中很多操作都会检查数据是否发生了变化。标识数据变化则是基于数据对应的MD5值来实现的。容灾在整个Diamond系统中，几个角色为了提高容灾性，都有自己的缓存，概括为下图：每一个角色出问题时，都可以尽量保证客户端对应用层提供服务。参考文档 diamond project diamond专题 中间件技术及双十一实践·软负载篇" }, { "title": "浅析glibc中thread tls的一处bug", "url": "/posts/pthread-tls-bug/", "categories": "c/c++", "tags": "pthread, tls", "date": "2014-10-07 00:00:00 +0800", "snippet": "最早的时候是在程序初始化过程中开启了一个timer(timer_create)，这个timer第一次触发的时间较短时就会引起程序core掉，core的位置也是不定的。使用valgrind可以发现有错误的内存写入：==31676== Invalid write of size 8==31676== at 0x37A540F852: _dl_allocate_tls_init (in /lib64/ld-2.5.so)==31676== by 0x4E26BD3: pthread_create@@GLIBC_2.2.5 (in /lib64/libpthread-2.5.so)==31676== by 0x76E0B00: timer_helper_thread (in /lib64/librt-2.5.so)==31676== by 0x4E2673C: start_thread (in /lib64/libpthread-2.5.so)==31676== by 0x58974BC: clone (in /lib64/libc-2.5.so)==31676== Address 0xf84dbd0 is 0 bytes after a block of size 336 alloc'd==31676== at 0x4A05430: calloc (vg_replace_malloc.c:418)==31676== by 0x37A5410082: _dl_allocate_tls (in /lib64/ld-2.5.so)==31676== by 0x4E26EB8: pthread_create@@GLIBC_2.2.5 (in /lib64/libpthread-2.5.so)==31676== by 0x76E0B00: timer_helper_thread (in /lib64/librt-2.5.so)==31676== by 0x4E2673C: start_thread (in /lib64/libpthread-2.5.so)==31676== by 0x58974BC: clone (in /lib64/libc-2.5.so)google _dl_allocate_tls_init 相关发现一个glibc的bug Bug 13862 和我的情况有点类似。本文就此bug及tls相关实现做一定阐述。需要查看glibc的源码，如何确认使用的glibc的版本，可以这样：$ /lib/libc.so.6GNU C Library stable release version 2.5, by Roland McGrath et al....为了方便，还可以直接在(glibc Cross Reference)[http://osxr.org/glibc/source/?v=glibc-2.17]网页上进行查看，版本不同，但影响不大。BUG描述要重现13862 BUG作者提到要满足以下条件： The use of a relatively large number of dynamic libraries, loaded at runtime using dlopen. The use of thread-local-storage within those libraries. A thread exiting prior to the number of loaded libraries increasing a significant amount, followed by a new thread being created after the number of libraries has increased.简单来说，就是在加载一大堆包含TLS变量的动态库的过程中，开启了一个线程，这个线程退出后又开启了另一个线程。这和我们的问题场景很相似。不同的是我们使用的是timer，但timer在触发时也是开启新的线程，并且这个线程会立刻退出：/nptl/sysdeps/unix/sysv/linux/timer_routines.ctimer_helper_thread(...) // 用于检测定时器触发的辅助线程{ ... pthread_t th; (void) pthread_create (&amp;th, &amp;tk-&gt;attr, timer_sigev_thread, // 开启一个新线程调用用户注册的定时器函数 td); ...} 要重现此BUG可以使用我的实验代码 thread-tls，或者使用Bug 13862 中的附件TLS相关实现可以顺着_dl_allocate_tls_init函数的实现查看相关联的部分代码。该函数遍历所有加载的包含TLS变量的模块，初始化一个线程的TLS数据结构。每一个线程都有自己的堆栈空间，其中单独存储了各个模块的TLS变量，从而实现TLS变量在每一个线程中都有单独的拷贝。TLS与线程的关联关系可以查看下图：应用层使用的pthread_t实际是个pthread对象的地址。创建线程时线程的堆栈空间和pthread结构是一块连续的内存。但这个地址并不指向这块内存的首地址。相关代码：/nptl/allocatestack.c allocate_stack，该函数分配线程的堆栈内存。pthread第一个成员是tcbhead_t，tcbhead_t中dtv指向了一个dtv_t数组，该数组的大小随着当前程序载入的模块多少而动态变化。每一个模块被载入时，都有一个l_tls_modid，其直接作为dtv_t数组的下标索引。tcbhead_t中的dtv实际指向的是dtv_t第二个元素，第一个元素用于记录整个dtv_t数组有多少元素，第二个元素也做特殊使用，从第三个元素开始，才是用于存储TLS变量。一个dtv_t存储的是一个模块中所有TLS变量的地址，当然这些TLS变量都会被放在连续的内存空间里。dtv_t::pointer::val正是用于指向这块内存的指针。对于非动态加载的模块它指向的是线程堆栈的位置；否则指向动态分配的内存位置。以上结构用代码描述为，union dtv_t { size_t counter; struct { void *val; /* point to tls variable memory */ bool is_static; } pointer;}; struct tcbhead_t { void *tcb; dtv_t *dtv; /* point to a dtv_t array */ void *padding[22]; /* other members i don't care */};struct pthread { tcbhead_t tcb; /* more members i don't care */};dtv是一个用于以模块为单位存储TLS变量的数组。实际代码参看 /nptl/descr.h 及 nptl/sysdeps/x86_64/tls.h。实验使用g++ -o thread -g -Wall -lpthread -ldl thread.cpp编译代码，即在创建线程前加载了一个.so：Breakpoint 1, dump_pthread (id=1084229952) at thread.cpp:4040 printf(\"pthread %p, dtv %p\\n\", pd, dtv);(gdb) set $dtv=pd-&gt;tcb.dtv(gdb) p $dtv[-1]$1 = {counter = 17, pointer = {val = 0x11, is_static = false}}(gdb) p $dtv[3]$2 = {counter = 18446744073709551615, pointer = {val = 0xffffffffffffffff, is_static = false}}dtv[3]对应着动态加载的模块，is_static=false，val被初始化为-1：/elf/dl-tls.c _dl_allocate_tls_initif (map-&gt;l_tls_offset == NO_TLS_OFFSET || map-&gt;l_tls_offset == FORCED_DYNAMIC_TLS_OFFSET) { /* For dynamically loaded modules we simply store the value indicating deferred allocation. */ dtv[map-&gt;l_tls_modid].pointer.val = TLS_DTV_UNALLOCATED; dtv[map-&gt;l_tls_modid].pointer.is_static = false; continue; }dtv数组大小之所以为17，可以参看代码 /elf/dl-tls.c allocate_dtv：// dl_tls_max_dtv_idx 随着载入模块的增加而增加，载入1个.so则是1 dtv_length = GL(dl_tls_max_dtv_idx) + DTV_SURPLUS; // DTV_SURPLUS 14dtv = calloc (dtv_length + 2, sizeof (dtv_t));if (dtv != NULL) { /* This is the initial length of the dtv. */ dtv[0].counter = dtv_length;继续上面的实验，当调用到.so中的function时，其TLS被初始化，此时dtv[3]中val指向初始化后的TLS变量地址：68 fn();(gdb)0x601808, 0x601804, 0x60180072 return 0;(gdb) p $dtv[3]$3 = {counter = 6297600, pointer = {val = 0x601800, is_static = false}}(gdb) x/3xw 0x6018000x601800: 0x55667788 0xaabbccdd 0x11223344这个时候还可以看看dtv[1]中的内容，正是指向了pthread前面的内存位置：(gdb) p $dtv[1]$5 = {counter = 1084229936, pointer = {val = 0x40a00930, is_static = true}}(gdb) p/x tid$7 = 0x40a00940结论: 线程中TLS变量的存储是以模块为单位的so模块加载这里也并不太需要查看dlopen等具体实现，由于使用__thread来定义TLS变量，整个实现涉及到ELF加载器的一些细节，深入下去内容较多。这里直接通过实验的手段来了解一些实现即可。上文已经看到，在创建线程前如果动态加载了.so，dtv数组的大小是会随之增加的。如果是在线程创建后再载入.so呢？使用g++ -o thread -g -Wall -lpthread -ldl thread.cpp -DTEST_DTV_EXPAND -DSO_CNT=1编译程序，调试得到：73 load_sos();(gdb)0x601e78, 0x601e74, 0x601e70Breakpoint 1, dump_pthread (id=1084229952) at thread.cpp:4444 printf(\"pthread %p, dtv %p\\n\", pd, dtv);(gdb) p $dtv[-1]$3 = {counter = 17, pointer = {val = 0x11, is_static = false}}(gdb) p $dtv[4]$4 = {counter = 6299248, pointer = {val = 0x601e70, is_static = false}}在新载入了.so时，dtv数组大小并没有新增，dtv[4]直接被拿来使用。因为dtv初始大小为16，那么当载入的.so超过这个数字的时候会怎样？使用g++ -o thread -g -Wall -lpthread -ldl thread.cpp -DTEST_DTV_EXPAND编译程序：...pthread 0x40a00940, dtv 0x6016a0...Breakpoint 1, dump_pthread (id=1084229952) at thread.cpp:4444 printf(\"pthread %p, dtv %p\\n\", pd, dtv);(gdb) p dtv$2 = (dtv_t *) 0x6078a0(gdb) p dtv[-1]$3 = {counter = 32, pointer = {val = 0x20, is_static = false}}(gdb) p dtv[5]$4 = {counter = 6300896, pointer = {val = 0x6024e0, is_static = false}}可以看出，dtv被重新分配了内存(0x6016a0 -&gt; 0x6078a0)并做了扩大。以上得出结论： 创建线程前dtv的大小会根据载入模块数量决定 创建线程后新载入的模块会动态扩展dtv的大小(必要的时候)pthread堆栈重用在allocate_stack中分配线程堆栈时，有一个从缓存中取的操作：allocate_stack(..) { ... pd = get_cached_stack (&amp;size, &amp;mem); ...}/* Get a stack frame from the cache. We have to match by size since some blocks might be too small or far too large. */get_cached_stack(...) { ... list_for_each (entry, &amp;stack_cache) // 根据size从stack_cache中取 { ... } ... /* Clear the DTV. */ dtv_t *dtv = GET_DTV (TLS_TPADJ (result)); for (size_t cnt = 0; cnt &lt; dtv[-1].counter; ++cnt) if (! dtv[1 + cnt].pointer.is_static &amp;&amp; dtv[1 + cnt].pointer.val != TLS_DTV_UNALLOCATED) free (dtv[1 + cnt].pointer.val); memset (dtv, '\\0', (dtv[-1].counter + 1) * sizeof (dtv_t)); /* Re-initialize the TLS. */ _dl_allocate_tls_init (TLS_TPADJ (result));}get_cached_stack会把取出的pthread中的dtv重新初始化。注意 _dl_allocate_tls_init 中是根据模块列表来初始化dtv数组的。实验当一个线程退出后，它就可能被当做cache被get_cached_stack取出复用。使用g++ -o thread -g -Wall -lpthread -ldl thread.cpp -DTEST_CACHE_STACK编译程序，运行：$ ./thread..pthread 0x413c9940, dtv 0x1be46a0... pthread 0x413c9940, dtv 0x1be46a0回顾BUG当新创建的线程复用了之前退出的线程堆栈时，由于在_dl_allocate_tls_init中初始化dtv数组时是根据当前载入的模块数量而定。如果在这个时候模块数已经超过了这个复用的dtv数组大小，那么就会出现写入非法的内存。使用valgrind检测就会得到本文开头提到的结果。由于dtv数组大小通常会稍微大点，所以在新加载的模块数量不够多时程序还不会有问题。可以通过控制测试程序中SO_CNT的大小看看dtv中内容的变化。另外，我查看了下glibc的更新历史，到目前为止(2.20)这个BUG还没有修复。参考文档 glibc Bug 13862 - Reuse of cached stack can cause bounds overrun of thread DTV gLibc TLS实现 Linux线程之线程栈 Linux用户空间线程管理介绍之二：创建线程堆栈" }, { "title": "zookeeper节点数与watch的性能测试", "url": "/posts/zk-watch-benchmark/", "categories": "network", "tags": "zookeeper, watch", "date": "2014-09-21 00:00:00 +0800", "snippet": "zookeeper中节点数量理论上仅受限于内存，但一个节点下的子节点数量受限于request/response 1M数据 (size of data / number of znodes)zookeeper的watch机制用于数据变更时zookeeper的主动通知。watch可以被附加到每一个节点上，那么如果一个应用有10W个节点，那zookeeper中就可能有10W个watch（甚至更多）。每一次在zookeeper完成改写节点的操作时就会检测是否有对应的watch，有的话则会通知到watch。Zookeeper-Watcher机制与异步调用原理本文将关注以下内容： zookeeper的性能是否会受节点数量的影响 zookeeper的性能是否会受watch数量的影响测试方法在3台机器上分别部署一个zookeeper，版本为3.4.3，机器配置：Intel(R) Xeon(R) CPU E5-2430 0 @ 2.20GHz16Gjava version \"1.6.0_32\"Java(TM) SE Runtime Environment (build 1.6.0_32-b05)OpenJDK (Taobao) 64-Bit Server VM (build 20.0-b12-internal, mixed mode)大部分实验JVM堆大小使用默认，也就是1/4 RAM：java -XX:+PrintFlagsFinal -version | grep HeapSize测试客户端使用zk-smoketest，针对watch的测试则是我自己写的。基于zk-smoketest我写了些脚本可以自动跑数据并提取结果，相关脚本可以在这里找到：https://github.com/kevinlynx/zk-benchmark测试结果节点数对读写性能的影响测试最大10W个节点，度量1秒内操作数(ops)：可见节点数的增加并不会对zookeeper读写性能造成影响。节点数据大小对读写性能的影响这个网上其实已经有公认的结论。本身单个节点数据越大，对网络方面的吞吐就会造成影响，所以其数据越大读写性能越低也在预料之中。写数据会在zookeeper集群内进行同步，所以其速度整体会比读数据更慢。该实验需要把超时时间进行一定上调，同时我也把JVM最大堆大小调整到8G。测试结果很明显，节点数据大小会严重影响zookeeper效率。watch对读写性能的影响zk-smoketest自带的latency测试有个参数--watch_multiple用来指定watch的数量，但其实仅是指定客户端的数量，在server端通过echo whcp | nc 127.0.0.1 4181会发现实际每个节点还是只有一个watch。在我写的测试中，则是通过创建多个客户端来模拟单个节点上的多个watch。这也更符合实际应用。同时对节点的写也是在另一个独立的客户端中，这样可以避免zookeeper client的实现对测试带来的干扰。每一次完整的测试，首先是对每个节点添加节点数据的watch，然后在另一个客户端中对这些节点进行数据改写，收集这些改写操作的耗时，以确定添加的watch对这些写操作带来了多大的影响。图中，0 watch表示没有对节点添加watch；1 watch表示有一个客户端对每个节点进行了watch；3 watch表示有其他3个客户端对每个节点进行了watch；依次类推。可见，watch对写操作还是有较大影响的，毕竟需要进行网络传输。同样，这里也显示出整个zookeeper的watch数量同节点数量一样对整体性能没有影响。总体结论 对单个节点的操作并不会因为zookeeper中节点的总数而受到影响 数据大小对zookeeper的性能有较大影响，性能和内存都会 单个节点上独立session的watch数对性能有一定影响" }, { "title": "浅析静态库链接原理", "url": "/posts/inside-static-library/", "categories": "c/c++", "tags": "static library, archive", "date": "2014-09-15 00:00:00 +0800", "snippet": "静态库的链接基本上同链接目标文件.obj/.o相同，但也有些不同的地方。本文简要描述linux下静态库在链接过程中的一些细节。静态库文件格式静态库远远不同于动态库，不涉及到符号重定位之类的问题。静态库本质上只是将一堆目标文件进行打包而已。静态库没有标准，不同的linux下都会有些细微的差别。大致的格式wiki上描述的较清楚：Global header----------------- +-------------------------------File header 1 ---&gt; | File nameFile content 1 | | File modification timestamp ----------------- | Owner IDFile header 2 | Group IDFile content 2 | File mode----------------- | File size in bytes... | File magic +-------------------------------File header很多字段都是以ASCII码表示，所以可以用文本编辑器打开。静态库本质上就是使用ar命令打包一堆.o文件。我们甚至可以用ar随意打包一些文件：$ echo 'hello' &gt; a.txt &amp;&amp; echo 'world' &gt; b.txt$ ar -r test.a a.txt b.txt$ cat test.a!&lt;arch&gt;a.txt/ 1410628755 60833 100 100644 6 `hellob.txt/ 1410628755 60833 100 100644 6 `world &lt;!-- more --&gt;链接过程链接器在链接静态库时，同链接一般的.o基本相似。链接过程大致可以归纳下图：总结为： 所有传入链接器的.o都会被链接进最终的可执行程序；链接.o时，会将.o中的global symbol和unresolved symbol放入一个临时表 如果多个.o定义了相同的global symbol，那么就会得到多重定义的链接错误 如果链接结束了，unresolved symbol表不为空，那么就会得到符号未定义的链接错误 .a静态库处理本质上就是处理其中的每一个.o，不同的是，如果某个.o中没有一个符号属于unresolved symbol表，也就是链接器此时怀疑该.o没有必要，那么其就会被忽略可以通过一些代码来展示以上过程。在开发C++程序时，可以利用文件静态变量会先于main之前执行做一些可能利于程序结构的事情。如果某个.o（包含静态库中打包的.o）被链接进程序，那么其文件静态变量就会先于main初始化。// test.cpp#include &lt;stdio.h&gt;class Test {public: Test() { printf(\"Test ctor\\n\"); }};static Test s_test;// lib.cpp#include &lt;stdio.h&gt;class Lib {public: Lib() { printf(\"Lib ctor\\n\"); }};static Lib s_lib;// main.cpp#include &lt;stdio.h&gt;int main() { printf(\"main\\n\"); return 0;}以上代码main.cpp中未引用任何test.cpplib.cpp中的符号：$ g++ -o test test.o lib.o main.o$ ./testLib ctorTest ctormain生成的可执行程序执行如预期，其链接了test.olib.o。但是如果把lib.o以静态库的形式进行链接，情况就不一样了：为了做对比，基于以上的代码再加一个文件，及修改main.cpp：// libfn.cppint sum(int a, int b) { return a + b;}// main.cpp#include &lt;stdio.h&gt;int main() { printf(\"main\\n\"); extern int sum(int, int); printf(\"sum: %d\\n\", sum(2, 3)); return 0;}将libfn.o和lib.o创建为静态库：$ ar -r libfn.a libfn.o lib.o$ g++ -o test main.o test.o -lfn -L.$ ./testTest ctormainsum: 5因为lib.o没有被链接，导致其文件静态变量也未得到初始化。调整链接顺序，可以进一步检验前面的链接过程：# 将libfn.a的链接放在main.o前面$ g++ -o test test.o -lfn main.o -L.main.o: In function `main':main.cpp:(.text+0x19): undefined reference to `sum(int, int)'collect2: ld returned 1 exit status这个问题遇到得比较多，也有点让人觉得莫名其妙。其原因就在于链接器在链接libfn.a的时候，发现libfn.o依然没有被之前链接的*.o引用到，也就是没有任何符号在unresolved symbol table中，所以libfn.o也被忽略。一些实践在实际开发中还会遇到一些静态库相关的问题。链接顺序问题前面的例子已经展示了这个问题。调整库的链接顺序可以解决大部分问题，但当静态库之间存在环形依赖时，则无法通过调整顺序来解决。-whole-archive-whole-archive选项告诉链接器把静态库中的所有.o都进行链接，针对以上例子：$ g++ -o test -L. test.o -Wl,--whole-archive -lfn main.o -Wl,--no-whole-archive$ ./testLib ctorTest ctormainsum: 5连lib.o也被链接了进来。-Wl选项告诉gcc将其作为链接器参数传入；之所以在命令行结尾加上--no-whole-archive是为了告诉编译器不要链接gcc默认的库可以看出这个方法还是有点暴力了。–start-group格式为：--start-group archives --end-group位于--start-group --end-group中的所有静态库将被反复搜索，而不是默认的只搜索一次，直到不再有新的unresolved symbol产生为止。也就是说，出现在这里的.o如果发现有unresolved symbol，则可能回到之前的静态库中继续搜索。$ g++ -o test -L. test.o -Wl,--start-group -lfn main.o -Wl,--end-group$ ./testTest ctormainsum: 5查看ldd关于该参数的man page还可以一窥链接过程的细节： The specified archives are searched repeatedly until no new undefined references are created. Normally, an archive is searched only once in the order that it is specified on the command line. If a symbol in that archive is needed to resolve an undefined symbol referred to by an object in an archive that appears later on the command line, the linker would not be able to resolve that reference. By grouping the archives, they all be searched repeatedly until all possible references are resolved.嵌套静态库由于ar创建静态库时本质上只是对文件进行打包，所以甚至可以创建一个嵌套的静态库，从而测试链接器是否会递归处理静态库中的.o：$ ar -r libfn.a libfn.o$ ar -r liboutfn.a libfn.a lib.o$ g++ -o test -L. test.o main.o -loutfnmain.o: In function `main':main.cpp:(.text+0x19): undefined reference to `sum(int, int)'collect2: ld returned 1 exit status可见链接器并不会递归处理静态库中的文件之所以要提到嵌套静态库这个问题，是因为我发现很多时候我们喜欢为一个静态库工程链接其他静态库。当然，这里的链接并非真正的链接（仅是打包），这个过程当然可以聪明到将其他静态库里的.o提取出来然后打包到新的静态库。如果我们使用的是类似scons这种封装更高的依赖项管理工具，那么它是否会这样干呢？基于之前的例子，我们使用scons来创建liboutfn.a：# SconstructStaticLibrary('liboutfn.a', ['libfn.a', 'lib.o'])使用文本编辑器打开liboutfn.a就可以看到其内容，或者使用：$ ar -tv liboutfn.arw-r--r-- 60833/100 1474 Sep 14 02:59 2014 libfn.arw-r--r-- 60833/100 2448 Sep 14 02:16 2014 lib.o可见scons也只是单纯地打包。所以，在scons中构建一个静态库时，再链接其他静态库是没有意义的参考文档 ar (Unix) ld man page GNU ld初探 Library order in static linking Linkers and Loaders scons Building and Linking with Libraries" }, { "title": "理解git常用命令原理", "url": "/posts/understand-git/", "categories": "other", "tags": "git", "date": "2014-09-09 00:00:00 +0800", "snippet": "git不同于类似SVN这种版本管理系统，虽然熟悉常用的操作就可以满足大部分需求，但为了在遇到麻烦时不至于靠蛮力去尝试，了解git的原理还是很有必要。文件通过git管理的文件版本信息全部存放在根目录.git下，稍微看下：$ ls .gitCOMMIT_EDITMSG HEAD branches description index logs packed-refsFETCH_HEAD ORIG_HEAD config hooks info objects refsgit除了提供给我们平时常用的一些命令之外，还有很多底层命令，可以用于查看以上部分文件表示的东西。三个区域/三类对象理解git里的三个区域概念非常重要。git里很多常用的命令都是围绕着这三个区域来做的。它们分别为： working directory，也就是你所操作的那些文件 history，你所提交的所有记录，文件历史内容等等。git是个分布式版本管理系统，在你本地有项目的所有历史提交记录；文件历史记录；提交日志等等。 stage(index)，暂存区域，本质上是个文件，也就是.git/indexgit中还有三类常用对象（实际不止三种），理解这三类对象也很重要。分别为： blob，用于表示一个文件 tree，用于表示一个目录，索引到若干文件或子目录 commit，用于表示一次提交(commit)所有对象都会以文件的形式保存在.git/objects目录，一个对象一个文件。接下来把上面所有的内容关联起来。做以下操作：$ mkdir test &amp;&amp; cd test$ git init$ ls -a .git/objects # 没有文件. .. info pack$ touch readme # working directory里增加了一个readme文件$ git add readme # 添加一个文件到stage区域$ git ls-files --stage # 这个命令可以查看stage区域里的内容，可以看到有readme100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 0 readme$ ls -a .git/objects # 同时.git/objects增加了一个e6的目录. .. e6 info pack$ ls -a .git/objects/e6/ # e6目录下增加了一个文件. .. 9de29bb2d1d6434b8b29ae775ad8c2e48c5391上面的操作展示了git中三个区域三个对象的部分关联关系。git中每个对象都以一个40个字符长度的SHA-1哈希值为标识，以这40个字符的前2个字符作为文件夹，以后38个字符为文件名。基于以上继续操作：$ git commit -m 'first commit' # commit会将stage里标识的文件提交到history区域[master (root-commit) 8bf6969] first commit 0 files changed, 0 insertions(+), 0 deletions(-) create mode 100644 readme$ ls -a .git/objects # 增加了2个文件，也就是2个对象. .. 8b e6 e8 info pack$ git ls-files --stage # stage仅表示当前被版本管理的文件，所以内容不变100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 0 readme# git cat-file 命令可以用于查看.git/objects下的文件，意即可用于查看对象$ git cat-file -t e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 # 这个是之前git add readme产生的文件对象 blobblob# 同样我们来查看git commit -m后新增的两个对象$ ls .git/objects/8b/f696927c17526eb8f0c6dae8badb968a001ed0$ git cat-file -t 8bf696927c17526eb8f0c6dae8badb968a001ed0 # 记得带上8b这个文件夹名，才算一个完整的对象ID。这是一个commit对象commit$ ls .git/objects/e80ad49ace82167de62e498622d70377d913c79e$ git cat-file -t e80ad49ace82167de62e498622d70377d913c79e # tree对象tree区域和对象如何交互的可以用下图描述：通过git cat-file -p可以查看对象的更多描述，git cat-file -t仅获取对象的类型。做以下操作获得更深的认识：# 这个commit对象记录了提交者的信息，还包括指向的tree对象$ git cat-file -p 8bf696927c17526eb8f0c6dae8badb968a001ed0tree e80ad49ace82167de62e498622d70377d913c79eauthor Kevin Lynx &lt;kevinlynx@gmail.com&gt; 1410090424 +0800committer Kevin Lynx &lt;kevinlynx@gmail.com&gt; 1410090424 +0800first commit# 查看tree对象可以看出tree指向的blob对象 $ git cat-file -p e80ad49ace82167de62e498622d70377d913c79e100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 readme即使是已经被版本管理的文件，发生改动后（正常改动或合并）都使用git add来重新mark它。创建第二次提交进一步认识：$ echo 'hello git' &gt; readme$ touch install$ git ls-files --stage # 不使用git add，暂存区域内容没变100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 0 readme# 此时stage里内容未变，提示no changes added to commit$ git commit# On branch master# Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)# (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)## modified: readme## Untracked files:# (use \"git add &lt;file&gt;...\" to include in what will be committed)## installno changes added to commit (use \"git add\" and/or \"git commit -a\")$ git add readme$ ls .git/objects/ # git add之后.git/objects下新增文件8b 8d e6 e8 info pack$ ls .git/objects/8d/0e41234f24b6da002d962a26c2495ea16a425f$ git cat-file -p 8d0e41234f24b6da002d962a26c2495ea16a425f # 查看该新增对象hello git# 这个时候还可以在提交前撤销git add readme$ git reset readme # 从history到stageUnstaged changes after reset:M readme$ cat readmehello git$ git checkout readme # 从stage到working directory$ cat readme # 没有内容，回到第一个版本$ git add install # 添加新创建的文件$ git ls-files --stage # stage中的内容是最新的readme和新添加的install100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 0 install100644 8d0e41234f24b6da002d962a26c2495ea16a425f 0 readme$ ls .git/objects/8b 8d e6 e8 info pack以上，发现一个有趣的现象：新加的install文件的SHA-1哈希值和之前的readme相同，这是因为这2个文件都是空的，内容相同。继续：$ git commit -m 'second commit'$ ls .git/objects/ # 提交后新增2个对象45 72 8b 8d e6 e8 info pack$ ls .git/objects/72/b94e949c5fca6092cc74c751a7bb35ee71c283$ git cat-file -p 72b94e949c5fca6092cc74c751a7bb35ee71c283tree 45cf0bd049d7eea4558b14f33a894db27c7c1130 # 新创建的tree对象parent 8bf696927c17526eb8f0c6dae8badb968a001ed0 # commit对象有parent，正是上一次提交author Kevin Lynx &lt;kevinlynx@gmail.com&gt; 1410094456 +0800committer Kevin Lynx &lt;kevinlynx@gmail.com&gt; 1410094456 +0800second commit# 新创建的tree对象指向了2个文件$ git cat-file -p 45cf0bd049d7eea4558b14f33a894db27c7c1130100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 install100644 blob 8d0e41234f24b6da002d962a26c2495ea16a425f readme需要注意，有时候我们使用git commit -a，它会直接将已经加入版本管理的文件一起提交，从而跳过了git add这个过程。同git很多操作一样，它只是一个快捷操作。总结从上面的内容其实已经可以看出git的优势所在，它可以完全不需要服务器就完成一个版本控制系统的所有事情。在.git文件中它记录了所有的文件的所有历史提交，记录了每一次提交的信息。git的常用操作中还会涉及到分支、远端仓库等，空了再写。参考文档 Git的思想和基本工作原理 图解Git Git详解之九：Git内部原理 Git 少用 Pull 多用 Fetch 和 Merge" }, { "title": "C++构造/析构函数中的多态(二)", "url": "/posts/necessary-dtor/", "categories": "c/c++", "tags": "c/c++, virtual", "date": "2014-09-06 00:00:00 +0800", "snippet": "本来是几年以前写的一篇博客：C++陷阱：构造函数中的多态。然后有同学在评论中讨论了起来，为了记录我就在这里单独写一篇，基本上就是用编译器的实现去证明了早就被大家熟知的一些结论。默认构造函数/析构函数不是在所有情况下都会被生成出来的。为此我还特地翻出《Inside C++ object model》： 2.1 Default Constructor Construction The C++ Annotated Reference Manual (ARM) [ELLIS90] (Section 12.1) tells us that “default constructors…are generated (by the compiler) where needed….”后面别人还罗列了好些例子告诉你哪些情况才算needed。本文我就解释构造函数中的多态评论中的问题。实验代码如下：#include &lt;stdio.h&gt;class Base {public: Base() { Init(); } //virtual ~Base() { printf(\"Base dtor\\n\"); Release(); } virtual void Init() { printf(\"Base::Init\\n\"); } virtual void Release() { printf(\"Base::Release\\n\"); }};class Derived : public Base {public: /* ~Derived() { printf(\"Derived dtor\\n\"); } // */ virtual void Init() { printf(\"Derived::Init\\n\"); } virtual void Release() { printf(\"Derived:Release\\n\"); }};int main(){ Base *obj = new Derived(); delete obj; return 0;}去掉Derived的析构函数，去掉Base析构函数的virtual：# g++ -Wa,-adhln -g test.cpp &gt; test.s 44:test.cpp **** delete obj; 227 .loc 1 44 0 228 0028 488B45F0 movq -16(%rbp), %rax 229 002c 488945E0 movq %rax, -32(%rbp) 230 0030 48837DE0 cmpq $0, -32(%rbp) 230 00 231 0035 7520 jne .L17 232 0037 EB30 jmp .L18... 244 .L17: 245 .loc 1 44 0 246 0057 488B7DE0 movq -32(%rbp), %rdi 247 005b E8000000 call _ZN4BaseD1Ev # 直接call从这里甚至可以看到delete对空指针的判定。Base的析构函数不是virtual，所以这里编译器生成的析构函数调用代码根本不需要用到vptr，直接call就可以。而具体call谁则是根据obj指向的类型Base确定。即使Derived用户定义了析构函数也不会调用，无论是否virtual。事实上编译器甚至不需要生成Derived的析构函数，多傻的编译器才会生成这些什么事都不做的代码而光进出函数就得好几条指令？查看程序中的符号，没有生成Derived析构函数：# nm test...0000000000400816 W _ZN4Base4InitEv00000000004007fe W _ZN4Base7ReleaseEv000000000040082e W _ZN4BaseC2Ev0000000000400876 W _ZN4BaseD1Ev 00000000004007e6 W _ZN7Derived4InitEv00000000004007ce W _ZN7Derived7ReleaseEv0000000000400852 W _ZN7DerivedC1Ev...现在把Base析构函数变为virtual的： 44:test.cpp **** delete obj; 170 .loc 1 44 0 171 0028 48837DF0 cmpq $0, -16(%rbp) 171 00 172 002d 7520 jne .L12 173 002f EB32 jmp .L13... 185 .L12: 186 .loc 1 44 0 187 004f 488B45F0 movq -16(%rbp), %rax # this -&gt; rax 188 0053 488B00 movq (%rax), %rax # *rax -&gt; vptr 189 0056 4883C008 addq $8, %rax # vptr += 8 190 005a 488B00 movq (%rax), %rax # *vptr -&gt; Base::~Base 191 005d 488B7DF0 movq -16(%rbp), %rdi # this as first argument (passed by rdi) 192 0061 FFD0 call *%rax # call析构函数动态调用这也是预期的。至于为什么是偏移vptr+8，是因为第一个指针指向的是type_info，具体可看浅议 Dynamic_cast 和 RTTI。vptr和virtual function table还需要详述吗？此时就会生成Derived的析构函数：...000000000040084c W _ZN4Base4InitEv00000000004008ac W _ZN4Base7ReleaseEv0000000000400864 W _ZN4BaseC2Ev0000000000400970 W _ZN4BaseD0Ev00000000004009b0 W _ZN4BaseD1Ev00000000004008c4 W _ZN4BaseD2Ev0000000000400834 W _ZN7Derived4InitEv000000000040081c W _ZN7Derived7ReleaseEv0000000000400888 W _ZN7DerivedC1Ev0000000000400904 W _ZN7DerivedD0Ev 000000000040093a W _ZN7DerivedD1Ev...细心的人就会发现无论是Base还是Derived都会生成多个析构函数，这个深入下去还有很多内容，具体可以参看：GNU GCC (g++): Why does it generate multiple dtors?。甚至可以运行这个例子看到调用到了Derived的析构函数：(gdb) ni0x000000000040080d 45 return 0;1: x/3i $pc0x40080d &lt;main()+117&gt;: callq *%rax # 调用0x40080f &lt;main()+119&gt;: mov $0x0,%eax0x400814 &lt;main()+124&gt;: add $0x28,%rsp(gdb) siDerived::~Derived (this=0x7ffff7ffd000, __in_chrg=&lt;value optimized out&gt;) at test.cpp:2424 class Derived : public Base {1: x/3i $pc0x400904 &lt;Derived::~Derived()&gt;: push %rbp0x400905 &lt;Derived::~Derived()+1&gt;: mov %rsp,%rbp0x400908 &lt;Derived::~Derived()+4&gt;: sub $0x10,%rsp其实看Derived的析构函数实现会发现很多有趣的东西：(gdb) disassemble 'Derived::~Derived'Dump of assembler code for function Derived::~Derived():0x0000000000400904 &lt;Derived::~Derived()+0&gt;: push %rbp0x0000000000400905 &lt;Derived::~Derived()+1&gt;: mov %rsp,%rbp0x0000000000400908 &lt;Derived::~Derived()+4&gt;: sub $0x10,%rsp0x000000000040090c &lt;Derived::~Derived()+8&gt;: mov %rdi,-0x8(%rbp)0x0000000000400910 &lt;Derived::~Derived()+12&gt;: mov $0x400b50,%edx0x0000000000400915 &lt;Derived::~Derived()+17&gt;: mov -0x8(%rbp),%rax0x0000000000400919 &lt;Derived::~Derived()+21&gt;: mov %rdx,(%rax)0x000000000040091c &lt;Derived::~Derived()+24&gt;: mov -0x8(%rbp),%rdi0x0000000000400920 &lt;Derived::~Derived()+28&gt;: callq 0x4008c4 &lt;Base::~Base()&gt;0x0000000000400925 &lt;Derived::~Derived()+33&gt;: mov $0x1,%eax0x000000000040092a &lt;Derived::~Derived()+38&gt;: test %al,%al0x000000000040092c &lt;Derived::~Derived()+40&gt;: je 0x400937 &lt;Derived::~Derived()+51&gt;0x000000000040092e &lt;Derived::~Derived()+42&gt;: mov -0x8(%rbp),%rdi0x0000000000400932 &lt;Derived::~Derived()+46&gt;: callq 0x400670 &lt;_ZdlPv@plt&gt; 0x0000000000400937 &lt;Derived::~Derived()+51&gt;: leaveq0x0000000000400938 &lt;Derived::~Derived()+52&gt;: retq实际上这个析构函数就是上面的D0版本，它做了一件重要的事就是delete this。具体的可以google gcc对析构函数的实现。构造函数和析构函数中根本就不会启用多态，这个是结论或者说是标准，但不是原因(真怕又有人告诉我c++ standard某section这样写的所以这就是理由)。既然反正已经看实现了，就索性看一眼编译器怎么处理这个问题：// Base::~Base 261 0000 55 pushq %rbp 262 .LCFI22: 263 0001 4889E5 movq %rsp, %rbp 264 .LCFI23: 265 0004 4883EC10 subq $16, %rsp 266 .LCFI24: 267 0008 48897DF8 movq %rdi, -8(%rbp) 268 .loc 1 10 0 269 000c BA000000 movl $_ZTV4Base+16, %edx 269 00 270 0011 488B45F8 movq -8(%rbp), %rax 271 0015 488910 movq %rdx, (%rax) 272 .loc 1 11 0 273 0018 BF000000 movl $.LC4, %edi 273 00 274 001d E8000000 call puts 274 00 275 .loc 1 12 0 276 0022 488B7DF8 movq -8(%rbp), %rdi 277 0026 E8000000 call _ZN4Base7ReleaseEv # 直接call绝对地址构造函数一样： 94 0000 55 pushq %rbp 95 .LCFI9: 96 0001 4889E5 movq %rsp, %rbp 97 .LCFI10: 98 0004 4883EC10 subq $16, %rsp 99 .LCFI11: 100 0008 48897DF8 movq %rdi, -8(%rbp) 101 .LBB2: 102 .loc 1 5 0 103 000c B8000000 movl $_ZTV4Base+16, %eax 103 00 104 0011 488B55F8 movq -8(%rbp), %rdx 105 0015 488902 movq %rax, (%rdx) 106 .loc 1 6 0 107 0018 488B7DF8 movq -8(%rbp), %rdi 108 001c E8000000 call _ZN4Base4InitEv # 直接call地址END" }, { "title": "C/C++中手动获取调用堆栈", "url": "/posts/stack-frame/", "categories": "c/c++", "tags": "stack frame", "date": "2014-09-02 00:00:00 +0800", "snippet": "当我们的程序core掉之后，如果能获取到core时的函数调用堆栈将非常有利于定位问题。在Windows下可以使用SEH机制；在Linux下通过gdb使用coredump文件即可。但有时候由于某些错误导致堆栈被破坏，发生拿不到调用堆栈的情况。一些基础预备知识本文不再详述，可以参考以下文章： 函数调用栈的获取原理分析 寄存器、函数调用与栈帧需要知道的信息： 函数调用对应的call指令本质上是先压入下一条指令的地址到堆栈，然后跳转到目标函数地址 函数返回指令ret则是从堆栈取出一个地址，然后跳转到该地址 EBP寄存器始终指向当前执行函数相关信息（局部变量）所在栈中的位置，ESP则始终指向栈顶 每一个函数入口都会保存调用者的EBP值，在出口处都会重设EBP值，从而实现函数调用的现场保存及现场恢复 64位机器增加了不少寄存器，从而使得函数调用的参数大部分时候可以通过寄存器传递；同时寄存器名字发生改变，例如EBP变为RBP在函数调用中堆栈的情况可用下图说明：将代码对应起来：void g() { int *p = 0; long a = 0x1234; printf(\"%p %x\\n\", &amp;a, a); printf(\"%p %x\\n\", &amp;p, p); f(); *p = 1;}void b(int argc, char **argv) { printf(\"%p %p\\n\", &amp;argc, &amp;argv); g();}int main(int argc, char **argv) { b(argc, argv); return 0;}在函数g()中断点，看看堆栈中的内容(64位机器)：(gdb) p $rbp$2 = (void *) 0x7fffffffe370(gdb) p &amp;p$3 = (int **) 0x7fffffffe368(gdb) p $rsp$4 = (void *) 0x7fffffffe360(gdb) x/8ag $rbp-160x7fffffffe360: 0x1234 0x00x7fffffffe370: 0x7fffffffe390 0x400631 &lt;b(int, char**)+43&gt;0x7fffffffe380: 0x7fffffffe498 0x1a561cbc00x7fffffffe390: 0x7fffffffe3b0 0x40064f &lt;main(int, char**)+27&gt;对应的堆栈图：可以看看例子中0x400631 &lt;b(int, char**)+43&gt;和 0x40064f &lt;main(int, char**)+27&gt;中的代码：(gdb) disassemble 0x400631...0x0000000000400627 &lt;b(int, char**)+33&gt;: callq 0x400468 &lt;printf@plt&gt;0x000000000040062c &lt;b(int, char**)+38&gt;: callq 0x4005ae &lt;g()&gt;0x0000000000400631 &lt;b(int, char**)+43&gt;: leaveq # call的下一条指令...(gdb) disassemble 0x40064f... 0x000000000040063f &lt;main(int, char**)+11&gt;: mov %rsi,-0x10(%rbp)0x0000000000400643 &lt;main(int, char**)+15&gt;: mov -0x10(%rbp),%rsi0x0000000000400647 &lt;main(int, char**)+19&gt;: mov -0x4(%rbp),%edi0x000000000040064a &lt;main(int, char**)+22&gt;: callq 0x400606 &lt;b(int, char**)&gt;0x000000000040064f &lt;main(int, char**)+27&gt;: mov $0x0,%eax # call的下一条指令...顺带一提，每个函数入口和出口，对应的设置RBP代码为：(gdb) disassemble g...0x00000000004005ae &lt;g()+0&gt;: push %rbp # 保存调用者的RBP到堆栈0x00000000004005af &lt;g()+1&gt;: mov %rsp,%rbp # 设置自己的RBP...0x0000000000400603 &lt;g()+85&gt;: leaveq # 等同于：movq %rbp, %rsp # popq %rbp0x0000000000400604 &lt;g()+86&gt;: retq 由以上可见，通过当前的RSP或RBP就可以找到调用堆栈中所有函数的RBP；找到了RBP就可以找到函数地址。因为，任何时候的RBP指向的堆栈位置就是上一个函数的RBP；而任何时候RBP所在堆栈中的前一个位置就是函数返回地址。由此我们可以自己构建一个导致gdb无法取得调用堆栈的例子：void f() { long *p = 0; p = (long*) (&amp;p + 1); // 取得g()的RBP *p = 0; // 破坏g()的RBP}void g() { int *p = 0; long a = 0x1234; printf(\"%p %x\\n\", &amp;a, a); printf(\"%p %x\\n\", &amp;p, p); f(); *p = 1; // 写0地址导致一次core}void b(int argc, char **argv) { printf(\"%p %p\\n\", &amp;argc, &amp;argv); g();}int main(int argc, char **argv) { b(argc, argv); return 0;}使用gdb运行该程序：Program received signal SIGSEGV, Segmentation fault.g () at ebp.c:3737 *p = 1;(gdb) btCannot access memory at address 0x8(gdb) p $rbp$1 = (void *) 0x0bt无法获取堆栈，在函数g()中RBP被改写为0，gdb从0偏移一个地址长度即0x8，尝试从0x8内存位置获取函数地址，然后提示Cannot access memory at address 0x8。RBP出现了问题，我们就可以通过RSP来手动获取调用堆栈。因为RSP是不会被破坏的，要通过RSP获取调用堆栈则需要偏移一些局部变量所占的空间：(gdb) p $rsp$2 = (void *) 0x7fffffffe360(gdb) x/8ag $rsp+16 # g()中局部变量占16字节0x7fffffffe370: 0x7fffffffe390 0x400631 &lt;b(int, char**)+43&gt;0x7fffffffe380: 0x7fffffffe498 0x1a561cbc00x7fffffffe390: 0x7fffffffe3b0 0x40064f &lt;main(int, char**)+27&gt;0x7fffffffe3a0: 0x7fffffffe498 0x100000000基于以上就可以手工找到调用堆栈：g()0x400631 &lt;b(int, char**)+43&gt;0x40064f &lt;main(int, char**)+27&gt;上面的例子本质上也是破坏堆栈，并且仅仅破坏了保存了的RBP。在实际情况中，堆栈可能会被破坏得更多，则可能导致手动定位也较困难。堆栈被破坏还可能导致更多的问题，例如覆盖了函数返回地址，则会导致RIP错误；例如堆栈的不平衡。导致堆栈被破坏的原因也有很多，例如局部数组越界；delete/free栈上对象等。omit-frame-pointer使用RBP获取调用堆栈相对比较容易。但现在编译器都可以设置不使用RBP(gcc使用-fomit-frame-pointer，msvc使用/Oy)，对于函数而言不设置其RBP意味着可以节省若干条指令。在函数内部则完全使用RSP的偏移来定位局部变量，包括嵌套作用域里的局部变量，即使程序实际运行时不会进入这个作用域。例如：void f2() { int a = 0x1234; if (a &gt; 0) { int b = 0xff; b = a; }}gcc中使用-fomit-frame-pointer生成的代码为：(gdb) disassemble f2Dump of assembler code for function f2:0x00000000004004a5 &lt;f2+0&gt;: movl $0x1234,-0x8(%rsp) # int a = 0x12340x00000000004004ad &lt;f2+8&gt;: cmpl $0x0,-0x8(%rsp) 0x00000000004004b2 &lt;f2+13&gt;: jle 0x4004c4 &lt;f2+31&gt; 0x00000000004004b4 &lt;f2+15&gt;: movl $0xff,-0x4(%rsp) # int b = 0xff0x00000000004004bc &lt;f2+23&gt;: mov -0x8(%rsp),%eax0x00000000004004c0 &lt;f2+27&gt;: mov %eax,-0x4(%rsp)0x00000000004004c4 &lt;f2+31&gt;: retq可以发现f2()没有操作RBP之类的指令了。" }, { "title": "基于protobuf的RPC实现", "url": "/posts/protobuf-rpc/", "categories": "c/c++", "tags": "protobuf, rpc", "date": "2014-08-31 00:00:00 +0800", "snippet": "可以对照使用google protobuf RPC实现echo service一文看，细节本文不再描述。google protobuf只负责消息的打包和解包，并不包含RPC的实现，但其包含了RPC的定义。假设有下面的RPC定义： service MyService { rpc Echo(EchoReqMsg) returns(EchoRespMsg) }那么要实现这个RPC需要最少做哪些事？总结起来需要完成以下几步：客户端RPC客户端需要实现google::protobuf::RpcChannel。主要实现RpcChannel::CallMethod接口。客户端调用任何一个RPC接口，最终都是调用到CallMethod。这个函数的典型实现就是将RPC调用参数序列化，然后投递给网络模块进行发送。 void CallMethod(const ::google::protobuf::MethodDescriptor* method, ::google::protobuf::RpcController* controller, const ::google::protobuf::Message* request, ::google::protobuf::Message* response, ::google::protobuf::Closure* done) { ... DataBufferOutputStream outputStream(...) // 取决于你使用的网络实现 request-&gt;SerializeToZeroCopyStream(&amp;outputStream); _connection-&gt;postData(outputStream.getData(), ... ... }服务端服务端首先需要实现RPC接口，直接实现MyService中定义的接口： class MyServiceImpl : public MyService { virtual void Echo(::google::protobuf::RpcController* controller, const EchoReqMsg* request, EchoRespMsg* response, ::google::protobuf::Closure* done) { ... done-&gt;Run(); } }标示service&amp;method基于以上，可以看出服务端根本不知道客户端想要调用哪一个RPC接口。从服务器接收到网络消息，到调用到MyServiceImpl::Echo还有很大一段距离。解决方法就是在网络消息中带上RPC接口标识。这个标识可以直接带上service name和method name，但这种实现导致网络消息太大。另一种实现是基于service name和method name生成一个哈希值，因为接口不会太多，所以较容易找到基本不冲突的字符串哈希算法。无论哪种方法，服务器是肯定需要建立RPC接口标识到protobuf service对象的映射的。这里提供第三种方法：基于option的方法。protobuf中option机制类似于这样一种机制：service&amp;method被视为一个对象，其有很多属性，属性包含内置的，以及用户扩展的。用户扩展的就是option。每一个属性有一个值。protobuf提供访问service&amp;method这些属性的接口。首先扩展service&amp;method的属性，以下定义这些属性的key： extend google.protobuf.ServiceOptions { required uint32 global_service_id = 1000; } extend google.protobuf.MethodOptions { required uint32 local_method_id = 1000; }应用层定义service&amp;method时可以指定以上key的值： service MyService { option (arpc.global_service_id) = 2302; rpc Echo(EchoReqMsg) returns(EchoRespMsg) { option (arpc.local_method_id) = 1; } rpc Echo_2(EchoReqMsg) returns(EchoRespMsg) { option (arpc.local_method_id) = 2; } ... }以上相当于在整个应用中，每个service都被赋予了唯一的id，单个service中的method也有唯一的id。然后可以通过protobuf取出以上属性值： void CallMethod(const ::google::protobuf::MethodDescriptor* method, ::google::protobuf::RpcController* controller, const ::google::protobuf::Message* request, ::google::protobuf::Message* response, ::google::protobuf::Closure* done) { ... google::protobuf::ServiceDescriptor *service = method-&gt;service(); uint32_t serviceId = (uint32_t)(service-&gt;options().GetExtension(global_service_id)); uint32_t methodId = (uint32_t)(method-&gt;options().GetExtension(local_method_id)); ... }考虑到serviceId methodId的范围，可以直接打包到一个32位整数里：uint32_t ret = (serviceId &lt;&lt; 16) | methodId;然后就可以把这个值作为网络消息头的一部分发送。当然服务器端是需要建立这个标识值到service的映射的： bool MyRPCServer::registerService(google::protobuf::Service *rpcService) { const google::protobuf::ServiceDescriptor = rpcService-&gt;GetDescriptor(); int methodCnt = pSerDes-&gt;method_count(); for (int i = 0; i &lt; methodCnt; i++) { google::protobuf::MethodDescriptor *pMethodDes = pSerDes-&gt;method(i); uint32_t rpcCode = PacketCodeBuilder()(pMethodDes); // 计算出映射值 _rpcCallMap[rpcCode] = make_pair(rpcService, pMethodDes); // 建立映射 } return true; }服务端收到RPC调用后，取出这个标识值，然后再从_rpcCallMap中取出对应的service和method，最后进行调用： google::protobuf::Message* response = _pService-&gt;GetResponsePrototype(_pMethodDes).New(); // 用于回应的closure RPCServerClosure *pClosure = new (nothrow) RPCServerClosure( _channelId, _pConnection, _pReqMsg, pResMsg, _messageCodec, _version); RPCController *pController = pClosure-&gt;GetRpcController(); ... // protobuf 生成的CallMethod，会自动调用到Echo接口 _pService-&gt;CallMethod(_pMethodDes, pController, _pReqMsg, pResMsg, pClosure);参考 使用google protobuf RPC实现echo service protobuf extensions protobuf service protobuf options" }, { "title": "分布式环境中的负载均衡策略", "url": "/posts/lb-policy/", "categories": "network", "tags": "round-robin, consitent hash, 负载均衡", "date": "2014-08-25 00:00:00 +0800", "snippet": "在分布式系统中相同的服务常常会部署很多台，每一台被称为一个服务节点（实例）。通过一些负载均衡策略将服务请求均匀地分布到各个节点，以实现整个系统支撑海量请求的需求。本文描述一些简单的负载均衡策略。Round-robin简单地轮询。记录一个选择位置，每次请求来时调整该位置到下一个节点：curId = ++curId % nodeCnt随机选择随机地在所有节点中选择：id = random(nodeCnt);本机优先访问后台服务的访问者可能本身是一个整合服务，或者是一个proxy，如果后台服务节点恰好有节点部署在本机的，则可以优先使用。在未找到本机节点时则可以继续走Round-robin策略：if (node-&gt;ip() == local_ip) { return node;} else { return roundRobin();} &lt;!-- more --&gt; 一旦遍历到本机节点，则后面的请求会一直落到本机节点。所以这里可以加上一些权重机制，仅是保证本机节点会被优先选择，但不会被一直选择。例如：// initialcur_weight = 100;...// select nodecur_weight -= 5;if (cur_weight &lt;= 0) cur_weight = 100;if (cur_weight &gt; 50 &amp;&amp; node-&gt;ip() == local_ip) { return node;} else { return roundRobin();}本机房优先服务节点可能会被部署到多个机房，有时候确实是需要考虑跨机房服务。同本机优先策略类似，本机房优先则是优先考虑位于相同机房内的服务节点。该请求是从哪个机房中的前端服务发送过来的，则需要前端在请求参数中携带上机房ID。在服务节点对应的数据结构中，也最好按照机房来组织。本机房优先策略实际上会作为节点选择的第一道工序，它可以把非本机房的节点先过滤掉，然后再传入后面的各种节点选择策略。这里还可以考虑节点数参数，如果本机房的节点过少，则可以不使用该策略，避免流量严重不均。Weighted Round-Robin加权轮询。相对于普通轮询而言，该策略中每一个节点都有自己的权重，优先选择权重更大的节点。权重可以根据机器性能预先配置。摘抄一下网上的算法：假设有一组服务器S = {S0, S1, …, Sn-1}，W(Si)表示服务器Si的权值，一个指示变量i表示上一次选择的服务器，指示变量cw表示当前调度的权值，max(S)表示集合S中所有服务器的最大权值，gcd(S)表示集合S中所有服务器权值的最大公约数。变量i初始化为-1，cw初始化为零。while (true) { i = (i + 1) mod n; if (i == 0) { cw = cw - gcd(S); if (cw &lt;= 0) { cw = max(S); if (cw == 0) return NULL; } } if (W(Si) &gt;= cw) return Si;}遍历完所有节点后权重衰减，衰减到0后重新开始。这样可以让权重更大的节点被选择得更多。Consistent Hash一致性哈希。一致性哈希用于在分布式环境中，分布在各个节点上的请求，不会因为新增节点（扩容）或减少节点（节点宕机）而变化。如果每个服务节点上都有自己的缓存，其保存了该节点响应请求时的回应。正常情况下，这些缓存都可以很好地被运用，也即cache命中率较高。如果某个节点不可用了，我们的选择策略又是基于所有节点的公平选择，那么原来一直分配在节点A上请求就很可能被分配到节点B上，从而导致节点A上的缓存较难被命中。这个时候就可以运用一致性哈希来解决。其基本思想是，在节点选择区间内，在找节点时以顺时针方向找到不小于该请求对应的哈希值的节点。在这个区间里增加很多虚拟节点，每一个虚拟节点相当于一个物理节点的引用，这样相当于把物理节点变成了一个哈希值区间。这个哈希值区间不会因为增加节点和减少节点而变化，那么对某个请求而言，它就会始终落到这个区间里，也就会始终被分配到原来的节点。至于这个不可用的节点，其上的请求也会被均匀地分配到其他节点中。摘抄网上的一段代码：// 添加一个物理节点时，会随之增加很多虚拟节点template &lt;class Node, class Data, class Hash&gt;size_t HashRing&lt;Node, Data, Hash&gt;::AddNode(const Node&amp; node){ size_t hash; std::string nodestr = Stringify(node); for (unsigned int r = 0; r &lt; replicas_; r++) { hash = hash_((nodestr + Stringify(r)).c_str()); ring_[hash] = node; // 物理节点和虚拟节点都保存在一个std::map中 } return hash;}// 选择data对应的节点，data可以是请求template &lt;class Node, class Data, class Hash&gt;const Node&amp; HashRing&lt;Node, Data, Hash&gt;::GetNode(const Data&amp; data) const{ if (ring_.empty()) { throw EmptyRingException(); } size_t hash = hash_(Stringify(data).c_str()); // 对请求进行哈希 typename NodeMap::const_iterator it; // Look for the first node &gt;= hash it = ring_.lower_bound(hash); // 找到第一个不小于请求哈希的节点 if (it == ring_.end()) { // Wrapped around; get the first node it = ring_.begin(); } return it-&gt;second;}参考一致性 hash 算法(consistent hashing)，Consistent Hash Ring" }, { "title": "select真的有限制吗", "url": "/posts/select-limit/", "categories": "network", "tags": "network, select, FD_SET, fd_set", "date": "2014-06-01 00:00:00 +0800", "snippet": "在刚开始学习网络编程时，似乎莫名其妙地就会被某人/某资料告诉select函数是有fd(file descriptor)数量限制的。在最近的一次记忆里还有个人笑说select只支持64个fd。我甚至还写过一篇不负责任甚至错误的博客(突破select的FD_SETSIZE限制)。有人说，直接重新定义FD_SETSIZE就可以突破这个select的限制，也有人说除了重定义这个宏之外还的重新编译内核。事实具体是怎样的？实际上，造成这些混乱的原因恰好是不同平台对select的实现不一样。Windows的实现MSDN上对select的说明：int select( _In_ int nfds, _Inout_ fd_set *readfds, _Inout_ fd_set *writefds, _Inout_ fd_set *exceptfds, _In_ const struct timeval *timeout);nfds [in] Ignored. The nfds parameter is included only for compatibility with Berkeley sockets.第一个参数MSDN只说没有使用，其存在仅仅是为了保持与Berkeley Socket的兼容。 The variable FD_SETSIZE determines the maximum number of descriptors in a set. (The default value of FD_SETSIZE is 64, which can be modified by defining FD_SETSIZE to another value before including Winsock2.h.) Internally, socket handles in an fd_set structure are not represented as bit flags as in Berkeley Unix.Windows上select的实现不同于Berkeley Unix，后者使用位标志来表示socket。在MSDN的评论中有人提到： Unlike the Linux versions of these macros which use a single calculation to set/check the fd, the Winsock versions use a loop which goes through the entire set of fds each time you call FD_SET or FD_ISSET (check out winsock2.h and you’ll see). So you might want to consider an alternative if you have thousands of sockets!不同于Linux下处理fd_set的那些宏(FD_CLR/FD_SET之类)，Windows上这些宏的实现都使用了一个循环，看看这些宏的大致实现(Winsock2.h)：#define FD_SET(fd, set) do { \\ u_int __i; \\ for (__i = 0; __i &lt; ((fd_set FAR *)(set))-&gt;fd_count; __i++) { \\ if (((fd_set FAR *)(set))-&gt;fd_array[__i] == (fd)) { \\ break; \\ } \\ } \\ if (__i == ((fd_set FAR *)(set))-&gt;fd_count) { \\ if (((fd_set FAR *)(set))-&gt;fd_count &lt; FD_SETSIZE) { \\ ((fd_set FAR *)(set))-&gt;fd_array[__i] = (fd); \\ ((fd_set FAR *)(set))-&gt;fd_count++; \\ } \\ } \\} while(0)看下Winsock2.h中关于fd_set的定义：typedef struct fd_set { u_int fd_count; SOCKET fd_array[FD_SETSIZE];} fd_set;再看一篇更重要的MSDN Maximum Number of Sockets Supported： The Microsoft Winsock provider limits the maximum number of sockets supported only by available memory on the local computer.The maximum number of sockets that a Windows Sockets application can use is not affected by the manifest constant FD_SETSIZE.If an application is designed to be capable of working with more than 64 sockets using the select and WSAPoll functions, the implementor should define the manifest FD_SETSIZE in every source file before including the Winsock2.h header file.Windows上select支持的socket数量并不受宏FD_SETSIZE的影响，而仅仅受内存的影响。如果应用程序想使用超过FD_SETSIZE的socket，仅需要重新定义FD_SETSIZE即可。实际上稍微想想就可以明白，既然fd_set里面已经有一个socket的数量计数，那么select的实现完全可以使用这个计数，而不是FD_SETSIZE这个宏。那么结论是，select至少在Windows上并没有socket支持数量的限制。当然效率问题这里不谈。这看起来推翻了我们一直以来没有深究的一个事实。Linux的实现在上面提到的MSDN中，其实已经提到了Windows与Berkeley Unix实现的不同。在select的API文档中也看到了第一个参数并没有说明其作用。看下Linux的man： nfds is the highest-numbered file descriptor in any of the three sets, plus 1.第一个参数简单来说就是最大描述符+1。 An fd_set is a fixed size buffer. Executing FD_CLR() or FD_SET() with a value of fd that is negative or is equal to or larger than FD_SETSIZE will result in undefined behavior.明确说了，如果调用FD_SET之类的宏fd超过了FD_SETSIZE将导致undefined behavior。也有人专门做了测试：select system call limitation in Linux。也有现实遇到的问题：socket file descriptor (1063) is larger than FD_SETSIZE (1024), you probably need to rebuild Apache with a larger FD_SETSIZE看起来在Linux上使用select确实有FD_SETSIZE的限制。有必要看下相关的实现 fd_set.h：typedef __uint32_t __fd_mask;/* 32 = 2 ^ 5 */#define __NFDBITS (32)#define __NFDSHIFT (5)#define __NFDMASK (__NFDBITS - 1) /* * Select uses bit fields of file descriptors. These macros manipulate * such bit fields. Note: FD_SETSIZE may be defined by the user. */ #ifndef FD_SETSIZE#define FD_SETSIZE 256#endif #define __NFD_SIZE (((FD_SETSIZE) + (__NFDBITS - 1)) / __NFDBITS)typedef struct fd_set { __fd_mask fds_bits[__NFD_SIZE];} fd_set;在这份实现中不同于Windows实现，它使用了位来表示fd。看下FD_SET系列宏的大致实现：#define FD_SET(n, p) \\ ((p)-&gt;fds_bits[(unsigned)(n) &gt;&gt; __NFDSHIFT] |= (1 &lt;&lt; ((n) &amp; __NFDMASK)))添加一个fd到fd_set中也不是Windows的遍历，而是直接位运算。这里也有人对另一份类似实现做了剖析：linux的I/O多路转接select的fd_set数据结构和相应FD_宏的实现分析。在APUE中也提到fd_set： 这种数据类型(fd_set)为每一可能的描述符保持了一位。既然fd_set中不包含其保存了多少个fd的计数，那么select的实现里要知道自己要处理多少个fd，那只能使用FD_SETSIZE宏去做判定，但Linux的实现选用了更好的方式，即通过第一个参数让应用层告诉select需要处理的最大fd（这里不是数量）。那么其实现大概为：for (int i = 0; i &lt; nfds; ++i) { if (FD_ISSET... ...}如此看来，Linux的select实现则是受限于FD_SETSIZE的大小。这里也看到，fd_set使用位数组来保存fd，那么fd本身作为一个int数，其值就不能超过FD_SETSIZE。这不仅仅是数量的限制，还是其取值的限制。实际上，Linux上fd的取值是保证了小于FD_SETSIZE的（但不是不变的）Is the value of a Linux file descriptor always smaller than the open file limits?： Each process is further limited via the setrlimit(2) RLIMIT_NOFILE per-process limit on the number of open files. 1024 is a common RLIMIT_NOFILE limit. (It’s very easy to change this limit via /etc/security/limits.conf.)fd的取值会小于RLIMIT_NOFILE，有很多方法可以改变这个值。这个值默认情况下和FD_SETSIZE应该是一样的。这个信息告诉我们，Linux下fd的取值应该是从0开始递增的（理论上，实际上还有stdin/stdout/stderr之类的fd）。这才能保证select的那些宏可以工作。应用层使用标准的select用法应该大致如下：while (true) { ... select(...) for-each socket { if (FD_ISSET(fd, set)) ... } ...}即遍历目前管理的fd，通过FD_ISSET去判定当前fd是否有IO事件。因为Windows的实现FD_ISSET都是一个循环，所以有了另一种不跨平台的用法：while (true) { ... select(. &amp;read_sockets, &amp;write_sockets..) for-each read_socket { use fd.fd_array[i) } ...}总结 Windows上select没有fd数量的限制，但因为使用了循环来检查，所以效率相对较低 Linux上select有FD_SETSIZE的限制，但其相对效率较高" }, { "title": "muduo源码阅读", "url": "/posts/muduo-source/", "categories": "c/c++, network", "tags": "muduo, c/c++", "date": "2014-05-04 00:00:00 +0800", "snippet": "最近简单读了下muduo的源码，本文对其主要实现/结构简单总结下。muduo的主要源码位于net文件夹下，base文件夹是一些基础代码，不影响理解网络部分的实现。muduo主要类包括： EventLoop Channel Poller TcpConnection TcpClient TcpServer Connector Acceptor EventLoopThread EventLoopThreadPool其中，Poller（及其实现类）包装了Poll/EPoll，封装了OS针对设备(fd)的操作；Channel是设备fd的包装，在muduo中主要包装socket；TcpConnection抽象一个TCP连接，无论是客户端还是服务器只要建立了网络连接就会使用TcpConnection；TcpClient/TcpServer分别抽象TCP客户端和服务器；Connector/Acceptor分别包装TCP客户端和服务器的建立连接/接受连接；EventLoop是一个主控类，是一个事件发生器，它驱动Poller产生/发现事件，然后将事件派发到Channel处理；EventLoopThread是一个带有EventLoop的线程；EventLoopThreadPool自然是一个EventLoopThread的资源池，维护一堆EventLoopThread。阅读库源码时可以从库的接口层着手，看看关键功能是如何实现的。对于muduo而言，可以从TcpServer/TcpClient/EventLoop/TcpConnection这几个类着手。接下来看看主要功能的实现：建立连接 TcpClient::connect -&gt; Connector::start -&gt; EventLoop::runInLoop(Connector::startInLoop... -&gt; Connector::connect EventLoop::runInLoop接口用于在this所在的线程运行某个函数，这个后面看下EventLoop的实现就可以了解。 网络连接的最终建立是在Connector::connect中实现，建立连接之后会创建一个Channel来代表这个socket，并且绑定事件监听接口。最后最重要的是，调用Channel::enableWriting。Channel有一系列的enableXX接口，这些接口用于标识自己关心某IO事件。后面会看到他们的实现。Connector监听的主要事件无非就是连接已建立，用它监听读数据/写数据事件也不符合设计。TcpConnection才是做这种事的。客户端收发数据当Connector发现连接真正建立好后，会回调到TcpClient::newConnection，在TcpClient构造函数中： connector_-&gt;setNewConnectionCallback( boost::bind(&amp;TcpClient::newConnection, this, _1));TcpClient::newConnection中创建一个TcpConnection来代表这个连接： TcpConnectionPtr conn(new TcpConnection(loop_, connName, sockfd, localAddr, peerAddr)); conn-&gt;setConnectionCallback(connectionCallback_); conn-&gt;setMessageCallback(messageCallback_); conn-&gt;setWriteCompleteCallback(writeCompleteCallback_); ... conn-&gt;connectEstablished();并同时设置事件回调，以上设置的回调都是应用层（即库的使用者）的接口。每一个TcpConnection都有一个Channel，毕竟每一个网络连接都对应了一个socket fd。在TcpConnection构造函数中创建了一个Channel，并设置事件回调函数。TcpConnection::connectEstablished函数最主要的是通知Channel自己开始关心IO读取事件： void TcpConnection::connectEstablished() { ... channel_-&gt;enableReading();这是自此我们看到的第二个Channel::enableXXX接口，这些接口是如何实现关心IO事件的呢？这个后面讲到。muduo的数据发送都是通过TcpConnection::send完成，这个就是一般网络库中在不使用OS的异步IO情况下的实现：缓存应用层传递过来的数据，在IO设备可写的情况下尽量写入数据。这个主要实现在TcpConnection::sendInLoop中。 TcpConnection::sendInLoop(....) { ... // if no thing in output queue, try writing directly if (!channel_-&gt;isWriting() &amp;&amp; outputBuffer_.readableBytes() == 0) // 设备可写且没有缓存时立即写入 { nwrote = sockets::write(channel_-&gt;fd(), data, len); } ... // 否则加入数据到缓存，等待IO可写时再写 outputBuffer_.append(static_cast&lt;const char*&gt;(data)+nwrote, remaining); if (!channel_-&gt;isWriting()) { // 注册关心IO写事件，Poller就会对写做检测 channel_-&gt;enableWriting(); } ... }当IO可写时，Channel就会回调TcpConnection::handleWrite（构造函数中注册） void TcpConnection::handleWrite() { ... if (channel_-&gt;isWriting()) { ssize_t n = sockets::write(channel_-&gt;fd(), outputBuffer_.peek(), outputBuffer_.readableBytes());服务器端的数据收发同客户端机制一致，不同的是连接(TcpConnection)的建立方式不同。服务器接收连接服务器接收连接的实现在一个网络库中比较重要。muduo中通过Acceptor类来接收连接。在TcpClient中，其Connector通过一个关心Channel可写的事件来通过连接已建立；在Acceptor中则是通过一个Channel可读的事件来表示有新的连接到来： Acceptor::Acceptor(....) { ... acceptChannel_.setReadCallback( boost::bind(&amp;Acceptor::handleRead, this)); ... } void Acceptor::handleRead() { ... int connfd = acceptSocket_.accept(&amp;peerAddr); // 接收连接获得一个新的socket if (connfd &gt;= 0) { ... newConnectionCallback_(connfd, peerAddr); // 回调到TcpServer::newConnectionTcpServer::newConnection中建立一个TcpConnection，并将其附加到一个EventLoopThread中，简单来说就是给其配置一个线程： void TcpServer::newConnection(int sockfd, const InetAddress&amp; peerAddr) { ... EventLoop* ioLoop = threadPool_-&gt;getNextLoop(); TcpConnectionPtr conn(new TcpConnection(ioLoop, connName, sockfd, localAddr, peerAddr)); connections_[connName] = conn; ... ioLoop-&gt;runInLoop(boost::bind(&amp;TcpConnection::connectEstablished, conn));IO的驱动之前提到，一旦要关心某IO事件了，就调用Channel::enableXXX，这个如何实现的呢？ class Channel { ... void enableReading() { events_ |= kReadEvent; update(); } void enableWriting() { events_ |= kWriteEvent; update(); } void Channel::update() { loop_-&gt;updateChannel(this); } void EventLoop::updateChannel(Channel* channel) { ... poller_-&gt;updateChannel(channel); }最终调用到Poller::upateChannel。muduo中有两个Poller的实现，分别是Poll和EPoll，可以选择简单的Poll来看： void PollPoller::updateChannel(Channel* channel) { ... if (channel-&gt;index() &lt; 0) { // a new one, add to pollfds_ assert(channels_.find(channel-&gt;fd()) == channels_.end()); struct pollfd pfd; pfd.fd = channel-&gt;fd(); pfd.events = static_cast&lt;short&gt;(channel-&gt;events()); // 也就是Channel::enableXXX操作的那个events_ pfd.revents = 0; pollfds_.push_back(pfd); // 加入一个新的pollfd int idx = static_cast&lt;int&gt;(pollfds_.size())-1; channel-&gt;set_index(idx); channels_[pfd.fd] = channel;可见Poller就是把Channel关心的IO事件转换为OS提供的IO模型数据结构上。通过查看关键的pollfds_的使用，可以发现其主要是在Poller::poll接口里。这个接口会在EventLoop的主循环中不断调用： void EventLoop::loop() { ... while (!quit_) { activeChannels_.clear(); pollReturnTime_ = poller_-&gt;poll(kPollTimeMs, &amp;activeChannels_); ... for (ChannelList::iterator it = activeChannels_.begin(); it != activeChannels_.end(); ++it) { currentActiveChannel_ = *it; currentActiveChannel_-&gt;handleEvent(pollReturnTime_); // 获得IO事件，通知各注册回调 }整个流程可总结为：各Channel内部会把自己关心的事件告诉给Poller，Poller由EventLoop驱动检测IO，然后返回哪些Channel发生了事件，EventLoop再驱动这些Channel调用各注册回调。从这个过程中可以看出，EventLoop就是一个事件产生器。线程模型在muduo的服务器中，muduo的线程模型是怎样的呢？它如何通过线程来支撑高并发呢？其实很简单，它为每一个线程配置了一个EventLoop，这个线程同时被附加了若干个网络连接，这个EventLoop服务于这些网络连接，为这些连接收集并派发IO事件。回到TcpServer::newConnection中： void TcpServer::newConnection(int sockfd, const InetAddress&amp; peerAddr) { ... EventLoop* ioLoop = threadPool_-&gt;getNextLoop(); ... TcpConnectionPtr conn(new TcpConnection(ioLoop, // 使用这个选择到的线程中的EventLoop connName, sockfd, localAddr, peerAddr)); ... ioLoop-&gt;runInLoop(boost::bind(&amp;TcpConnection::connectEstablished, conn));注意TcpConnection::connectEstablished是如何通过Channel注册关心的IO事件到ioLoop的。极端来说，muduo的每一个连接线程可以只为一个网络连接服务，这就有点类似于thread per connection模型了。网络模型传说中的Reactor模式，以及one loop per thread，基于EventLoop的作用，以及线程池与TcpConnection的关系，可以醍醐灌顶般理解以下这张muduo的网络模型图了：总结本文主要对muduo的主要结构及主要机制的实现做了描述，其他如Buffer的实现、定时器的实现大家都可以自行研究。muduo的源码很清晰，通过源码及配合陈硕博客上的内容可以学到一些网络编程方面的经验。" }, { "title": "dhtcrawler的进程模型经验", "url": "/posts/dhtcrawler-process/", "categories": "erlang, module", "tags": "erlang, dht, p2p, magnet, dhtcrawler", "date": "2014-02-21 00:00:00 +0800", "snippet": "距离写dhtcrawler已经有半年时间。半年前就想总结点心得经验，但最后写出来的并没有表达出我特别有感慨的地方。最近又被人问到这方面的经验问题，才静下心来思考整理了下。我的经验是关于在写一个网络项目时所涉及到的架构（或者说是模型）。在dhtcrawler中，一个主要的问题是：程序在网络中需要尽可能快尽可能多地收集请求，然后程序需要尽可能快地加工处理这些信息。本质上就这么简单，我觉得很多网络系统面临的都可能是类似的问题。详细点说，dhtcrawler高峰期每天会收到2000万的DHT协议请求，收到这些请求后，dhtcrawler需要对这些请求做处理，包括：合并相同的请求；从外部网站请求下载种子文件；新增/更新种子信息到数据库；建立种子sphinx索引等。在实际运行期间，高峰期每天能新录入14万个种子。那么如何架构这个系统来让处理速度尽可能地快呢？首先，毫无疑问这个系统是多线程/多进程，甚至是分布式的。写一个多线程程序学几个API谁都会，但是如何组织这些线程以让系统最优则是一个较困难的问题。根据dhtcrawler的经验，我简单总结了以下几种模型/架构：简单模型约定一个线程/进程为worker。那么简单模型就是每一个worker都包含了完整的处理逻辑，从收到请求，到把该请求处理完毕。Req -&gt; Worker -&gt; Process -&gt; O当然，我们可以给系统配置若干个Worker，以求最大化效率。例子中，Req的来源是非常快非常多的，而 Process过程相对而言则非常慢，涉及到各种IO操作（从外部网站下载种子，写入数据库等）。这个模型的整体效率完全受限于Process的过程。如果Req的来源速度还不是稳定的，那么Process的速度将严重影响系统的吞吐性。当然这个模型的优点就是特别简单，咋并发系统中简单有利于维护和调试。粗粒度分离模型分离模型指的是把Req的获取过程和处理过程分离开来。也就是合理地将系统中慢的部分和快的部分分离。然后两者之间通过一些数据共享方式来交互。Req -&gt; ReqWorker -&gt; PoolPool -&gt; ReqProcessor -&gt; O这个时候，ReqWorker可以以尽可能快的速度收集Req，不用受限于ReqProcessor的处理速度。这个Pool的实现有很多方式。这种模型有点类似于线程/进程间的交互，典型的生产者消费者问题。在需要同步的实现中，Pool可能需要写的比较精巧。Pool可以放置在内存中。也就是ReqWorker把收到的请求稍作加工就放到内存中。这里的稍作加工可以是一段时间里的重复数据合并。ReqProcessor则可以以一定策略从这个内存中取得Req。这个策略可以是以一定时间间隔，或者基于ReqWorker的通知。在erlang中，可以以一个单独的进程来维护这个Pool。那么这里就是通过erlang的进程来实现数据的同步。本质上也是基于erlang进程的mailbox机制。这个维护Pool的进程逻辑足够简单，可以快速响应ReqWorker的Req压入，以及ReqProcessor的Req取出。在用erlang的过程中，很多时候就是在平衡这种actor进程模式中各种进程间的协调程度。平衡不好会导致两种情况：a)进程mailbox暴涨最后内存耗尽；b)消费者进程请求资源超时。Pool被放置在内存中时，本身也可能有问题。例如数据量过大，无论是直接基于OS的程序还是基于erlang/jvm等虚拟机的程序，都可能在这个时候出现问题。并且，把数据放置在内存中也可能由于程序不稳定导致数据丢失。dhtcrawler中把很多中间数据放置在数据库中。当然这里是个权衡问题。更复杂的系统里我相信就可以加入内存数据库之类的系统。使用了分离模型之后，还是可以配置每种进程的数量，但是这里的问题在于很难平衡每种进程所配置的比例，以最大化使用CPU内存之类的资源。细粒度分离模型异步程序编写起来始终比同步程序更困难。在异步系统中需要加入各种例如事件、消息等机制。一个简单的逻辑可能会分散到程序的不同地方。对于资源的管理，错误的排除，性能的调优都带来了困难。细粒度分离模型同粗粒度模型一样，只不过对进程种类的划分粒度更细。在erlang这种使用进程来组织程序合情合理的语言中，就可以做到每一种进程仅仅只做一种事情，就像函数设计原则一样，功能单一。以dhtcrawler为例，整个系统可以划分为如下若干种进程： 请求收集，用于收集请求，涉及到网络操作和数据库操作 请求分类，将请求按是否需要从外部网站下载种子分类，仅涉及到数据库操作 种子下载，从外部网站下载种子 种子索引，建立sphinx索引部分简单的进程其代码实现量不到千行。在erlang的进程中也是简单的几个消息，维护起来非常容易。从上面的这种模型中，进程之间全部通过数据库做交互，那就很自然地可以发展为分布式系统。数据库再通过集群之类的技术，可以较高地提升系统的吞吐量。" }, { "title": "my 2013", "url": "/posts/2013/", "categories": "other", "tags": "2013", "date": "2014-02-02 00:00:00 +0800", "snippet": "技术这一年里个人的技术感觉进步不是那么大。一方面技术之外的事情多了起来，另一方面由于工作原因接触的技术也较为杂乱，没有机会专注。技术的提升还是得靠业余时间。系统分析设计学了些RUP的方法，对规范化的系统分析设计算是有了一定认识。但这个东西在实践的过程中往往较难运用，好的方法学还是得看项目的实际情况而定。单元测试软件基于clang重写了公司的一个测试软件。因为之前有过一定的编译原理实践，本身我对编程语言也有一定认识，所以带领团队实现这个项目的时候也较容易。倒是对clang的研究，一直没有深入的机会。浏览器前端这一年里工作原因，对浏览器前端的一些技术有了更深的接触。后来还参与了部分编码，使用AngularJS和Bootstrap写了些代码。到目前为止对Javascrpt以及前端框架理念只能算有了个初步认识。也是希望能在这一块有一定深入的机会。自己写一个前端框架应该不难。Erlang基于之前做的dhtcrawler2，对Erlang有了一定的实践经验。使用函数式语言编写应用非常爽。主要体现在对集合的方便操作，以及lambda的应用。但Erlang的基础API确实不优美，接口的命名风格都存在一定的不统一。Erlang的进程模型非常酷，用来写服务器程序非常自然。进程相关的API比起同样是actor模型的akka好用太多。Erlang调优依然是服务器编程中无法回避的问题，虽然OTP提供了很多辅助这一过程的接口。dhtcrawler2也存在很多问题，可惜后来实在太忙，已经没有时间顾及这种业余项目。ScalaScala到目前为止也是一门我比较喜欢的语言。它综合了面向对象和函数式语言的特性，基于JVM可以无代价地使用任何一个Java库，使得该语言在实际应用中没有什么阻碍。Scala的语法集很大，能被写出难以阅读的代码。11月份的时候接了一个外包，我就直接选用了Scala来做，总算有了实践机会。在实际使用中越是发现Scala的强大。但对语言本身还深入的很不够，也希望在未来有更多的实践机会。团队管理适量的制度和信任有那么一段时间很多很细的事情我都亲历亲为，对于整个项目的细节都掌握得比较清楚，对于每个技术实现方案也都是自己在做，后来发现这样太累，没有精力做更高层面的工作。所以，后来我就在这个度上做了些调整。仅做技术方案的大体制定，将分析设计的细化交给能够胜任的人。通过一份好的文档来做几次高效率的沟通，从而节省了我的时间。此外，这种方式也有利于培养团队成员编码之外的能力，对于成员本身应该也是大有益处的。对于团队成员的信任，应该是一个逐渐累积的过程。这个过程中存在一定的磨合期，这个磨合期我觉得应该建立一些制度，用于实现沟通的有效性、工作的明确性以及部分工作的指导。这个制度应该保持轻量，尽量维持在不限制程序员的创造性以及造成厌恶情绪的程度。团队氛围的营造团队氛围我觉得是非常重要的，它可以与公司的氛围不一样。良好的氛围可以较大程度地提升团队成员的工作积极性，提高团队的战斗力。团队的氛围肯定是需要与团队成员契合的，这涉及到人员招聘的问题。我希望我的团队应该充满技术氛围。程序员处在这个团队中，不仅仅是为公司工作，在项目中能够把解决掉的某个问题作为茶余饭后的谈资。成员之间应该可以在任何时候任何地点激情地讨论技术问题。程序员留在这个团队不仅仅是因为公司提供的待遇，团队本身的引力应该占到足够的比重。要营造以上的氛围，我觉得Leader要做很多工作。可以包括： 适当且有效的技术交流，这其实也很难 一定频率的技术比赛，要适合每个成员的参与，也比较困难 技术热情的散播，Leader可以随时随地发起话题 项目问题的讨论 项目经验的总结及散播此外，除了以上需要尽量做到的事情之外，我觉得有些事情是应该避免做的，包括： 工作时间与项目关系不太直接的纯技术学习。这其实本身是件好事，但其实反映了一个管理问题：某个成员的工作安排不够饱和。而一旦出现这样的情况，Leader不应该立即制止，而是分析项目情况以及成员的工作安排，通过及时安排工作来中断该行为。纯技术的学习，可以作为某个技术点交流会议的准备。 浏览技术之外的网页或其他甚至和自身技术提升不沾边的行为。我一般不明确制止该行为，但会同上一点一样从其他方面终止该行为。我觉得，一个团队成员的不良行为，往往不仅仅是影响到他自己，这种现象通常会进行传播。人员招聘基于我喜欢的团队氛围目标，我会在程序员招聘时就进行严格的筛选。我一般不喜欢包含以下特征的程序员： 基础不好。我希望我团队中的每个成员都能成长为牛人，拥有较快上升特征的程序员也会给团队注入活力。而不管你是从事什么类型开发的程序员，我相信扎实的计算机基础才是成长的基石。当然，出于公司或项目原因，这个条件可以放宽。 浮夸。我喜欢踏实的程序员，会就是会，不会就是不会，不熟就是不熟，忘了就是忘了。实力可以从很多方面体现出来，但肯定不是每一项技术细节你都了解。当然，那种招聘5年C++程序员却嫌你不熟MFC的面试官本身就是一个问题，除非他明确地招聘一个MFC程序员。浮夸的特征不一定很明显，但是我觉得如果遇到一个能说会道的人，那就得小心点。 说话太冲。这个主要是担心以后难以管理，与其他人合作会有问题。在面试的时候我尽量表现的随意，希望面试者将面试过程当作一次平等的技术交流。但是，我觉得对面试官的基本尊重必须有。可能有些技术问题无法达成共识，但没必要在面试的过程中追根究底面红耳赤。我在面试过程中有几次坦白自己不太确定某个技术，也曾很自信地告诉对方可以私下验证一下我的结论。我的组员中还确实有人在入职的时候告诉我，某某问题我错了。我都能欣然接受，反而能增加我的好感。由于我处在一个小公司，所以我不会对性格做过多的考察。我觉得，对于这样的公司，只要这个程序员不是内向到沟通比较困难，不是太自我为中心，就成。人员招聘是一件需要很谨慎的事情。我可能在看人上还很欠缺经验，所以在过去面试的几十个人里（应该在50以下），我花费的平均面试时间大概在2小时左右。为了提高这2小时的有效率，通过有效合理的笔试题和简历研究来进行筛选是必不可少的手段。适当的职责提升这个同给予成员信任差不多。一个人得到别人的信任才能把事情做得更好，对项目本身也会有归属感。在项目的某些时期，明确地提升某个成员的职责，意义也在于此。当然这涉及到人员的挑选，我觉得有足够的责任心以及技术实力，就可以胜任这个角色。再往上的话，当然得需要一定的协调能力，能够协调一定数量的人员将项目的某一部分良好地完成。项目管理由于几个项目规模都较小，一个月的时间4个程序员就可以获得一个雏形。所以我感觉这些项目的管理方式更偏重于敏捷。在项目中有些活动是必须的。项目计划说法上我们称一自然周为一个迭代周期。在项目做完初步的分析设计之后，我会根据当时对项目的把握情况做出尽可能久尽可能详细的迭代计划。这份迭代计划会描述未来几次迭代周期应该完成的内容。项目里程碑在哪个时间点。在项目开始的时候，每一次迭代开始我会更新这份迭代计划，尽可能细化当前迭代的内容。迭代的内容里主要包含开发内容，但也会包含需求沟通、分析设计、测试类工作。项目总结在每一次迭代快完的时候，我会及时总结当前迭代所完成的内容。这些内容一般都会与计划有些微的出入，有时候由于需求的介入、客户方的要求等等，实际完成的内容可能会非常不同。除了在迭代结束的时候总结当前完成情况之外，在迭代中我也可能进行总结分析。其目的并不在于形成一种规范，而在于真真实实地辅助对项目进展的把控。另一方面，当项目进度不再特别紧的时候，我觉得团队主要人员应该对整个项目的技术进行分析总结，一方面起到促进沟通交流的作用，另一方面也可以为团队沉淀技术实力和业务知识。例会/周报/管理系统在公司里做事往往需要对上对下。这么多感触，基本上都是对下的经验。公司高层虽然不需要像项目经理一样对项目做细致地把控，但也不能完全隔离项目的实际情况。有些规章制度总是需要的。这些制度对于程序员而言可能是一种干扰，但对管理层而言却也是必不可少的。一套好用的项目管理系统，可以尽可能方便地让项目参与人员录入信息，也尽可能方便地管理层看到项目的大致进展情况，看到项目成员的工作情况。这也是目前我觉得我们做得不好的地方。关于周报，我觉得在项目较空闲的时候是完全没有必要的。这个同某个成员在某个时间段较空闲的理由一样，这完全是管理层的问题，却要把这个问题转换为程序员编造工作周报的烦恼。但在项目较紧的时候，则是很有必要的。工作例会，同很多沟通活动一样，我主张效率至上。在我能控制范围内，尽可能少地进行形式化的活动。例会的内容通常用于团队成员彼此之间工作内容的交流，让每个人知道其他人大概做的事情。同时，例会也是维持团队工作激情的一种简单方式。总结2013年下半年开始就一直很忙。最差的情况是：加班，加完班回去接着做外包，完了就睡觉。在项目里偶尔充当打杂的角色，哪块技术缺人就去补位。有时候又不放心别人的工作，又要去参合一下。公司里偶尔也有些杂物事。招聘人也费了不少时间，接触得多了发现来面试的群体都差不多，对自身的提高也失去了作用。工作上偶尔觉得有压力。眼看快而立之年，技术没什么特别强的建树，钱也没挣到，生活也不免有了压力。有时候想回去游戏行业，觉得专注一个领域才有长足的发展。但又没有特别吸引人的团队和公司。不太喜欢和国企的人打交道，虚来虚去，时间浪费不少。越来越相信选择有时候特别重要。希望2014年，自己还是能把眼前的事踏实做好。无论是技术还是管理还是个人收入，都能真正地上一个台阶。" }, { "title": "scala主要特性一览", "url": "/posts/scala-feature-overview/", "categories": "Scala", "tags": "scala, curry", "date": "2013-09-23 00:00:00 +0800", "snippet": "概述scala语言包含了函数式语言和面向对象语言的语法特性，从我目前的感受来看，这不是一门简单的语言。同Ruby/Erlang相比，其语法集大多了。scala基于JVM或.NET平台，其可以几乎无缝地使用Java库（不但使用上没有负担，其运行效率上也不会增加负担），配合其强大的语言表达能力，还是很有吸引力。类型类/对象scala中一切都是对象，虽然Java也是这样说的（其实ruby也是这样说的）。在Java中一个数字仅仅是个值，但在scala中却真的是对象：\tprintln(\"2 type: \" + 2.getClass())scala同Java一样将所有类型都设定了一个基类：Any。不同的是，Any下还区分了AnyVal和AnyRef。类型推断scala是一门静态类型语言，但是其强大的类型推断可以避免很多冗余信息的代码。例如：\tval map:Map[String, Int] = new HashMap[String, Int]// 可简写为val map = new HashMap[String, Int]def func():String = {\t\"hello\"}// 可简写为def func() = {\t\"hello\"}类型推断可以根据表达式的类型决定这个变量/函数的类型，这就如同C++11中的auto关键字。函数scala既然包含了函数式语言的特性，那么函数作为first citizen就是自然而言的事情。而function literal的语法形式也就必须更自然（想想common lisp里lambda那蛋疼的关键字）：\tval factor = 3val multiplier = (i:Int) =&gt; i * factor // function literal, lexical bind to factorval l1 = List(1, 2, 3, 4, 5) map multiplier // map `multiplier` to every element in List l1def add(a:Int, b:Int) = { a + b}val f:(Int, Int) =&gt; Int = add // f is a function type: (Int, Int) =&gt; Intprintln(\"f:\" + f(2, 3))Symbol在Ruby中有Symbol，在Erlang中也有Symbol(Erlang中叫Atom)。Symbol在Erlang中使用非常自然，因为其思维模式；但在scala中基于目前我还在把它当命令式语言使用，Symbol成了一个可有可无的特性。语句/表达式scala中其实没有语句。对于if/while之类都算是表达式，其处理方式同函数式语言中一样，将最后一个表达式的值作为返回值：\tval i = if (2 &gt; 1) 'true else 'false控制语句if/while什么的同C-like language一致。for comprehension这个语法特性对应着函数式语言中的List Comprehension，可以用于处理一个集合，以产出另一个集合。\tval r = for { n &lt;- Array(1, 2, 3, 4, 5) if n % 2 == 0} yield nr map println这个例子同Erlang中的：[N || N &lt;- [1, 2, 3, 4, 5], N rem 2 == 0].for中的generator在实践中也比较有用，相当于foreach：\tfor (i &lt;- Array(1, 2, 3, 4)) println(i)pattern matchpattern match同Erlang中一样，可以简单地当switch…case来用，但用途远不止于对整数值的匹配。pattern match同样有返回值，其返回值为匹配成功块的值。最简单的匹配：\tprintln(1 match { case 1 =&gt; \"one\" case 2 =&gt; \"two\" case _ =&gt; \"unknown\" })对类型进行匹配：\tval obj:Any = nullprintln(obj match { case t:Int =&gt; \"int\" case t:String =&gt; \"string\" case _ =&gt; \"unknown\"})更有用的是提取list/tuple之类集合里的元素。通过一个match…case才能匹配出list/tuple里的元素（当然也可以通过一些函数来提取），多少有点累赘：\t(\"hello\", 110) match { case (str, _) =&gt; println(str) case _ =&gt; println(\"unknown\")}List(\"hello\", 110, 'sym) match { case List(_, _, s) =&gt; println(s) case _::n::_ =&gt; println(n) // head::tail}例子中还体现了scala对于list的处理能力，果然包含了函数式语言的特性。Guard函数式语言里为了支持if，一般都会有Guard的概念。其用于进行条件限定，在scala中的for comprehension和pattern match中四处可见：\tval obj:Any = \"hello\"println(obj match { case t:Int =&gt; \"int\" case t:String if t == \"hello\" =&gt; \"world\" // guard case t:String =&gt; \"hello\" case _ =&gt; \"unknown\"})trait/abstract typetrait可以用于实现mix-in，虽然可以简单地将它视为interface，但它的功能远不止于此：简单的应用：\ttrait Show { def show(s:String) = println(s)}abstract class Widgetclass MyClass extends Widget with Show { override def show(s:String) = println(\"MyClass \" + s)}val t:Show = new MyClasst show \"hello\" // 等同于t.show(\"hello\")，scala中支持这种函数调用，可应用于构建DSL以上例子显现不出trait的作用。trait为了支持“混入(mixin)“，语法上允许在创建一个对象时，混入一个trait，而不用在类定义时混入：\ttrait Show { def show(s:String) = println(s)}class Person(val name:String) {}val person = new Person(\"kevin\") with Show // 混入Show到person中person.show(person.name) // person拥有show接口classclass方面的语法可以简单关注些常用的语法，trait一节中的例子已经显示了class定义方面的一些语法：\tclass Person(val name:String) { // primary constructor，参数作为类成员 val address = \"earth\" // 另一个成员，默认的可见属性 var id:Int = 0 private val email = \"kevinlynx at gmail dot com\" // private成员 id = randid // 类体一定程度上作为primary constructor函数体 def fullname = println(name + \" lynx\") // 接口 def this() = this(\"ah\") // 0个或多个auxiliary constructor，可以调用primary constructor def randid:Int = 2}val p = new Personprintln(p.fullname)println(p.id)面向对象语法在scala中占有很大的比例，除了基本类语法外，还有很多类相关的语法，例如companion classes、case classes等。objectobject类似于类，类可以有很多实例化出很多对象，但object则只有一个实例，其更像一个语言内置的单件模式。scala中任意object，只要包含了main接口，即可作为一个程序的入口：\tobject Test { val i = 100 val str = \"hello\"\t def main(args:Array[String]) = { println(i) }}println(Test.str)functions首先，函数定义是可以嵌套的。函数相关的语法里这里只关注几个重要的函数式风格的语法，包括：偏函数(partial function)、柯里化(currying)等。partial functions简单来说就是将多参数的函数转换为某个参数为固定值的函数：\tdef concatUpper(s1:String, s2:String):String = (s1 + \" \" + s2).toUpperCaseval c1 = concatUpper _ // now c1 is a function value, type: (String, String) =&gt; Stringprintln(c1(\"short\", \"pants\"))val c2 = concatUpper(\"short\", _:String)println(c2(\"pants\")) currying函数柯里化同偏函数一定程度上具有相同的作用。scala里柯里化函数的语法不同：\tdef multiplier(i:Int)(factor:Int) = i * factor// 当然也可以将一个普通函数转换为柯里化版本val catVal = concatUpper _val curryCat = catVal.curried // 2.10中curry，以前是用Function.curriedval catLeft = curryCat(\"hello\")println(catLeft(\"world\"))call by name函数参数传递中的call by name特性，有点类似于惰性计算，即在使用到参数的时候才计算该参数，而不是在调用函数之前就把参数值计算好。\tdef show(s: =&gt; String) = { // 指定s call by name println(\"show get called\") println(\"argument:\" + s)}def getStr = { println(\"getStr get called\") \"hello\"}show(getStr)给我印象较深的是，通过call by name语法，可以实现一个如同while的函数：\tdef myWhile(cond: =&gt; Boolean)(f: =&gt; Unit) { if (cond) { f myWhile(cond)(f) }}var count = 0// WTF ?myWhile(count &lt; 3) { println(\"in while\") count += 1}otherscala中有那么一些语法，虽然不是什么很大的特性，但很会给人留下深刻的印象。structural types和parameterized types有点像C++里的模板，前者约定拥有相同接口的类型，后者则只表示一种类型。structural types用来表示所有拥有某个相同原型接口的类型：\t// 相当于C中的typedef，定义一个structural types类型，需要包含名为show的接口type MyType = { def show():Unit } class ClassA { def show():Unit = { println(\"ClassA\") }}class ClassB { def show():Unit = { println(\"ClassB\") }}var obj:MyType = nullobj = new ClassAobj.showobj = new ClassBobj.show虽然ClassA/ClassB没有任何关系，但因为都包含了一个show接口，则可以通过一个统一的类型将其统一起来。parameterized types基本类似于C++模板，但仅限于类型信息，适合定义类似C++ STL的容器：\tclass Vector[T](var a:T, var b:T) {}val v = new Vector[Int](1, 2)println(v.a + \":\" + v.b)小结目前基于JVM的语言有很多，基于JVM的好处是可以使用Java社区丰富的库、框架。scala的语法还算优美，值得一试。希望能有机会投入到更大的项目中使用。" }, { "title": "Javascript Overview", "url": "/posts/javascript-overview/", "categories": "Javascript", "tags": "javascript", "date": "2013-08-21 00:00:00 +0800", "snippet": "Lexical StructureIn JavaScript, identifiers are used to name variables and functions and to provide labels for certain loops in JavaScript code. A JavaScript identifier must begin with a letter, an underscore (_), or a dollar sign ($). Subsequent characters can be letters, digits, underscores, or dollar signsiabcv1$strJavaScript allows identifiers to contain letters and digits from the entire Unicode character set.Like many programming languages, JavaScript uses the semicolon (;) to separate statements from each other. In JavaScript, you can usually omit the semicolon between two statements if those statements are written on separate lines.Types/Values/VariablesNumbersUnlike many languages, JavaScript does not make a distinction between integer values and floating-point values. All numbers in JavaScript are represented as floating-point values.030xff3.14Strings\"hello world\"'hello world'\"Wouldn't you prefer O'Reilly's book?\"\t &lt;!-- more --&gt; ### BooleantruefalseAny JavaScript value can be converted to a boolean value. The following values convert to, and therefore work like, false:undefinednull0-0NaN\"\" // the empty stringnull/undefinednull is a language keyword that evaluates to a special value that is usually used to indicate the absence of a value. Using the typeof operator on null returns the string “object”, indicating that null can be thought of as a special object value that indicates “no object”.ObjectsJavaScript objects are composite values: they are a collection of properties or named values.var s = \"hello world!\"; // A stringvar word = s.substring(s.indexOf(\" \")+1, s.length); \tvar obj = { propName1: 123, propName2: \"abc\"};obj.propName1 = 456;obj[\"propName1\"] = 456; // same as previous statementArraysArrays are a specialized kind of object. JavaScript arrays are untyped: an array element may be of any type, and different elements of the same array may be of different types.var empty = []; // An array with no elementsvar primes = [2, 3, 5, 7, 11]; // An array with 5 numeric elementsvar misc = [ 1.1, true, \"a\", ]; // 3 elements of various types + trailing commaAnother way to create an array is with the Array() constructor:var a = new Array();var a = new Array(10);var a = new Array(5, 4, 3, 2, 1, \"testing, testing\");FunctionsFunctions designed to initialize a newly created object are called constructors. In JavaScript, functions are objects. JavaScript can assign functions to variables and pass them to other functions. JavaScript function definitions can be nested within other functions.function printprops(o) {\tfor(var p in o)\tconsole.log(p + \": \" + o[p] + \"\\n\");}var square = function(x) { return x*x; }function hypotenuse(a, b) {\tfunction square(x) { return x*x; }\treturn Math.sqrt(square(a) + square(b));}Expressions/OperatorsObject and Array initializersvar p = { x:2.3, y:-1.2 }; // An object with 2 propertiesvar q = {}; // An empty object with no propertiesq.x = 2.3; q.y = -1.2; // Now q has the same properties as pvar matrix = [[1,2,3], [4,5,6], [7,8,9]];Object creation expressionAn object creation expression creates a new object and invokes a function (called a constructor) to initialize the properties of that object.new Object()new Point(2,3)Operators Arithmetic operator Relational operator Logical operator Assignment operator Conditional operator typeof operator delete operatoreval expressionJavaScript has the ability to interpret strings of JavaScript source code, evaluating them to produce a value. JavaScript does this with the global function eval():eval(\"3+2\") // =&gt; 5StatementsDeclaration StatementsThe var statement declares a variable or variables. Here’s the syntax:var name_1 [ = value_1] [ ,..., name_n [= value_n]]\tConditionalsif (expression)\tstatement\telse if (expression)\tstatementswitch(expression) {\tstatements}Loopswhile (expression)\tstatementdo\tstatementwhile (expression);for(initialize ; test ; increment)\tstatementfor (variable in object)\tstatementvar o = {a:1, b:2};for(var p in o) // Assign property names of o to variable p\tconsole.log(o[p]); // Print the value of each propertyOther break/break label continue/continue label return throw try/catch/finally with use strictObjectsAn object is more than a simple stringtovalue map, however. In addition to maintaining its own set of properties, a JavaScript object also inherits the properties of another object, known as its “prototype”. The methods of an object are typically inherited properties, and this “prototypal inheritance” is a key feature of JavaScript.JavaScript objects are dynamic—properties can usually be added and deleted—but they can be used to simulate the static objects and “structs” of statically typed languages.Objects are mutable and are manipulated by reference rather than by value.Every JavaScript object has a second JavaScript object (or null, but this is rare) associated with it. This second object is known as a prototype.Objects created using the new keyword and a constructor invocation use the value of the prototype property of the constructor function as their prototype.Object.create() creates a new object, using its first argument as the prototype of that object.var o1 = Object.create({x:1, y:2}); // o1 inherits properties x and y.If you want to create an ordinary empty object (like the object returned by {} or new Object()), pass Object.prototype:var o3 = Object.create(Object.prototype); // o3 is like {} or new Object().The delete operator removes a property from an object:delete book.author; // The book object now has no author property.delete book[\"main title\"]; // Now it doesn't have \"main title\", either.property getters and settersProperties defined by getters and setters are sometimes known as accessor properties to distinguish them from data properties that have a simple value.var p = {\t// x and y are regular read-write data properties.\tx: 1.0,\ty: 1.0,\t// r is a read-write accessor property with getter and setter.\t// Don't forget to put a comma after accessor methods.\tget r() { return Math.sqrt(this.x*this.x + this.y*this.y); },\tset r(newvalue) {\t\tvar oldvalue = Math.sqrt(this.x*this.x + this.y*this.y);\t\tvar ratio = newvalue/oldvalue;\t\tthis.x *= ratio;\t\tthis.y *= ratio;\t},\t// theta is a read-only accessor property with getter only.\tget theta() { return Math.atan2(this.y, this.x); }};FunctionsIn JavaScript, functions may be nested within other functions. For example:function hypotenuse(a, b) {\tfunction square(x) { return x*x; }\treturn Math.sqrt(square(a) + square(b));}\tInvoking functionsJavaScript functions can be invoked in four ways: as functions as methods as constructors indirectly through their call() and apply() methodsOptional parameters// Append the names of the enumerable properties of object o to the// array a, and return a. If a is omitted, create and return a new array.function getPropertyNames(o, /* optional */ a) {\tif (a === undefined) a = []; // If undefined, use a new array\tfor(var property in o) a.push(property);\treturn a;}// This function can be invoked with 1 or 2 arguments:var a = getPropertyNames(o); // Get o's properties into a new arraygetPropertyNames(p,a); // append p's properties to that arrayVariable-Length Argument Lists: The Arguments Objectfunction max(/* ... */) {\tvar max = Number.NEGATIVE_INFINITY;\t// Loop through the arguments, looking for, and remembering, the biggest.\tfor(var i = 0; i &lt; arguments.length; i++)\tif (arguments[i] &gt; max) max = arguments[i];\t// Return the biggest\treturn max;}var largest = max(1, 10, 100, 2, 3, 1000, 4, 5, 10000, 6); // =&gt; 10000In addition to its array elements, the Arguments object defines callee and caller properties.var factorial = function(x) {\tif (x &lt;= 1) return 1;\treturn x * arguments.callee(x-1);};Function as valuesFunctions are not primitive values in JavaScript, but a specialized kind of object, which means that functions can have properties.// Initialize the counter property of the function object.// Function declarations are hoisted so we really can// do this assignment before the function declaration.uniqueInteger.counter = 0;// This function returns a different integer each time it is called.// It uses a property of itself to remember the next value to be returned.function uniqueInteger() {\treturn uniqueInteger.counter++; // Increment and return counter property}ClosuresLike most modern programming languages, JavaScript uses lexical scoping.Function bind methodWhen you invoke the bind() method on a function f and pass an object o, the method returns a new function. Invoking the new function (as a function) invokes the original function f as a method of o. Any arguments you pass to the new function are passed to the original function.function f(y) { return this.x + y; } // This function needs to be boundvar o = { x : 1 }; // An object we'll bind tovar g = f.bind(o); // Calling g(x) invokes o.f(x)g(2) // =&gt; 3\tThe Function() ConstructorFunctions are usually defined using the function keyword, either in the form of a function definition statement or a function literal expression. But functions can also be defined with the Function() constructor. For example:var f = new Function(\"x\", \"y\", \"return x*y;\");Reference &lt;Javascript The Definitive Guid 6th&gt; A Survey of the JavaScript Programming Language A quick overview of JavaScript JavaScript Summary" }, { "title": "记一次堆栈平衡错误", "url": "/posts/debug-esp-bug/", "categories": "c/c++", "tags": "esp, stack, 堆栈", "date": "2013-08-15 00:00:00 +0800", "snippet": "最近在一个使用Visual Studio开发的C++程序中，出现了如下错误： Run-Time Check Failure #0 - The value of ESP was not properly saved across a function call. This is usually a result of calling a function declared with one calling convention with a function pointer declared with a different calling convention.这个错误主要指的就是函数调用堆栈不平衡。在C/C++程序中，调用一个函数前会保存当前堆栈信息，目标函数返回后会把堆栈恢复到调用前的状态。函数的参数、局部变量会影响堆栈。而函数堆栈不平衡，一般是因为函数调用方式和目标函数定义方式不一致导致，例如：void __stdcall func(int a) {}int main(int argc, char* argv[]) { typedef void (*funcptr)(int); funcptr ptr = (funcptr) func; ptr(1); // 返回后导致堆栈不平衡 return 0;}__stdcall修饰的函数，其函数参数的出栈由被调用者自己完成，而__cdecl，也就是C/C++函数的默认调用约定，则是调用者完成参数出栈。Visual Studio在debug模式下会在我们的代码中加入不少检查代码，例如以上代码对应的汇编中，就会增加一个检查堆栈是否平衡的函数调用，当出现问题时，就会出现提示Run-Time Check Failure...这样的错误对话框：call dword ptr [ptr] ; ptr(1)add esp,4 ; cdecl方式，调用者清除参数cmp esi,esp call @ILT+1345(__RTC_CheckEsp) (0B01546h) ; 检查堆栈是否平衡但是我们的程序不是这种低级错误。我们调用的函数是放在dll中的，调用约定显示定义为__stdcall，函数声明和实现一致。大致的结构如下：IParser *parser = CreateParser();parser-&gt;Begin();......parser-&gt;End();parser-&gt;Release(); // 返回后导致堆栈不平衡IParser的实现在一个dll里，这反而是一个误导人的信息。parser-&gt;Release返回后，堆栈不平衡，并且仅仅少了一个字节。一个字节怎么来的？解决这个问题主要的手段就是跟反汇编，在关键位置查看寄存器和堆栈的内容。编译器生成的代码是正确的，而我们自己的代码乍看上去也没问题。最后甚至使用最傻逼的调试手段–逐行语句注释查错。具体查错过程就不细说了。解决问题往往需要更多的冷静，和清晰的思路。最终我使用的方法是，在进入Release之前记录堆栈指针的值，堆栈指针的值会被压入堆栈，以在函数返回后从堆栈弹出，恢复堆栈指针。Release的实现很简单，就是删除一个Parser这个对象，但这个对象的析构会导致很多其他对象被析构。我就逐层地检查，是在哪个函数里改变了堆栈里的内容。理论上，函数本身是操作不到调用者的堆栈的。而现在看来，确实是被调用函数，也就是Release改写了调用者的堆栈内容。要改变堆栈的内容，只有通过局部变量的地址才能做到。最终，我发现在调用完以下函数后，我跟踪的堆栈地址内容发生了改变：call llvm::RefCountedBase&lt;clang::TargetOptions&gt;::Release (10331117h)因为注意到TargetOptions这个字眼，想起了在parser-&gt;Begin里有涉及到这个类的使用，类似于：TargetOptions TO;...TargetInfo *TI = TargetInfo::CreateTargetInfo(m_inst.getDiagnostics(), TO);这部分初始化代码，是直接从网上复制的，因为并不影响主要逻辑，所以从来没对这块代码深究。查看CreateTargetInfo的源码，发现这个函数将TO这个局部变量的地址保存了下来。而在Release中，则会对这个保存的临时变量进行删除操作，形如：void Delete() const { assert (ref_cnt &gt; 0 &amp;&amp; \"Reference count is already zero.\"); if (--ref_cnt == 0) delete static_cast&lt;const Derived*&gt;(this);}但是，问题并不在于对一个局部变量地址进行delete，delete在调试模式下是做了内存检测的，那会导致一种断言。TargetOptions包含了ref_cnt这个成员。当出了Begin作用域后，parser保存的TargetOptions的地址，指向的内容（堆栈）发生了改变，也就是ref_cnt这个成员变量的值不再正常。由于一些巧合，主要是代码中各个局部变量、函数调用顺序、函数参数个数（曾尝试去除Begin的参数，可以避免错误提示），导致在调用Release前堆栈指针恰好等于之前保存的TargetOptions的地址。注意，之前保存的TargetOptions的地址，和调用Release前的堆栈指针值相同了。而在TargetOptions的Delete函数中，进行了--ref_cnt，这个变量是TargetOptions的第一个成员，它的减1，也就导致了堆栈内容的改变。至此，整个来龙去脉算是摸清。" }, { "title": "dhtcrawler2换用sphinx搜索", "url": "/posts/sphinx-dhtcrawler/", "categories": "erlang, network", "tags": "erlang, dht, dhtcrawler, mongodb, sphinx", "date": "2013-08-08 00:00:00 +0800", "snippet": "dhtcrawler2最开始使用mongodb自带的全文搜索引擎搜索资源。搜索一些短关键字时很容易导致erlang进程call timeout，也就是查询时间太长。对于像avi这种关键字，搜索时间长达十几秒。搜索的资源数量200万左右。这其中大部分资源只是对root文件名进行了索引，即对于多文件资源而言没有索引单个文件名。索引方式有部分资源是按照字符串子串的形式，没有拆词，非常占用存储空间；有部分是使用了rmmseg（我编译了rmmseg-cpp作为erlang nif库调用 erl-rmmseg）进行了拆词，占用空间小了很多，但由于词库问题很多片里的词汇没拆出来。很早以前我以为搜索耗时的原因是因为数据库太忙，想部署个mongodb集群出来。后来发现数据库没有任何读写的状态下，查询依然慢。终于只好放弃mongodb自带的文本搜索。于是我改用sphinx。简单起见，我直接下载了coreseek4.1（sphinx的一个支持中文拆词的包装）。现在，已经导入了200多万的资源进sphinx，并且索引了所有文件名，索引文件达800M。对于avi关键字的搜索大概消耗0.2秒的时间。搜索试试。以下记录下sphinx在dhtcrawler的应用sphinx简介sphinx包含两个主要的程序：indexer和searchd。indexer用于建立文本内容的索引，然后searchd基于这些索引提供文本搜索功能，而要使用该功能，可以遵循searchd的网络协议连接searchd这个服务来使用。indexer可以通过多种方式来获取这些文本内容，文本内容的来源称为数据源。sphinx内置mysql这种数据源，意思是可以直接从mysql数据库中取得数据。sphinx还支持xmlpipe2这种数据源，其数据以xml格式提供给indexer。要导入mongodb数据库里的内容，可以选择使用xmlpipe2这种方式。sphinx documentxmlpipe2数据源需要按照以下格式提交：&lt;sphinx:docset&gt; &lt;sphinx:schema&gt; &lt;sphinx:field name=\"subject\"/&gt; &lt;sphinx:field name=\"files\"/&gt; &lt;sphinx:attr name=\"hash1\" type=\"int\" bits=\"32\"/&gt; &lt;sphinx:attr name=\"hash2\" type=\"int\" bits=\"32\"/&gt; &lt;/sphinx:schema&gt; &lt;sphinx:document id=\"1\"&gt; &lt;subject&gt;this is the subject&lt;/subject&gt; &lt;files&gt;file content&lt;/files&gt; &lt;hash1&gt;111&lt;/hash1&gt; &lt;/sphinx:document&gt;&lt;/sphinx:docset&gt;该文件包含两大部分：schema和documents，其中schema又包含两部分：field和attr，其中由field标识的字段就会被indexer读取并全部作为输入文本建立索引，而attr则标识查询结果需要附带的信息；documents则是由一个个sphinx:document组成，即indexer真正要处理的数据。注意其中被schema引用的属性名。document一个很重要的属性就是它的id。这个id对应于sphinx需要唯一，查询结果也会包含此id。一般情况下，此id可以直接是数据库主键，可用于查询到详细信息。searchd搜索关键字，其实可以看作为搜索这些document，搜索出来的结果也是这些document，搜索结果中主要包含schema中指定的attr。增量索引数据源的数据一般是变化的，新增的数据要加入到sphinx索引文件中，才能使得searchd搜索到新录入的数据。要不断地加入新数据，可以使用增量索引机制。增量索引机制中，需要一个主索引和一个次索引(delta index)。每次新增的数据都建立为次索引，然后一段时间后再合并进主索引。这个过程主要还是使用indexer和searchd程序。实际上，searchd是一个需要一直运行的服务，而indexer则是一个建立完索引就退出的工具程序。所以，这里的增量索引机制，其中涉及到的“每隔一定时间就合并”这种工作，需要自己写程序来协调（或通过其他工具）sphinx与mongodb上面提到，一般sphinx document的id都是使用的数据库主键，以方便查询。但mongodb中默认情况不使用数字作为主键。dhtcrawler的资源数据库使用的是资源info-hash作为主键，这无法作为sphinx document的id。一种解决办法是，将该hash按位拆分，拆分成若干个sphinx document attr支持位数的整数。例如，info-hash是一个160位的id，如果使用32位的attr（高版本的sphinx支持64位的整数），那么可以把该info-hash按位拆分成5个attr。而sphinx document id则可以使用任意数字，只要保证不冲突就行。当获得查询结果时，取得对应的attr，组合为info-hash即可。mongodb默认的Object id也可以按这种方式拆分。dhtcrawler2与sphinxdhtcrawler2中我自己写了一个导入程序。该程序从mongodb中读出数据，数据到一定量时，就输出为xmlpipe2格式的xml文件，然后建立为次索引，最后合并进主索引。过程很简单，包含两次启动外部进程的工作，这个可以通过erlang中os:cmd完成。值得注意的是，在从mongodb中读数据时，使用skip基本是不靠谱的，skip 100万个数据需要好几分钟，为了不增加额外的索引字段，我只好在created_at字段上加索引，然后按时间段来读取资源，这一切都是为了支持程序关闭重启后，可以继续上次工作，而不是重头再来。200万的数据，已经处理了好几天了。后头数据建立好了，需要在前台展示出来。erlang中似乎只有一个sphinx客户端库：giza。这个库有点老，写成的时候貌似还在使用sphinx0.9版本。其中查询代码包含了版本判定，已经无法在我使用的sphinx2.x版本中使用。无奈之下我只好修改了这个库的源码，幸运的是查询功能居然是正常的，意味着sphinx若干个版本了也没改动通信协议？后来，我为了取得查询的统计信息，例如消耗时间以及总结果，我再一次修改了giza的源码。新的版本可以在我的github上找到：my giza，看起来我没侵犯版本协议吧？目前dhtcrawler的搜索，先是基于sphinx搜索出hash列表，然后再去mongodb中搜索hash对应的资源。事实上，可以为sphinx的document直接附加这些资源的描述信息，就可以避免去数据库查询。但我想，这样会增加sphinx索引文件的大小，担心会影响搜索速度。实际测试时，发现数据库查询有时候还真的很消耗时间，尽管我做了分页，以使得单页仅对数据库进行少量查询。xml unicode在导入xml到sphinx的索引过程中，本身我输出的内容都是unicode的，但有很多资源会导致indexer解析xml出错。出错后indexer直接停止对当前xml的处理。后来查阅资料发现是因为这些无法被indexer处理的xml内容包含unicode里的控制字符，例如 ä (U+00E4)。我的解决办法是直接过滤掉这些控制字符。unicode的控制字符参看UTF-8 encoding table and Unicode characters。在erlang中干这个事居然不复杂：strip_invalid_unicode(&lt;&lt;&gt;&gt;) -&gt;\t&lt;&lt;&gt;&gt;;strip_invalid_unicode(&lt;&lt;C/utf8, R/binary&gt;&gt;) -&gt;\tcase is_valid_unicode(C) of\t\ttrue -&gt;\t\t\tRR = strip_invalid_unicode(R),\t\t\t&lt;&lt;C/utf8, RR/binary&gt;&gt;;\t\tfalse -&gt;\t\t\tstrip_invalid_unicode(R)\tend;strip_invalid_unicode(&lt;&lt;_, R/binary&gt;&gt;) -&gt;\tstrip_invalid_unicode(R).\tis_valid_unicode(C) when C &lt; 16#20 -&gt;\tfalse;is_valid_unicode(C) when C &gt;= 16#7f, C =&lt; 16#ff -&gt;\tfalse;is_valid_unicode(_) -&gt;\ttrue." }, { "title": "磁力搜索第二版-dhtcrawler2", "url": "/posts/dhtcrawler2/", "categories": "erlang, network", "tags": "erlang, dht, p2p, magnet, dhtcrawler", "date": "2013-07-02 00:00:00 +0800", "snippet": "接上篇。下载使用目前为止dhtcrawler2相对dhtcrawler而言，数据库部分调整很大，DHT部分基本沿用之前。但单纯作为一个爬资源的程序而言，DHT部分可以进行大幅削减，这个以后再说。这个版本更快、更稳定。为了方便，我将编译好的erlang二进制文件作为git的主分支，我还添加了一些Windows下的批处理脚本，总之基本上下载源码以后即可运行。项目地址：https://github.com/kevinlynx/dhtcrawler2使用方法 下载erlang，我测试的是R16B版本，确保erl等程序被加入Path环境变量 下载mongodb，解压即用： mongod --dbpath xxx --setParameter textSearchEnabled=true 下载dhtcrawler2 git clone https://github.com/kevinlynx/dhtcrawler2.git 运行win_start_crawler.bat 运行win_start_hash.bat 运行win_start_http.bat 打开localhost:8000查看stats爬虫每次运行都会保存DHT节点状态，早期运行的时候收集速度会不够。dhtcrawler2将程序分为3部分： crawler，即DHT爬虫部分，仅负责收集hash hash，准确来讲叫hash reader，处理爬虫收集的hash，处理过程主要涉及到下载种子文件 http，使用hash处理出来的数据库，以作为Web端接口我没有服务器，但程序有被部署在别人的服务器上：bt.cm，http://222.175.114.126:8000/。其他工具为了提高资源索引速度，我陆续写了一些工具，包括： import_tors，用于导入本地种子文件到数据库 tor_cache，用于下载种子到本地，仅仅提供下载的功能，hash_reader在需要种子文件时，可以先从本地取 cache_indexer，目前hash_reader取种子都是从torrage.com之类的种子缓存站点取，这些站点提供了种子列表，cache_indexer将这些列表导入数据库，hash_reader在请求种子文件前可以通过该数据库检查torrage.com上有无此种子，从而减少多余的http请求这些工具的代码都被放在dhtcrawler2中，可以查看对应的启动脚本来查看具体如何启动。OS/Database根据实际的测试效果来看，当收集的资源量过百万时（目前bt.cm录入近160万资源），4G内存的Windows平台，mongodb很容易就会挂掉。挂掉的原因全是1455，页面文件太小。有人建议不要在Windows下使用mongodb，Linux下我自己没做过测试。mongodb可以部署为集群形式(replica-set)，当初我想把http部分的查询放在一个只读的mongodb实例上，但因为建立集群时，要同步已有的10G数据库，而每次同步都以mongodb挂掉结束，遂放弃。在目前bt.cm的配置中，数据库torrent的锁比例（db lock）很容易上50%，这也让http在搜索时，经常出现搜索超时的情况。技术信息dhtcrawler最早的版本有很多问题，修复过的最大的一个问题是关于erlang定时器的，在DHT实现中，需要对每个节点每个peer做超时处理，在erlang中的做法直接是针对每个节点注册了一个定时器。这不是问题，问题在于定时器资源就像没有GC的内存资源一样，是会由于程序员的代码问题而出现资源泄漏。所以，dhtcrawler第一个版本在节点数配置在100以上的情况下，用不了多久就会内存耗尽，最终导致erlang虚拟机core dump。除了这个问题以外，dhtcrawler的资源收录速度也不是很快。这当然跟数据库和获取种子的速度有直接关系。尤其是获取种子，使用的是一些提供info-hash到种子映射的网站，通过HTTP请求来下载种子文件。我以为通过BT协议直接下载种子会快些，并且实时性也要高很多，因为这个种子可能未被这些缓存网站收录，但却可以直接向对方请求得到。为此，我还特地翻阅了相关协议，并且用erlang实现了（以后的文章我会讲到具体实现这个协议）。后来我怀疑get_peers的数量会不会比announce_peer多，但是理论上一般的客户端在get_peers之后都是announce_peer，但是如果get_peers查询的peers恰好不在线呢？这意味着很多资源虽然已经存在，只不过你恰好暂时请求不到。实际测试时，发现get_peers基本是announce_peer数量的10倍。将hash的获取方式做了调整后，dhtcrawler在几分钟以内以几乎每秒上百个新增种子的速度工作。然后，程序挂掉。从dhtcrawler到今天为止的dhtcrawler2，中间间隔了刚好1个月。我的所有业余时间全部扑在这个项目上，面临的问题一直都是程序的内存泄漏、资源收录的速度不够快，到后来又变为数据库压力过大。每一天我都以为我将会完成一个稳定版本，然后终于可以去干点别的事情，但总是干不完，目前完没完都还在观察。我始终明白在做优化前需要进行详尽的数据收集和分析，从而真正地优化到正确的点上，但也总是凭直觉和少量数据分析就开始尝试。这里谈谈遇到的一些问题。erlang call timeout最开始遇到erlang中gen_server:call出现timeout错误时，我还一直以为是进程死锁了。相关代码读来读去，实在觉得不可能发生死锁。后来发现，当erlang虚拟机压力上去后，例如内存太大，但没大到耗尽系统所有内存（耗进所有内存基本就core dump了），进程间的调用就会出现timeout。当然，内存占用过大可能只是表象。其进程过多，进程消息队列太长，也许才是导致出现timeout的根本原因。消息队列过长，也可能是由于发生了消息泄漏的缘故。消息泄漏我指的是这样一种情况，进程自己给自己发消息（当然是cast或info），这个消息被处理时又会发送相同的消息，正常情况下，gen_server处理了一个该消息，就会从消息队列里移除它，然后再发送相同的消息，这不会出问题。但是当程序逻辑出问题，每次处理该消息时，都会发生多余一个的同类消息，那消息队列自然就会一直增长。保持进程逻辑简单，以避免这种逻辑错误。erlang gb_trees我在不少的地方使用了gb_trees，dht_crawler里就可能出现gb_trees:get(xxx, nil)这种错误。乍一看，我以为我真的传入了一个nil值进去。然后我苦看代码，以为在某个地方我会把这个gb_trees对象改成了nil。但事情不是这样的，gb_tress使用一个tuple作为tree的节点，当某个节点没有子节点时，就会以nil表示。gb_trees:get(xxx, nil)类似的错误，实际指的是xxx没有在这个gb_trees中找到。erlang httpcdht_crawler通过http协议从torrage.com之类的缓存网站下载种子。最开始我为了尽量少依赖第三方库，使用的是erlang自带的httpc。后来发现程序有内存泄漏，google发现erlang自带的httpc早为人诟病，当然也有大神说在某个版本之后这个httpc已经很不错。为了省事，我直接换了ibrowse，替换之后正常很多。但是由于没有具体分析测试过，加之时间有点远了，我也记不太清细节。因为早期的http请求部分，没有做数量限制，也可能是由于我的使用导致的问题。某个版本后，我才将http部分严格地与hash处理部分区分开来。相较数据库操作而言，http请求部分慢了若干数量级。在hash_reader中将这两块分开，严格限制了提交给httpc的请求数，以获得稳定性。对于一个复杂的网络系统而言，分清哪些是耗时的哪些是不大耗时的，才可能获得性能的提升。对于hash_reader而言，处理一个hash的速度，虽然很大程度取决于数据库，但相较http请求，已经快很多。它在处理这些hash时，会将数据库已收录的资源和待下载的资源分离开，以尽快的速度处理已存在的，而将待下载的处理速度交给httpc的响应速度。erlang httpc sslibrowse处理https请求时，默认和erlang自带的httpc使用相同的SSL实现。这经常导致出现tls_connection进程挂掉的错误，具体原因不明。erlang调试首先合理的日志是任何系统调试的必备。我面临的大部分问题都是内存泄漏相关，所以依赖的erlang工具也是和内存相关的： 使用etop，可以检查内存占用多的进程、消息队列大的进程、CPU消耗多的进程等等： spawn(fun() -&gt; etop:start([{output, text}, {interval, 10}, {lines, 20}, {sort, msg_q }]) end). 使用erlang:system_info(allocated_areas).检查内存使用情况，其中会输出系统timer数量 使用erlang:process_info查看某个具体的进程，这个甚至会输出消息队列里的消息hash_writer/crawlercrawler本身仅收集hash，然后写入数据库，所以可以称crawler为hash_writer。这些hash里存在大量的重复。hash_reader从数据库里取出这些hash然后做处理。处理过程会首先判定该hash对应的资源是否被收录，没有收录就先通过http获取种子。在某个版本之后，crawler会简单地预先处理这些hash。它缓存一定数量的hash，接收到新hash时，就合并到hash缓存里，以保证缓存里没有重复的hash。这个重复率经过实际数据分析，大概是50%左右，即收到的100个请求里，有50个是重复的。这样的优化，不仅会降低hash数据库的压力，hash_reader处理的hash数量少了，也会对torrent数据库有很大提升。当然进一步的方案可以将crawler和hash_reader之间交互的这些hash直接放在内存中处理，省去中间数据库。但是由于mongodb大量使用虚拟内存的缘故（内存映射文件），经常导致服务器内存不够（4G），内存也就成了珍稀资源。当然这个方案还有个弊端是难以权衡hash缓存的管理。crawler收到hash是一个不稳定的过程，在某些时间点这些hash可能爆多，而hash_reader处理hash的速度也会不太稳定，受限于收到的hash类别（是新增资源还是已存在资源）、种子请求速度、是否有效等。当然，也可以限制缓存大小，以及对hash_reader/crawler处理速度建立关系来解决这些问题。但另一方面，这里的优化是否对目前的系统有提升，是否是目前系统面临的最大问题，却是需要考究的事情。cache indexerdht_crawler是从torrage.com等网站获取种子文件，这些网站看起来都是使用了相同的接口，其都有一个sync目录，里面存放了每天每个月索引的种子hash，例如 http://torrage.com/sync/。这个网站上是否有某个hash对应的种子，就可以从这些索引中检查。hash_reader在处理新资源时，请求种子的过程中发现大部分在这些服务器上都没有找到，也就是发起的很多http请求都是404回应，这不但降低了系统的处理能力、带宽，也降低了索引速度。所以我写了一个工具，先手工将sync目录下的所有文件下载到本地，然后通过这个工具 (cache indexer) 将这些索引文件里的hash全部导入数据库。在以后的运行过程中，该工具仅下载当天的索引文件，以更新数据库。 hash_reader 根据配置，会首先检查某个hash是否存在该数据库中，存在的hash才可能在torrage.com上下载得到。种子缓存hash_reader可以通过配置，将下载得到的种子保存在本地文件系统或数据库中。这可以建立自己的种子缓存，但保存在数据库中会对数据库造成压力，尤其在当前测试服务器硬件环境下；而保存为本地文件，又特别占用硬盘空间。基于BT协议的种子下载通过http从种子缓存里取种子文件，可能会没有直接从P2P网络里取更实时。目前还没来得及查看这些种子缓存网站的实现原理。但是通过BT协议获取种子会有点麻烦，因为dht_crawler是根据get_peer请求索引资源的，所以如果要通过BT协议取种子，那么这里还得去DHT网络里查询该种子，这个查询过程可能会较长，相比之下会没有http下载快。而如果通过announce_peer来索引新资源的话，其索引速度会大大降低，因为announce_peer请求比get_peer请求少很多，几乎10倍。所以，这里的方案可能会结合两者，新开一个服务，建立自己的种子缓存。中文分词mongodb的全文索引是不支持中文的。我在之前提到，为了支持搜索中文，我将字符串拆成了若干子串。这样的后果就是字符串索引会稍稍偏大，而且目前这一块的代码还特别简单，会将很多非文字字符也算在内。后来我加了个中文分词库，使用的是rmmseg-cpp。我将其C++部分抽离出来编译成erlang nif，这可以在我的github上找到。但是这个库拆分中文句子依赖于词库，而这个词库不太新，dhtcrawler爬到的大部分资源类型你们也懂，那些词汇拆出来的比率不太高，这会导致搜索出来的结果没你想的那么直白。当然更新词库应该是可以解决这个问题的，目前还没有时间顾这一块。总结一个老外对我说过，”i have 2 children to feed, so i will not do this only for fun”。你的大部分编程知识来源于网络，所以稍稍回馈一下不会让你丢了饭碗。我很穷，如果你能让我收获金钱和编程成就，还不会嫌我穿得太邋遢，that’s really kind of you。" }, { "title": "使用erlang实现P2P磁力搜索-实现", "url": "/posts/magnet-search-impl/", "categories": "erlang, network", "tags": "erlang, dht, p2p, magnet", "date": "2013-06-21 00:00:00 +0800", "snippet": "接上篇，本篇谈谈一些实现细节。这个爬虫程序主要的问题在于如何获取P2P网络中分享的资源，获取到资源后索引到数据库中，搜索就是自然而然的事情。DHTDHT网络本质上是一个用于查询的网络，其用于查询一个资源有哪些计算机正在下载。每个资源都有一个20字节长度的ID用于标示，称为infohash。当一个程序作为DHT节点加入这个网络时，就会有其他节点来向你查询，当你做出回应后，对方就会记录下你。对方还会询问其他节点，当对方开始下载这个infohash对应的资源时，他就会告诉所有曾经询问过的节点，包括你。这个时候就可以确定，这个infohash对应的资源在这个网络中是有效的。关于这个网络的工作原理，参看：P2P中DHT网络爬虫以及写了个磁力搜索的网页。获取到infohash后能做什么？关键点在于，我们现在使用的磁力链接(magnet url)，是和infohash对应起来的。也就是拿到infohash，就等于拿到一个磁力链接。但是这个爬虫还需要建立资源的信息，这些信息来源于种子文件。种子文件其实也是对应到一个资源，种子文件包含资源名、描述、文件列表、文件大小等信息。获取到infohash时，其实也获取到了对应的计算机地址，我们可以在这些计算机上下载到对应的种子文件。但是我为了简单，在获取到infohash后，从一些提供映射磁力链到种子文件服务的网站上直接下载了对应的种子。dhtcrawler里使用了以下网站：http://torrage.comhttps://zoink.ithttp://bt.box.n0808.com使用这些网站时，需提供磁力哈希（infohash可直接转换），构建特定的URL，发出HTTP请求即可。\tU1 = \"http://torrage.com/torrent/\" ++ MagHash ++ \".torrent\",\tU2 = \"https://zoink.it/torrent/\" ++ MagHash ++ \".torrent\",\tU3 = format_btbox_url(MagHash),format_btbox_url(MagHash) -&gt;\tH = lists:sublist(MagHash, 2),\tT = lists:nthtail(38, MagHash),\t\"http://bt.box.n0808.com/\" ++ H ++ \"/\" ++ T ++ \"/\" ++ MagHash ++ \".torrent\".但是，以一个节点的身份加入DHT网络，是无法获取大量查询的。在DHT网络中，每个节点都有一个ID。每个节点在查询信息时，仅询问离信息较近的节点。这里的信息除了infohash外还包含节点，即节点询问一个节点，这个节点在哪里。DHT的典型实现中（Kademlia），使用两个ID的xor操作来确定距离。既然距离的计算是基于ID的，为了尽可能获取整个DHT网络交换的信息，爬虫程序就可以建立尽可能多的DHT节点，让这些节点的ID均匀地分布在ID取值区间内，以这样的方式加入网络。在dhtcrawler中，我使用以下方式产生了N个大致均匀分布的ID：create_discrete_ids(1) -&gt;\t[dht_id:random()];create_discrete_ids(Count) -&gt;\tMax = dht_id:max(),\tPiece = Max div Count,\t[random:uniform(Piece) + Index * Piece || Index &lt;- lists:seq(0, Count - 1)].除了尽可能多地往DHT网络里部署节点之外，对单个节点而言，也有些注意事项。例如应尽可能快地将自己告诉尽可能多的节点，这可以在启动时进行大量的随机infohash的查询。随着查询过程的深入，该节点会与更多的节点打交道。因为DHT网络里的节点实际上是不稳定的，它今天在线，明天后天可能不在线，所以计算你的ID固定，哪些节点与你较近，本身就是个相对概念。节点在程序退出时，也最好将自己的路由信息（与自己交互的节点列表）保存起来，这样下次启动时就可以更快地加入网络。在dhtcrawler的实现中，每个节点每个一定时间，都会向网络中随机查询一个infohash，这个infohash是随机产生的。其查询目的不在于infohash，而在于告诉更多的节点，以及在其他节点上保持自己的活跃。handle_event(startup, {MyID}) -&gt;\ttimer:apply_interval(?QUERY_INTERVAL, ?MODULE, start_tell_more_nodes, [MyID]).start_tell_more_nodes(MyID) -&gt;\tspawn(?MODULE, tell_more_nodes, [MyID]).tell_more_nodes(MyID) -&gt;\t[search:get_peers(MyID, dht_id:random()) || _ &lt;- lists:seq(1, 3)].DHT节点的完整实现是比较繁琐的，涉及到查询以及繁杂的各种对象的超时（节点、桶、infohash），而超时的处理并不是粗暴地做删除操作。因为本身是基于UDP协议，你得对这些超时对象做进一步的查询才能正确地进一步做其他事情。而搜索也是个繁杂的事情，递归地查询节点，感觉上，你不一定离目标越来越近，由于被查询节点的不确定性（无法确定对方是否在玩弄你，或者本身对方就是个傻逼），你很可能接下来要查询的节点反而离目标变远了。在我第一次的DHT实现中，我使用了类似transmission里DHT实现的方法，不断无脑递归，当搜索有太久时间没得到响应后终止搜索。第二次实现时，我就使用了etorrent里的实现。这个搜索更聪明，它记录搜索过的节点，并且检查是否离目标越来越远。当远离目标时，就认为搜索是不太有效的，不太有效的搜索尝试几次就可以放弃。实际上，爬虫的实现并不需要完整地实现DHT节点的正常功能。爬虫作为一个DHT节点的唯一动机仅是获取网络里其他节点的查询。而要完成这个功能，你只需要装得像个正常人就行。这里不需要保存infohash对应的peer列表，面临每一次查询，你随便回复几个节点地址就可以。但是这里有个责任问题，如果整个DHT网络有2000个节点，而你这个爬虫就有1000个节点，那么你的随意回复，就可能导致对方根本找不到正确的信息，这样你依然得不到有效的资源。（可以利用这一点破坏DHT网络）DHT的实现没有使用第三方库。种子种子文件的格式同DHT网络消息格式一样，使用一种称为bencode的文本格式来编码。种子文件分为两类：单个文件和多个文件。文件的信息无非就是文件名、大小。文件名可能包含utf8编码的名字，为了后面处理的方便，dhtcrawler都会优先使用utf8编码。\t{ok, {dict, Info}} = dict:find(&lt;&lt;\"info\"&gt;&gt;, TD),\tcase type(Info) of\t\tsingle -&gt; {single, parse_single(Info)};\t\tmulti -&gt; {multi, parse_multi(Info)}\tend.parse_single(Info) -&gt;\tName = read_string(\"name\", Info),\t{ok, Length} = dict:find(&lt;&lt;\"length\"&gt;&gt;, Info),\t{Name, Length}.parse_multi(Info) -&gt;\tRoot = read_string(\"name\", Info),\t{ok, {list, Files}} = dict:find(&lt;&lt;\"files\"&gt;&gt;, Info),\tFileInfo = [parse_file_item(Item) || {dict, Item} &lt;- Files],\t{Root, FileInfo}.数据库我最开始在选用数据库时，为了不使用第三方库，打算使用erlang自带的mnesia。但是因为涉及到字符串匹配搜索，mnesia的查询语句在我看来太不友好，在经过一些资料查阅后就直接放弃了。然后我打算使用couchdb，因为它是erlang写的，而我正在用erlang写程序。第一次接触非关系型数据库，发现NoSQL数据库使用起来比SQL类的简单多了。但是在erlang里要使用couchdb实在太折腾了。我使用的客户端库是couchbeam。因为couchdb暴露的API都是基于HTTP协议的，其数据格式使用了json，所以couchbeam实际上就是对各种HTTP请求、回应和json的包装。但是它竟然使用了ibrowse这个第三方HTTP客户端库，而不是erlang自带的。ibrowse又使用了jiffy这个解析json的库。这个库更惨烈的是它的解析工作都是交给C语言写的动态库来完成，我还得编译那个C库。couchdb看起来不支持字符串查询，我得自己创建一个view，这个view里我通过翻阅了一些资料写了一个将每个doc的name拆分成若干次查询结果的map。这个map在处理每一次查询时，我都得动态更新之。couchdb是不支持局部更新的，这还不算大问题。然后很高兴，终于支持字符串查询了。这里的字符串查询都是基于字符串的子串查询。但是问题在于，太慢了。每一次在WEB端的查询，都直接导致erlang进程的call超时。要让couchdb支持字符串查询，要快速，当然是有解决方案的。但是这个时候我已经没有心思继续折腾，任何一个库、程序如果接口设计得如此不方便，那就可以考虑换一个其他的。我选择了mongodb。同样的基于文档的数据库。2.4版本还支持全文搜索。什么是全文搜索呢，这是一种基于单词的全文搜索方式。hello world我可以搜索hello，基于单词。mongodb会自动拆词。更关键更让人爽的是，要开启这个功能非常简单：设置启动参数、建立索引。没了。mongodb的erlang客户端库mongodb-erlang也只依赖一个bson-erlang库。然后我又埋头苦干，几个小时候我的这个爬虫程序就可以在浏览器端搜索关键字了。后来我发现，mongodb的全文搜索是不支持中文的。因为它还不知道中文该怎么拆词。恰好我有个同事做过中文拆词的研究，看起来涉及到很复杂的算法。直到这个时候，我他妈才醒悟，我为什么需要基于单词的搜索。我们大部分的搜索其实都是基于子字符串的搜索。于是，我将种子文件的名字拆分成了若干个子字符串，将这些子字符串以数组的形式作为种子文档的一个键值存储，而我依然还可以使用全文索引，因为全文索引会将整个字符串作为单词比较。实际上，基于一般的查询方式也是可以的。当然，索引还是得建立。使用mongodb时唯一让我很不爽的是mongodb-erlang这个客户端库的文档太欠缺。这还不算大问题，因为看看源码参数还是可以大概猜到用法。真正悲剧的是mongodb的有些查询功能它是不支持的。例如通过cursor来排序来限制数量。在cursor模块并没有对应的mongodb接口。最终我只好通过以下方式查询，我不明白batchsize，但它可以工作：search_announce_top(Conn, Count) -&gt;\tSel = {'$query', {}, '$orderby', {announce, -1}},\tList = mongo_do(Conn, fun() -&gt;\t\tCursor = mongo:find(?COLLNAME, Sel, [], 0, Count), \t\tmongo_cursor:rest(Cursor)\tend),\t[decode_torrent_item(Item) || Item &lt;- List].另一个悲剧的是，mongodb-erlang还不支持文档的局部更新，它的update接口直接要求传入整个文档。几经折腾，我可以通过runCommand来完成：inc_announce(Conn, Hash) when is_list(Hash) -&gt;\tCmd = {findAndModify, ?COLLNAME, query, {'_id', list_to_binary(Hash)}, \t\tupdate, {'$inc', {announce, 1}},\t\tnew, true},\tRet = mongo_do(Conn, fun() -&gt;\t\tmongo:command(Cmd)\tend).Unicode不知道在哪里我看到过erlang说自己其实是不需要支持unicode的，因为这门语言本身是通过list来模拟字符串。对于unicode而言，对应的list保存的本身就是整数值。但是为了方便处理，erlang还是提供了一些unicode操作的接口。因为我需要将种子的名字按字拆分，对于a中文这样的字符串而言，我需要拆分成以下结果：aa中a中文中中文文那么，在erlang中当我获取到一个字符串list时，我就需要知道哪几个整数合起来实际上对应着一个汉字。erlang里unicode模块里有几个函数可以将unicode字符串list对应的整数合起来，例如：[111, 222, 333]可能表示的是一个汉字，将其转换以下可得到[111222333]这样的形式。split(Str) when is_list(Str) -&gt;\tB = list_to_binary(Str), % 必须转换为binary\tcase unicode:characters_to_list(B) of\t\t{error, L, D} -&gt;\t\t\t{error, L, D};\t\t{incomplete, L, D} -&gt;\t\t\t{incomplete, L, D};\t\tUL -&gt;\t\t{ok, subsplit(UL)}\tend.subsplit([]) -&gt;\t[];subsplit(L) -&gt;\t[_|R] = L,\t{PreL, _} = lists:splitwith(fun(Ch) -&gt; not is_spliter(Ch) end, L),\t[unicode:characters_to_binary(lists:sublist(PreL, Len)) \t\t|| Len &lt;- lists:seq(1, length(PreL))] ++ subsplit(R).除了这里的拆字之外，URL的编码、数据库的存储都还好，没遇到问题。注意，以上针对数据库本身的吐槽，完全基于我不熟悉该数据库的情况下，不建议作为你工具选择的参考。erlang的稳定性都说可以用erlang来编写高容错的服务器程序。看看它的supervisor，监视子进程，自动重启子进程。天生的容错功能，就算你宕个几次，单个进程自动重启，整个程序看起来还稳健地在运行，多牛逼啊。再看看erlang的进程，轻量级的语言特性，就像OOP语言里的一个对象一样轻量。如果说使用OOP语言写程序得think in object，那用erlang你就得think in process，多牛逼多骇人啊。实际上，以我的经验来看，你还得以传统的思维去看待erlang的进程。一些多线程程序里的问题，在erlang的进程环境中依然存在，例如死锁。在erlang中，对于一些异步操作，你可以通过进程间的交互将这个操作包装成同步接口，例如ping的实现，可以等到对方回应之后再返回。被阻塞的进程反正很轻量，其包含的逻辑很单一。这不但是一种良好的包装，甚至可以说是一种erlang-style。但这很容易带来死锁。在最开始的时候我没有注意这个问题，当爬虫节点数上升的时候，网络数据复杂的时候，似乎就出现了死锁型宕机（进程互相等待太久，直接timeout）。另一个容易在多进程环境下出现的问题就是消息依赖的上下文改变问题。当投递一个消息到某个进程，到这个消息被处理之前，这段时间这个消息关联的逻辑运算所依赖的上下文环境改变了，例如某个ets元素不见了，在处理这个消息时，你还得以多线程编程的思维来编写代码。至于supervisor，这玩意你得端正态度。它不是用来包容你的傻逼错误的。当你写下傻逼代码导致进程频繁崩溃的时候，supervisor屁用没有。supervisor的唯一作用，仅仅是在一个确实本身可靠的系统，确实人品问题万分之一崩溃了，重启它。毕竟，一个重启频率的推荐值，是一个小时4次。" }, { "title": "使用erlang实现P2P磁力搜索(开源)", "url": "/posts/magnet-search/", "categories": "erlang, network", "tags": "erlang, dht, p2p, magnet", "date": "2013-06-20 00:00:00 +0800", "snippet": "接上回对DHT网络的研究，我用erlang克隆了一个磁力搜索引擎。我这个实现包含了完整的功能，DHT网络的加入、infohash的接收、种子的获取、资源信息的索引、搜索。如下图：在我的笔记本上，我开启了100个DHT节点，大致均匀地分布在DHT网络里，资源索引速度大概在1小时一万个左右（包含重复资源）。这个程序包含三大部分： DHT实现，kdht，https://github.com/kevinlynx/kdht 基于该DHT实现的搜索引擎，dhtcrawler，https://github.com/kevinlynx/dhtcrawler，该项目包含爬虫部分和一个简单的WEB端这两个项目总共包含大概2500行的erlang代码。其中，DHT实现部分将DHT网络的加入包装成一个库，爬虫部分在搜索种子时，暂时没有使用P2P里的种子下载方式，而是使用现成的磁力链转种子的网站服务，这样我只需要使用erlang自带的HTTP客户端就可以获取种子信息。爬虫在获取到种子信息后，将数据存储到mongodb里。WEB端我为了尽量少用第三方库，我只好使用erlang自带的HTTP服务器，因此网页内容的创建没有模板系统可用，只好通过字符串构建，编写起来不太方便。使用整个程序依赖了两个库：bson-erlang和mongodb-erlang，但下载依赖库的事都可以通过rebar解决，项目文件里我已经包含了rebar的执行程序。我仅在Windows7上测试过，但理论上在所有erlang支持的系统上都可以。 下载安装mongodb 进入mongodb bin目录启动mongodb，数据库目录保存在db下，需手动建立该目录 mongod --dbpath db --setParameter textSearchEnabled=true 下载erlang，我使用的是R16B版本 下载dhtcrawler，不需要单独下载kdht，待会下载依赖项的时候会自动下载 git clone git@github.com:kevinlynx/dhtcrawler.git cmd进入dhtcrawler目录，下载依赖项前需保证环境变量里有git，例如D:\\Program Files (x86)\\Git\\cmd，需注意不要将bash的目录加入进来，使用以下命令下载依赖项 rebar get-deps 编译 rebar compile 在dhtcrawler目录下，启动erlang erl -pa ebin 在erlang shell里运行爬虫，erlang语句以点号(.)作为结束 crawler_app:start(). erlang shell里运行HTTP服务器 crawler_http:start(). 浏览器里输入localhost:8000/index.html，这个时候还没有索引到资源，建议监视网络流量以观察爬虫程序是否正确工作爬虫程序启动时会读取priv/dhtcrawler.config配置文件，该文件里配置了DHT节点的UDP监听端口、节点数量、数据库地址等，可自行配置。接下来我会谈谈各部分的实现方法。" }, { "title": "使用ActionScript开发Ice Web客户端", "url": "/posts/ice-web-client/", "categories": "ICE, web", "tags": "ICE, web, Flash, JavaScript, ActionScript", "date": "2013-06-09 00:00:00 +0800", "snippet": "我们目前的项目服务器端使用了Ice来构建。Ice有一套自己的网络协议，客户端和服务器端可以基于此协议来交互。由于Ice使用Slice这种中间语言来描述服务器和客户端的交互接口，所以它可以做到极大限度地屏蔽网络协议这个细节。也就是说，我们只要借助Ice和Slice，我们可以轻松地编写网络程序。然后，我们的后端现在需要一个运行在Web浏览器上的客户端。要与Ice做交互，如果使用TCP协议的话，得保证是长连接的。但HTTP是短连接的。而另一方面，我们还需要选择一个Ice支持的和Web相关的语言来做这件事情。如果要在浏览器端直接与Ice服务建立连接，可供选择的语言/平台包括： Flash Silverlight因为我之前用erlang简单写了个Ice的客户端库，所以我对Ice底层协议有一定了解，可以不一定使用Ice支持的语言，所以HTML5其实也是个选择。此外，如果在浏览器端使用Applet，Java可能也是个选择。其实几个月前在这块的技术选择问题上我就做过简单的研究，当时确定的方案是使用Flash。但是，后来人员招聘上遇到了问题，看起来要招一个会ActionScript和前端页面技术的程序员来做我们这种项目，似乎大材小用，成本显高了。那么，考虑到团队里有现成的Java程序员，而且看起来招一个会用Java写网站的程序员简单又便宜，似乎是排除技术原因的最好选择。但是，如果不在浏览器端直接连接服务器来做交互，而是让Web服务器端来做中转的话，会面临不少问题： 浏览器端操作结果的获取问题，说白了就是非实时了，得用Ajax等等技术去模拟实时，代价就是不断轮训，也就是通常说的poll Web服务器端需要编写大量代码：对用户操作的映射，结果缓存等等如果能用Flash包装与服务器交互的部分，而把UI相关的东西留给HTML/JS/CSS去做，那是不是可行一点？如果只是用ActionScript编写与服务器端的交互逻辑代码，我就不需要花时间去系统学习ActionScript，甚至如何用Flash做界面，我甚至不用搞懂这些技术之间的关系。基本上看些Ice for ActionScript的例子代码，就可以完成这件事情。以下记录一些主要的过程/方法：ActionScript程序的开发开发一个嵌入到网页中的FLASH，只需要Flex SDK。SDK里自带了一些编译器相关工具。我不打算使用IDE，因为看起来IDE更复杂。简单的google之后，基本就可以构建出一个Flash文件： 构建基本的程序需要一个mxml文件，这个文件里主要用来捕获Flash在页面上初始化完成这个事件，以初始化内部逻辑 编写ActionScript源码，看起来其文件、类的组织方式很像Java 使用Flex SDK中的mxmlc程序来编译，生成swf文件，例如： mxmlc myflexapp.mxml -library-path+=xxx.swc 嵌入到网页中，简单的做法可以借助swfobject.js这个库，嵌入的方式： \t&lt;script type=\"text/javascript\" src=\"swfobject.js\"&gt;&lt;/script&gt; \t&lt;script type=\"text/javascript\"&gt;\t \tvar flashvars = {};\t \tvar params = {}; params.play = \"true\";\t \tparams.quality = \"high\";\t \tparams.bgcolor = \"white\";\t \tparams.allowscriptaccess = \"always\";\t \tparams.allowfullscreen = \"true\";\t \tvar attributes = {};\t \tattributes.id = \"asclient\";\t \tattributes.name = \"asclient\";\t \tattributes.align = \"middle\";\t \tswfobject.embedSWF(\"asclient.swf\", \"flashContent\", \"1\", \"1\",\t \t\t\"0\", \"\", \t \t\tflashvars, params, attributes);\t \tswfobject.createCSS(\"#flashContent\", \"display:none;\");\t&lt;/script&gt;自然，页面中需加入flashContent这个div： \t&lt;div id=\"flashContent\"&gt; \t\t&lt;p&gt;no flash&lt;/p&gt; \t&lt;/div&gt;我的mxml文件也很简单：&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;s:Application xmlns:fx=\"http://ns.adobe.com/mxml/2009\" xmlns:s=\"library://ns.adobe.com/flex/spark\" xmlns:mx=\"library://ns.adobe.com/flex/mx\" applicationComplete=\"doApplicationComplete()\" &gt; &lt;fx:Script&gt; &lt;![CDATA[ import ASClient.Coordinator; import flash.external.ExternalInterface; private var _coordinator:Coordinator; public function doApplicationComplete():void { trace(\"doApplicationComplete\"); _coordinator = new Coordinator(); _coordinator.reg_methods(); ExternalInterface.call(\"as_ready\"); } ]]&gt; &lt;/fx:Script&gt;&lt;/s:Application&gt;ActionScript日志我通过日志来调试ActionScript代码。最简单的方式就是通过trace函数来输出日志。要成功输出日志包含以下步骤： 给浏览器安装调试版本的Flash Player 日志是输出到用户目录下的，并且需要手动创建日志目录(Administrator替换为用户名)： C:\\Users\\Administrator\\AppData\\Roaming\\Macromedia\\Flash Player\\Logs 用户目录下新建配置文件mm.cfg： AS3StaticProfile=0 AS3Verbose=0 TraceOutputFileEnable=1 TraceOutputBuffered=0 ErrorReportingEnable=1 AS3Trace=0 编译DEBUG版本的Flash文件，可以修改flex sdk下的flex-config.xml文件，里面增加debug=true配置即可在开发过程中需要注意浏览器缓存问题，当编译出新的Flash文件后，浏览器即使页面刷新也可能使用的是缓存里的Flash。当然，最重要的，是通过浏览器来访问这个包含了Flash的网页，Web服务器随意。Flash Policy文件在Flash的某个版本后，Flash中如果要向外建立socket连接，是首先要取得目标主机返回的policy文件的。也就是在建立连接前，Flash底层会先向目标主机询问得到一个描述访问权限的文件。简单来说，目标主机需要在843端口上建立TCP监听，一旦有网络连接，就发送以下内容，内容后需添加0x00用于标示结束。（当然，具体细节还挺多，自行google）&lt;cross-domain-policy&gt; &lt;allow-access-from domain=\"*\" to-ports=\"*\" /&gt;&lt;/cross-domain-policy&gt;最开始我使用的是朋友给的现成的Policy服务，虽然我写的Flash可以成功连接我的Ice服务，但始终要等待2秒以上的时间。google Flash Policy相关内容，可以发现确实存在一个延时，但那是因为目标主机没有在843端口服务。后来我自己用erlang写了个Policy服务，延时就没有了。猜测可能是他的Policy服务没有添加0x00作为结束导致。ActionScript与JavaScript的交互既然我使用ActionScript来包装与服务器的交互，那么JavaScript就必然需要和ActionScript通信。这个通信过程也就是在JavaScript中调用ActionScript中的函数，反过来亦然。这个过程很简单：在JavaScript中调用ActionScript函数：首先是ActionScript需要注册哪些函数可以被调用：ExternalInterface.addCallback(\"service_loadall\", loadAll);通过ExternalInterface.addCallback注册的函数，其实是个closure，所以在类中注册自己的成员函数都可以（因为成员函数会使用this，形成了一个closure）。然后在JavaScript中调用： function asObject() { // asclient是嵌入Flash时填入的name和(或?)id return window.document.asclient; }\tvar as = asObject();\tas.service_loadall();在ActionScript中调用JavaScript中调用则更简单，一句话：ExternalInterface.call(\"service_load_done\", args);至于在两者之间的函数参数传递，其类型都可以自动映射。但因为我的应用里数据较为复杂，我就将数据转换为JSON格式，在JavaScript这边操作较为简单。页面切换这里我们需要的Web前端页面，更像是一个管理系统，所以页面切换是很有可能的。问题在于，当出现页面跳转时，Flash对象会重新初始化，新的页面无法使用前一个页面建立好的网络连接（或者能？）。为了解决这个问题，服务器当然可以设计一种重登录机制，方便客户端以一种特殊的方式进入系统，绕过正常的登录环节。但是我们使用了Glacier2这个网关，在这个网关上有针对连接的超时管理，这样反复建立新的连接对资源太浪费了。综上，我想只能通过前端去规避这个问题。例如，前端开发人员依然可以分开设计很多页面，页面里也可以使用正常的链接。我们编写一些JavaScript代码，将页面里的链接替换成对应的JavaScript代码，动态载入新的页面内容，然后对页面内的部分内容进行替换，从而尽可能让页面设计人员编写正常的网页，同时也解决页面切换问题。这是个蹩脚的方法，但在我有限的前端知识体系下，似乎也只能这样干了。" }, { "title": "erlang编程技巧若干", "url": "/posts/erlang-code-snippets/", "categories": "tips, erlang", "tags": "tips, erlang", "date": "2013-06-03 21:53:00 +0800", "snippet": "guardguard可以以逗号或者分号分隔，以逗号分隔表示最终的结果为各个guard的and结果，以分号则是只要任意一个guard为true则最终结果为true。guard(X, Y) when not(X&gt;Y), is_atom(X) -&gt; X + Y.guard在list comprehension中可以筛选元素：NewNodes = [Node || Node &lt;- AllNodes, not gb_sets:is_member(Node, NewQueried)],guard中不能使用自定义函数，因为guard应该保证没有副作用，但自定义函数无法保证这一点，所以erlang禁止在guard中使用自定义函数。list comprehensionlist comprehension是一个非常有用的语法特性，它可以用于构造一个新的list，可以用于将一种list映射到另一种list，可以筛选list元素。只要是跟list相关的操作，优先考虑用list comprehension来实现，将大大减少代码量。记住list comprehension的语法：[Expression || Generators, Guards, Generators, ...]timer一定时间后向进程发送消息：erlang:send_after(token_lifetime(), self(), renew_token),一段时间后执行某个函数：{ok, TRef} = timer:apply_interval(Interval, ?MODULE, announce, [self()]),gb_trees/gb_setpattern matchpattern match有太多作用了：pattern match in casecase中判定多个值，比其使用逻辑运算符简洁多了：A = 1, B = 2,case {A, B} of {_C, _C} -&gt; true; {_, _} -&gt; falseendpattern match to check data typepattern match可以用于检测变量的类型，可以用于检测函数的返回值，就像C/C++中的assert一样，可以用于尽早检测出异常状态：ping({_, _, _, _} = IP, Port) -&gt; ok.{ok, Ret} = call().list操作添加元素添加元素进list有很多方式：[2]++[3, 4].[2|[3,4]].foldl/foldr用于遍历list计算出一个“累加值“。lists:foldl(fun(X, Sum) -&gt; X + Sum end, 0, [1,2,3,4,5]).也就是遍历一个list，将每个元素传递给fun，将fun的返回值继续传递给下一个元素。zip将两个list一一对应构造出一个tuple，作为新的list里的元素。lists:zip([1, 2, 3], [4, 5, 6]). =&gt; [{1,4},{2,5},{3,6}]数字进制16##FF，表示16进制数字0xFF，通用格式为scale##num，即scale进制下的num。" }, { "title": "P2P中DHT网络爬虫", "url": "/posts/crawl-dht/", "categories": "network", "tags": "dht, p2p", "date": "2013-05-19 00:00:00 +0800", "snippet": "DHT网络爬虫基于DHT网络构建了一个P2P资源搜索引擎。这个搜索引擎不但可以用于构建DHT网络中活跃的资源索引（活跃的资源意味着该网络中肯定有人至少持有该资源的部分数据），还可以分析出该网络中的热门分享资源。小虾不久前发布了一个这样的搜索引擎：磁力搜索。他也写博客对此稍作了介绍：写了个磁力搜索的网页 － 收录最近热门分享的资源。网络上其实也有其他人做了类似的应用：DHT monitoring，Crawling Bittorrent DHT但是他的这篇文章仅介绍了DHT网络的大致工作原理，并且这个爬虫的具体工作原理也没有提到。对此我查阅了些文章及代码，虽然从原理上梳理出了整个实现方案，但很多细节还是不甚清楚。所以本文仅作概要介绍。DHT/Magnet/Torrent在P2P网络中，要通过种子文件下载一个资源，需要知道整个P2P网络中有哪些计算机正在下载/上传该资源。这里将这些提供某个资源下载的计算机定义为peer。传统的P2P网络中，存在一些tracker服务器，这些服务器的作用主要用于跟踪某个资源有哪些关联的peer。下载这个资源当然得首先取得这些peer。DHT的出现用于解决当tracker服务器不可用时，P2P客户端依然可以取得某个资源的peer。DHT解决这个问题，是因为它将原来tracker上的资源peer信息分散到了整个网络中。这里将实现了DHT协议的计算机定义为节点(node)。通常一个P2P客户端程序既是peer也是节点。DHT网络有多种实现算法，例如Kademlia。当某个P2P客户端通过种子文件下载资源时，如果没有tracker服务器，它就会向DHT网络查询这个资源对应的peer列表。资源的标识在DHT网络中称为infohash，是一个20字节长的字符串，一般通过sha1算法获得，也就是一个类似UUID的东西。实际上，种子文件本身就对应着一个infohash，这个infohash是通过种子文件的文件描述信息动态计算得到。一个种子文件包含了对应资源的描述信息，例如文件名、文件大小等。Magnet，这里指的是磁力链接，它是一个类似URL的字符串地址。P2P软件通过磁力链接，会下载到一个种子文件，然后根据该种子文件继续真实资源的下载。磁力链接中包含的最重要的信息就是infohash。这个infohash一般为40字节或32字节，它其实只是资源infohash（20字节）的一种编码形式。KademliaKademlia是DHT网络的一种实现。网络上关于这个算法的文章，主要是围绕整个DHT网络的实现原理进行论述。个人觉得这些文章很蛋疼，基本上读了之后对于要如何去实现一个DHT客户端还是没有概念。这里主要可参考P2P中DHT网络介绍，以及BitTorrent网站上的DHT协议描述Kad的主要目的是用于查询某个资源对应的peer列表，而这个peer列表实际上是分散在整个网络中。网络中节点数量很大，如果要获得peer列表，最简单的做法无非就是依次询问网络中的每个节点。这当然不可行。所以在Kad算法中，设立了一个路由表。每一个节点都有一份路由表。这个是按照节点之间的距离关系构建出来的。节点之间的距离当然也有特定的算法定义，在Kad中通过对两个节点的ID进行异或操作得到。节点的ID和infohash通过相同算法构建，都是20字节长度。节点和infohash之间也有距离关系，实际上表示的是节点和资源的距离关系。有了这个路由表之后，再通过一个基于距离关系的查找算法，就可以实现不用挨个遍历就找到特定的节点。而查找资源peer这个操作，正是基于节点查找这个过程。路由表的实现，按我的理解，有点类似一般的hash表结构。在这个表中有160个桶，称为K桶，这个桶的数量在实现上可以动态增长。每个桶保存有限个元素，例如K取值为8，指的就是这个桶最多保存8个元素。每个元素就是一个节点，节点包含节点ID、地址信息以及peer信息。这些桶可以通过距离值索引得到，即距离值会经过一个hash算法，使其值落到桶的索引范围内。要加入一个DHT网络，需要首先知道这个网络中的任意一个节点。如何获得这个节点？在一些开源的P2P软件中，会提供一些节点地址，例如transmission中提供的dht.transmissionbt.com:6881。协议Kad定义了节点之间的交互协议。这些协议支撑了整个DHT网络里信息分布式存储的实现。这些协议都是使用UDP来传送。其协议格式使用一种称为bencode的编码方式来编码协议数据。bencode是一种文本格式的编码，它还用于种子文件内的信息编码。Kad协议具体格式可参考BitTorrent的定义：[DHT Protocol]((http://www.bittorrent.org/beps/bep_0005.html)。这些协议包括4种请求：ping，find_node，get_peer，announce_peer。在有些文档中这些请求的名字会有不同，例如announce_peer又被称为store，get_peer被称为find_value。这4种请求中，都会有对应的回应消息。其中最重要的消息是get_peer，其目的在于在网络中查找某个资源对应的peer列表。值得一提的是，所有这些请求，包括各种回应，都可以用于处理该消息的节点构建路由表。因为路由表本质就是存储网络中的节点信息。ping用于确定某个节点是否在线。这个请求主要用于辅助路由表的更新。find_node用于查找某个节点，以获得其地址信息。当某个节点接收到该请求后，如果目标节点不在自己的路由表里，那么就返回离目标节点较近的K个节点。这个消息可用于节点启动时构建路由表。通过find_node方式构建路由表，其实现方式为向DHT网络查询自己。那么，接收该查询的节点就会一直返回其他节点了列表，查询者递归查询，直到无法查询为止。那么，什么时候无法继续查询呢？这一点我也不太清楚。每一次查询得到的都是离目标节点更接近的节点集，那么理论上经过若干次递归查询后，就无法找到离目标节点更近的节点了，因为最近的节点是自己，但自己还未完全加入网络。这意味着最后所有节点都会返回空的节点集合，这样就算查询结束？实际上，通过find_node来构建路由表，以及顺带加入DHT网络，这种方式什么时候停止在我看来并不重要。路由表的构建并不需要在启动时构建完成，在以后与其他节点的交互过程中，路由表本身就会慢慢地得到构建。在初始阶段尽可能地通过find_node去与其他节点交互，最大的好处无非就是尽早地让网络中的其他节点认识自己。get_peer通过资源的infohash获得资源对应的peer列表。当查询者获得资源的peer列表后，它就可以通过这些peer进行资源下载了。收到该请求的节点会在自己的路由表中查找该infohash，如果有收录，就返回对应的peer列表。如果没有，则返回离该infohash较近的若干个节点。查询者若收到的是节点列表，那么就会递归查找。这个过程同find_node一样。值得注意的是，get_peer的回应消息里会携带一个token，该token会用于稍后的announce_peer请求。announce_peer该请求主要目的在于通知，通知其他节点自己开始下载某个资源。这个消息用于构建网络中资源的peer列表。当一个已经加入DHT网络的P2P客户端通过种子文件开始下载资源时，首先在网络中查询该资源的peer列表，这个过程通过get_peer完成。当某个节点从get_peer返回peer时，查询者开始下载，然后通过announce_peer告诉返回这个peer的节点。announce_peer中会携带get_peer回应消息里的token。关于这一点，我有一个疑问是，在P2P中DHT网络介绍文档中提到： (announce_peer)同时会把自己的peer信息发送给先前的告诉者和自己K桶中的k个最近的节点存储该peer-list信息不管这里提到的K的最近的节点是离自己最近，还是离资源infohash最近的节点，因为处理announce_peer消息时，有一个token的验证过程。但是这K个节点中，并没有在之前创建对应的token。我通过transmission中的DHT实现做了个数据收集，可以证明的是，announce_peer消息是不仅仅会发给get_peer的回应者的。DHT爬虫DHT爬虫是一个遵循Kad协议的假节点程序。具体可以参考小虾发布的那个网站应用：磁力搜索。这个爬虫的实现方式，主要包含以下内容： 通过其他节点的announce_peer发来的infohash确认网络中有某个资源可被下载 通过从网络中获取这个资源的种子文件，来获得该资源的描述通过累计收集得到的资源信息，就可以提供一个资源搜索引擎，或者构建资源统计信息。以下进一步描述实现细节。整个爬虫的实现依赖了一个很重要的信息，那就是资源的infohash实际上就是一个磁力链接（当然需要包装一下数据）。这意味着一旦我们获得了一个infohash，我们就等于获得了一个种子。获得资源通知当爬虫程序加入DHT网络后，它总会收到其他节点发来的announce_peer消息。announce_peer消息与get_peer消息里都带了资源的infohash，但是get_peer里的infohash对应的资源在该网络中不一定存在，即该资源没有任何可用peer。而announce_peer则表示已经确认了该网络中有节点正在下载该资源，也即该资源的数据确实存在该网络中。所以，爬虫程序需要尽最大努力地获取其他节点发来的announce_peer消息。如果announce_peer消息会发送给离消息发送节点较近的节点，那么，一方面，爬虫程序应该将自己告诉网络中尽可能多的节点。这可以通过一次完整的find_node操作实现。另一方面，爬虫程序内部实现可以部署多个DHT节点，总之目的在于尽可能地让爬虫程序称为其他节点的较近者。当收集到infohash之后，爬虫程序还需要通过该infohash获得对应资源的描述信息。获取资源信息获得资源描述信息，其实就是通过infohash获得对应的种子文件。这需要实现P2P协议里的文件分享协议。种子文件的获取其实就是一个文件下载过程，下载到种子文件之后，就可以获取到资源描述。这个过程一种简单的方法，就是从infohash构建出一个磁力链接，然后交给一个支持磁力下载的程序下载种子。从infohash构建出磁力链接非常简单，只需要将infohash编码成磁力链接的xt字段即可，构建实现可以从transmission源码里找到：/* 这个算法其实和printf(\"%02x\", sha1[i])一样 */void tr_sha1_to_hex (char *out, const unsigned char *sha1){ int i; static const char hex[] = \"0123456789abcdef\"; for (i=0; i&lt;20; ++i) { const unsigned int val = *sha1++; *out++ = hex[val &gt;&gt; 4]; *out++ = hex[val &amp; 0xf]; } *out = '\\0';}void appendMagnet(FILE *fp, const unsigned char *info_hash) { char out[48]; tr_sha1_to_hex(out, info_hash); fprintf(fp, \"magnet:?xt=urn:btih:%s\", out);}现在你就可以做一个实验，在transmission的DHT实现中，在announce_peer消息的处理代码中，将收到的infohash通过上面的appendMagnet转换为磁力链接输出到日志文件里。然后，可以通过支持磁力链接的程序（例如QQ旋风）直接下载。有趣的是，当QQ旋风开始下载该磁力链接对应的种子文件时，你自己的测试程序能收到QQ旋风程序发出的announce_peer消息。当然，你得想办法让这个测试程序尽可能地让其他节点知道你，这可以通过很多方式实现。总结最终的DHT爬虫除了需要实现DHT协议之外，还需要实现P2P文件下载协议，甚至包括一个种子文件解析模块。看起来包含不小的工作量。而如果要包装为一个资源搜索引擎，还会涉及到资源存储以及搜索，更别说前端呈现了。这个时候，如果你使用的语言不包含这些工具库，那实在是太悲剧了。没错，我就没找到一个erlang DHT库（倒是有erlang实现的BT客户端，懒得去剥了）。UPDATE通过详细阅读transmission里的DHT实现，一些之前的疑惑随之解开。announce_peer会发给哪些节点在一次对infohash的查询过程中，所有对本节点发出的get_peer作出回应的节点（不论这个回应节点回应的是nodes还是peers），当本节点取得peer信息时，就会对所有这些节点发出announce_peer。get_peer的回应消息里，不论是peer还是node，都会携带一个token，这样在将来收到对方的announce_peer时，就可以验证该token。节点和bucket状态在本地的路由表中，保存的node是有状态之分的。状态分为三种：good/dubious/bad。good节点基本可以断定该节点是一个在线的并且可以正常回应消息的节点；而bad节点则是可确定的无效节点，通常会尽快从路由表中移除；而dubious则是介于good和bad节点之间，表示可能有问题的节点，需要进一步发送例如ping消息来确认其状态。路由表中应该尽可能保证保存的是good节点，对查询消息的回应里也需携带好的节点。bucket也是有状态的，当一个bucket中的所有节点在一定时间之内都没有任何活动的时候，该bucket则应该考虑进行状态的确认，确认方式可以随机选择该bucket中的节点进行find_node操作（这也是find_node除了用于启动之外的唯一作用，但具体实现不见得使用这种方式）。没有消息来往的bucket则应该考虑移除。DHT中几乎所有操作都会涉及到bucket的索引，如果索引到一个所有节点都有问题的bucket，那么该操作可能就无法完成。search在何时停止首先，某次发起的search，无论是对node还是对peer，都可能导致进一步产生若干个search。这些search都是基于transaction id来标识的。由一次search导致产生的所有子search都拥有相同的transaction id，以使得在该search成功或失败时可以通过该transaction id来删除对应的所有search。transaction id也就是DHT中每个消息消息头”t”的值。但是search何时停止？transmission中是通过超时机制来停止。在search过程中，如果长时间没有收到跟该search关联的节点发来的回应消息，那么就撤销该search，表示搜索失败。参考资料 DHT Protocol P2P中DHT网络介绍 Torrent文件结构解析 BitDHT源码 Transmission DHT源码 bencode magnet Crawling Bittorrent DHT" }, { "title": "erlang使用感受", "url": "/posts/thought-about-erlang/", "categories": "erlang", "tags": "erlang, ICE", "date": "2013-05-08 00:00:00 +0800", "snippet": "用erlang也算写了些代码了，主要包括使用RabbitMQ的练习，以及最近写的kl_tserver和icerl。其中icerl是一个实现了Ice的erlang库。erlang的书较少，我主要读过&lt;Programming Erlang&gt;和&lt;Erlang/OTP in Action&gt;。其实erlang本身就语言来说的话比较简单，同ruby一样，类似这种本身目标是应用于实际软件项目的语言都比较简单，对应的语法书很快可以翻完。这里我仅谈谈自己在编写erlang代码过程中的一些感受。语法erlang语法很简单，接触过函数式语言的程序员上手会很快。它没有类似common lisp里宏这种较复杂的语言特性。其语法元素很紧凑，不存在一些用处不大的特性。在这之前，我学习过ruby和common lisp。ruby代码写的比common lisp多。但是在学习erlang的过程中我的脑海里却不断出现common lisp里的语法特性。这大概是因为common lisp的语法相对ruby来说，更接近erlang。编程模式erlang不是一个面向对象的语言，它也不同common lisp提供多种编程模式。它的代码就是靠一个个函数组织出来的。面向对象语言在语法上有一点让我很爽的是，其函数调用更自然。erlang的接口调用就像C语言里接口的调用一样：func(Obj, args)Obj-&gt;func(args)即需要在函数第一个参数传递操作对象。但是面向对象语言也会带来一些语法的复杂性。如果一门语言可以用很少的语法元素表达很多信息，那么我觉得这门语言就是门优秀的语言。表达式/语句erlang里没有语句，全部是表达式，意思是所有语法元素都是有返回值的。这实在太好了，全世界都有返回值可以让代码写起来简单多了： Flag = case func() of 1 -&gt; true; 0 -&gt; false end, 命名我之所以不想写一行python代码的很大一部分原因在于这门语言居然要求我必须使用代码缩进来编程，真是不敢相信。erlang里虽然没有此规定，却也有不同的语法元素有大小写的限定。变量首字母必须大写，atom必须以小写字母开头，更霸气的是模块命名必须和文件名相同。变量erlang里的变量是不可更改的。实际上给一个变量赋值，严格来说应该叫bound，即绑定。这个特性完全就是函数式语言里的特性。其带来的好处就像函数式语言宣扬的一样，这会使得代码没有副作用(side effect)。因为程序里的所有函数不论怎样调用，其程序状态都不会改变，因为变量无法被改变。变量不可更改，直接意味着全局变量没有存在的意义，也就意味着不论你的系统是多么复杂地被构建出来，当系统崩溃时，其崩溃所在位置的上下文就足够找到问题。但是变量不可改变也会带来一些代码编写上的不便。我想这大概是编程思维的转变问题。erlang的语法特性会强迫人编写非常短小的函数，你大概不愿意看到你的函数实现里出现Var1/Var2/Var3这样的变量，而实际上这样的命名在命令式语言里其实指的是同一个变量，只不过其值不同而已。但是我们的程序总是应该有状态的。在erlang里我们通过不断创建新的变量来存储这个状态。我们需要通过将这个状态随着我们的程序流程不断地通过函数参数和返回值传递下去。atomatom这个语法特性本身没问题，它就同lisp里的atom一样，没什么意义，就是一个名字。它主要用在增加代码的可读性上。但是这个atom带来的好处，直接导致erlang不去内置诸如true/false这种关键字。erlang使用true/false这两个atom来作为boolean operator的返回值。但erlang里严格来说是没有布尔类型的。这其实没什么，糟糕的是，对于一些较常见的函数返回值，例如true/false，erlang程序员之间就得做约定。要表示一个函数执行失败了，我可以返回false、null、failed、error、nil，甚至what_the_fuck，这一度让我迷惘。list/tupleerlang里的list当然没有lisp里的list牛逼，别人整个世界就是由list构成的。在一段时间里，我一直以为list里只能保存相同类型的元素，而tuple才是用于保存不同类型元素的容器。直到有一天我发现tuple的操作不能满足我的需求了，我才发现list居然是可以保存不同类型的。list相对于tuple而言，更厉害的地方就在于头匹配，意思是可以通过匹配来拆分list的头和剩余部分。匹配(match)erlang的匹配机制是个好东西。这个东西贯穿了整个语言。在我理解看来，匹配机制减少了很多判断代码。它试图用一个期望的类型去匹配另一个东西，如果这个东西出了错，它就无法完成这个匹配。无法完成匹配就导致程序断掉。匹配还有个方便的地方在于可以很方便地取出record里的成员，或者tuple和list的某个部分，这其实增强了其他语法元素的能力。循环erlang里没有循环语法元素，这真是太好了。函数式语言里为什么要有循环语法呢？common lisp干毛要加上那些复杂的循环（宏），每次我遇到需要写循环的场景时，我都诚惶诚恐，最后还是用递归来解决。同样，在erlang里我们也是用函数递归来解决循环问题。甚至，我们还有list comprehension。当我写C++代码时，我很不情愿用循环去写那些容器遍历代码，幸运的是在C++11里通过lambda和STL里那些算法我终于不用再写这样的循环代码了。if/case/guarderlang里有条件判定语法if，甚至还有类似C语言里的switch…case。这个我一时半会还不敢评价，好像haskell里也保留了if。erlang里同haskell一样有guard的概念，这其实是一种变相的条件判断，只不过其使用场景不一样。进程并发性支持属于erlang的最大亮点。erlang里的进程概念非常简单，基于消息机制，程序员从来不需要担心同步问题。每个进程都有一个mailbox，用于缓存发送到此进程的消息。erlang提供内置的语法元素来发送和接收消息。erlang甚至提供分布式支持，更酷的是你往网络上的其他进程发送消息，其语法和往本地进程发送是一样的。模块加载如果我写了一个erlang库，该如何在另一个erlang程序里加载这个库？这个问题一度让我迷惘。erlang里貌似有对库打包的功能(.ez?)，按理说应该提供一种整个库加载的方式，然后可以通过手动调用函数或者指定代码依赖项来加载。结果不是这样。erlang不是按整个库来加载的，因为也没有方式去描述一个库（应该有第三方的）。当我们调用某个模块里的函数时，erlang会自动从某个目录列表里去搜索对应的beam文件。所以，可以通过在启动erlang添加这个模块文件所在目录来实现加载，这还是自动的。当然，也可以在erlang shell里通过函数添加这个目录。OTP使用erlang来编写程序，最大的优势可能就是其OTP了。OTP基本上就是一些随erlang一起发布的库。这些库中最重要的一个概念是behaviour。behaviour其实就是提供了一种编程框架，应用层提供各种回调函数给这个框架，从而获得一个健壮的并发程序。application behaviourapplication behaviour用于组织一个erlang程序，通过一个配置文件，和提供若干回调，就可以让我们编写的erlang程序以一种统一的方式启动。我之前写的都是erlang库，并不需要启动，而是提供给应用层使用，所以也没使用该behaviour。gen_server behaviour这个behaviour应该是使用频率很高的。它封装了进程使用的细节，本质上也就是将主动收取消息改成了自动收取，收取后再回调给你的模块。supervisor behaviour这个behaviour看起来很厉害，通过对它进行一些配置，你可以把你的并发程序里的所有进程建立成树状结构。这个结构的牛逼之处在于，当某个进程挂掉之后，通过supervisor可以自动重新启动这个挂掉的进程，当然重启没这么简单，它提供多种重启规则，以让整个系统确实通过重启变成正常状态。这实在太牛逼了，这意味着你的服务器可以7x24小时地运行了，就算有问题你也可以立刻获得一个重写工作的系统。热更新代码热更新对于一个动态语言而言其实根本算不上什么优点，基本上动态语言都能做到这一点。但是把热更新这个功能加到一个用于开发并发程序的语言里，那就很牛逼了。你再一次可以确保你的服务器7x24小时不停机维护。gen_tcp最开始我以为erlang将网络部分封装得已经认不出有socket这个概念了。至少，你也得有一个牛逼的网络库吧。结果发现依然还是socket那一套。然后我很失望。直到后来，发现使用一些behaviour，加上调整gen_tcp的一些option，居然可以以很少的代码写出一个维护大量连接的TCP服务器。是啊，erlang天生就是并发的，在传统的网络模型中，我们会觉得使用one-thread-per-connection虽然简单却不是可行的，因为thread是OS资源，太昂贵。但是在erlang里，one-process-per-connection却是再自然不过的事情。你要是写个erlang程序里面却只有一个process你都不好意思告诉别人你写的是erlang。process是高效的（对我们这种二流程序员而言），它就像C++里一个很普通的对象一样。在使用gen_tcp的过程中我发现一个问题，不管我使用哪一种模型，我竟然找不到一种温柔的关闭方式。我查看了几个tutorial，这些混蛋竟然没有一个人提到如何去正常关闭一个erlang TCP服务器。后来，我没有办法，只好使用API强制关闭服务器进程。Story其实，我和erlang之间是有故事的。我并不是这个月开始才接触erlang。早在2009年夏天的时候我就学习过这门语言。那时候我还没接触过任何函数式语言，那时候lua里的闭包都让我觉得新奇。然后无意间，我莫名其妙地接触了haskell（&lt;Real World Haskell&gt;），在我决定开始写点什么haskell练习时，我发现我无从下手，最后，Monads把我吓哭了。haskell实在太可怕了。紧接着我怀揣着对函数式语言的浓烈好奇心看到了erlang。当我看到了concurrent programming的章节时，在一个燥热难耐的下午我的领导找到了我，同我探讨起erlang对我们的网游服务器有什么好处。然后，我结束我了的erlang之旅。时隔四年，这种小众语言，居然进入了中国程序员的视野，并被用于开发网页游戏服务器。时代在进步，我们总是被甩在后面。" }, { "title": "erlang和RabbitMQ学习总结", "url": "/posts/rabbitmq-erlang/", "categories": "erlang", "tags": "erlang, rabbitmq", "date": "2013-04-11 00:00:00 +0800", "snippet": "AMQP和RabbitMQ概述AMQP(Advanced Message Queue Protocol)定义了一种消息系统规范。这个规范描述了在一个分布式的系统中各个子系统如何通过消息交互。而RabbitMQ则是AMQP的一种基于erlang的实现。AMQP将分布式系统中各个子系统隔离开来，子系统之间不再有依赖。子系统仅依赖于消息。子系统不关心消息的发送者，也不关心消息的接受者。AMQP中有一些概念，用于定义与应用层的交互。这些概念包括：message、queue、exchange、channel, connection, broker、vhost。注：到目前为止我并没有打算使用AMQP，所以没有做更深入的学习，仅为了找个机会写写erlang代码，以下信息仅供参考。 message，即消息，简单来说就是应用层需要发送的数据 queue，即队列，用于存储消息 exchange，有翻译为“路由”，它用于投递消息，应用程序在发送消息时并不是指定消息被发送到哪个队列，而是将消息投递给路由，由路由投递到队列 channel，几乎所有操作都在channel中进行，有点类似一个沟通通道 connection，应用程序与broker的网络连接 broker，可简单理解为实现AMQP的服务，例如RabbitMQ服务关于AMQP可以通过一篇很有名的文章了解更多：RabbitMQ+Python入门经典 兔子和兔子窝RabbitMQ的运行需要erlang的支持，erlang和RabbitMQ在windows下都可以直接使用安装程序，非常简单。RabbitMQ还支持网页端的管理，这需要开启一些RabbitMQ的插件，可以参考官方文档。RabbitMQ本质上其实是一个服务器，与这个服务器做交互则是通过AMQP定义的协议，应用可以使用一个实现了AMQP协议的库来与服务器交互。这里我使用erlang的一个客户端，对应着RabbitMQ的tutorial，使用erlang实现了一遍。基于这个过程我将一些关键实现罗列出来以供记忆：主要功能使用关于RabbitMQ erlang client的使用说明可以参考官方文档。这个client library下载下来后是两个ez文件，其实就是zip文件，本身是erlang支持的库打包格式，但据说这个feature还不成熟。总之我是直接解压，然后在环境变量中指定ERL_LIBS到解压目录。使用时使用include_lib包含库文件（类似C语言里的头文件）： -include_lib(\"amqp_client/include/amqp_client.hrl\").Connection/Channel对于连接到本地的RabbitMQ服务： {ok, Connection} = amqp_connection:start(#amqp_params_network{}), {ok, Channel} = amqp_connection:open_channel(Connection),创建Queue每个Queue都有名字，这个名字可以人为指定，也可以由系统分配。Queue创建后如果不显示删除，断开网络连接是不会自动删除这个Queue的，这个可以在RabbitMQ的web管理端看到。 #'queue.declare_ok'{queue = Q} = amqp_channel:call(Channel, #'queue.declare'{queue = &lt;&lt;\"rpc_queue\"&gt;&gt;}),但也可以指定Queue会在程序退出后被自动删除，需要指定exclusive参数： QDecl = #'queue.declare'{queue = &lt;&lt;&gt;&gt;, exclusive = true}, #'queue.declare_ok'{queue = Q} = amqp_channel:call(Channel, QDecl),上例中queue的名字未指定，由系统分配。发送消息一般情况下，消息其实是发送给exchange的： Payload = &lt;&lt;\"hello\"&gt;&gt; Publish = #'basic.publish'{exchange = &lt;&lt;\"log_exchange\"&gt;&gt;}, amqp_channel:cast(Channel, Publish, #amqp_msg{payload = Payload}),exchange有一系列规则，决定某个消息将被投递到哪个队列。发送消息时也可以不指定exchange，这个时候消息的投递将依赖于routing_key，routing_key在这种场景下就对应着目标queue的名字： #'queue.declare_ok'{queue = Q} = amqp_channel:call(Channel, #'queue.declare'{queue = &lt;&lt;\"rpc_queue\"&gt;&gt;}), Payload = &lt;&lt;\"hello\"&gt;&gt;, Publish = #'basic.publish'{exchange = &lt;&lt;&gt;&gt;, routing_key = Q}, amqp_channel:cast(Channel, Publish, #amqp_msg{payload = Payload}),接收消息可以通过注册一个消息consumer来完成消息的异步接收： Sub = #'basic.consume' {queue = Q}, #'basic.consume_ok'{consumer_tag = Tag} = amqp_channel:subscribe(Channel, Sub, self()),以上注册了了一个consumer，监听变量Q指定的队列。当有消息到达该队列时，系统就会向consumer进程对应的mailbox投递一个通知，我们可以使用receive来接收该通知： loop(Channel) -&gt; receive % This is the first message received (from RabbitMQ) #'basic.consume_ok'{} -&gt; loop(Channel); % a delivery {#'basic.deliver'{delivery_tag = Tag}, #amqp_msg{payload = Payload}} -&gt; echo(Payload), % ack the message amqp_channel:cast(Channel, #'basic.ack'{delivery_tag = Tag}), loop(Channel); ...绑定exchange和queue绑定(binding)其实也算AMQP里的一个关键概念，它用于建立exchange和queue之间的联系，以方便exchange在收到消息后将消息投递到队列。我们不一定需要将队列和exchange绑定起来。 Binding = #'queue.bind'{queue = Queue, exchange = Exchange, routing_key = RoutingKey}, #'queue.bind_ok'{} = amqp_channel:call(Channel, Binding)在绑定的时候需要填入一个routing_key的参数，不同类型的exchange对该值的处理方式不一样，例如后面提到fanout类型的exchange时，就不需要该值。更多细节通过阅读RabbitMQ tutorial，我们还会获得很多细节信息。例如exchange的种类、binding等。exchange分类exchange有四种类型，不同类型决定了其在收到消息后，该如何处理这条消息（投递规则），这四种类型为： fanout direct topic headersfanout类型的exchange是一个广播exchange，它在收到消息后会将消息广播给所有绑定到它上面的队列。绑定(binding)用于将队列和exchange关联起来。我们可以在创建exchange的时候指定exchange的类型： Declare = #'exchange.declare'{exchange = &lt;&lt;\"my_exchange\"&gt;&gt;, type = &lt;&lt;\"fanout\"&gt;&gt;} #'exchange.declare_ok'{} = amqp_channel:call(Channel, Declare)direct类型的exchange在收到消息后，会将此消息投递到发送消息时指定的routing_key和绑定队列到exchange上时的routing_key相同的队列里。可以多次绑定一个队列到一个exchange上，每次指定不同的routing_key，就可以接收多种routing_key类型的消息。注意，绑定队列时我们可以填入一个routing_key，发送消息时也可以指定一个routing_key。topic类型的exchange相当于是direct exchange的扩展，direct exchange在投递消息到队列时，是单纯的对routing_key做相等判定，而topic exchange则是一个routing_key的字符串匹配，就像正则表达式一样。在routing_key中可以填入一种字符串匹配符号：* (star) can substitute for exactly one word.# (hash) can substitute for zero or more words.header exchange tutorial中未提到，我也不深究消息投递及回应每个消息都可以提供回应，以使RabbitMQ确定该消息确实被收到。RabbitMQ重新投递消息仅依靠与consumer的网络连接情况，所以只要网络连接正常，consumer卡死也不会导致RabbitMQ重投消息。如下回应消息： amqp_channel:cast(Channel, #'basic.ack'{delivery_tag = Tag}),其中Tag来源于接收到消息时里的Tag。如果有多个consumer监听了一个队列，RabbitMQ会依次把消息投递到这些consumer上。这里的投递原则使用了round robin方法，也就是轮流方式。如前所述，如果某个consumer的处理逻辑耗时严重，则将导致多个consumer出现负载不均衡的情况，而RabbitMQ并不关心consumer的负载。可以通过消息回应机制来避免RabbitMQ使用这种消息数平均的投递原则： Prefetch = 1, amqp_channel:call(Channel, #'basic.qos'{prefetch_count = Prefetch})消息可靠性RabbitMQ可以保证消息的可靠性，这需要设置消息和队列都为durable的： #'queue.declare_ok'{queue = Q} = amqp_channel:call(Channel, #'queue.declare'{queue = &lt;&lt;\"hello_queue\"&gt;&gt;, durable = true}), Payload = &lt;&lt;\"foobar\"&gt;&gt;, Publish = #'basic.publish'{exchange = \"\", routing_key = Queue}, Props = #'P_basic'{delivery_mode = 2}, %% persistent message Msg = #amqp_msg{props = Props, payload = Payload}, amqp_channel:cast(Channel, Publish, Msg)参考除了参考RabbitMQ tutorial外，还可以看看别人使用erlang是如何实现这些tutorial的，github上有一个这样的项目：rabbitmq-tutorials。我自己也实现了一份，包括rabbitmq-tutorials中没实现的RPC。后来我发现原来rabbitmq erlang client的实现里已经包含了一个RPC模块。 RabbitMQ源码解析前奏–AMQP协议 RabbitMQ+Python入门经典 兔子和兔子窝 Erlang AMQP Client library Manage RabbitMQ by WebUI" }, { "title": "浅析软件工程开发方法学RUP", "url": "/posts/rup/", "categories": "module", "tags": "rup", "date": "2013-03-21 00:00:00 +0800", "snippet": "前言因为之前一直处在游戏开发行业，由于种种原因一直对软件工程中的项目管理、项目开发方法缺乏体验。虽然项目中也曾倡导编写更多的文档，无论是模块说明文档还是设计文档，但效果一直不好。不甚理想的地方主要体现在文档的规范性欠缺、不统一、浮于表面没有实质内容。文档的编写缺乏详尽的方法指导，那么所谓的设计文档要么是用来敷衍上级要么就是随着开发人员的水平不一而千差万别。当我开始目前这个非游戏项目时，我也曾想，前期做好结构设计，制定好关键问题的解决方案，那么要完成这个项目就不在话下了。但是我很快就面临了一个问题：需求不定。回想身处游戏公司的那些日子，程序员总是抱怨策划需求变更过快过多，在每一次策划提出一个需求变更时，谨慎的程序员都会再三让策划保证：放心，不会变了。而我面临的问题则更为严峻。我意识到，项目的需求，就连用户也无法一一罗列出来。我们需要的是需求调研。但就算你将客户的所有需求全部挖掘出来后（这几乎不可能，因为他们自己也不太清楚自己想要什么），当你交付了第一个软件版本，几乎可以肯定客户会提出一大堆的需求变更：我要的不是这个，我要的那个怎么没有，哦，我当初以为你说的是另一个意思。当然，需求调研这种工作不是让程序员去做的（那会更悲剧，无论是对客户还是对程序员而言，他们都是在对牛弹琴）。但需求的不确定性也总是存在的。事实上，需求变化本身就是一个很正常的现象。我一向愿意更悲观地处理软件开发方面的问题，所谓小心使得万年船。基于此，我决定摆好心态学学软件开发的方法学。概要本文简要描述、总结了RUP开发方法学的主要内容，结合我自己的感受阐述了一些RUP的核心原则。我相信我所理解的内容是肤浅的，对于非代码的表达我更相信其是存在歧义的。所以本文仅当是一种经验参考，不必当真。RUP据传是用于指导大型甚至超大型项目开发的，我们做的不是这样规模的项目。但是我们需要记录下整个项目的开发过程，通过这个过程中产出的工件任何一个人可以看出这个项目是如何实现出来的，其目的在于规避唯有从海量代码中才能熟悉项目实现这种问题。这里出现了一个概念：工件，其指的是软件项目开发过程中任何留下记录的事物，例如文档、图、代码等。RUP的一个重要思想，在于其整个软件开发过程都是可推导的。例如我们通常说的软件架构，或小一点的模块结构，都是通过开发过程中前面阶段产出的工件推导得出，而不是凭借程序员的经验拍脑袋想出来的（经验不太可靠，并且千差万别，而推导意味着将每个环节变得可靠）。我们借助RUP的这个特性，创建这些工件，用以建立起软件实现的可靠知识库。RUP概览以下均摘自&lt;Thinking in UML&gt;中对RUP的描述： 统一过程归纳和集成了软件开发活动中的最佳实践，它定义了软件开发过程中最重要的阶段和工作（四个阶段和九个核心工作流），定义了参与软件开发过程的各种角色和他们的职责，还定义了软件生产过程中产生的工件，并提供了模板。最后，采用演进式软件生命周期（迭代）将工作、角色和工件串在一起，形成了统一过程。 统一过程是一种追求稳定的软件方法，它追求开发稳定架构，控制变更 统一过程集成了面向对象方法、UML语言、核心工作流、工件模板和过程指导等知识简单来说，RUP作为一种软件项目开发方法学，它定义了软件开发的每一个过程，最重要的是它指导了在每一个过程需要产出什么，这些产出又是怎样得到。它试图规范化整个流程，以规避需求变更，项目参与者水平不一等带来的项目不可控等问题，以期一个软件产品稳定地开发出来。在一个项目开发过程中，最核心的资源是人，最不可控的亦是人。RUP过程与实践我觉得要快速学习一种知识，需要首先获得这门知识的总体框架。另一方面，在我们获得更多信息后，我们需要挖掘出这门知识的核心思想。学习RUP我觉得从这两方面入手是相对比较快速和有效的手段。RUP框架RUP定义了软件开发过程的四个阶段，以及9个工作流程。一张极为经典的RUP开发过程框架图如下：RUP将整个软件开发过程分为四个阶段： 先启(Inception)、 精化(Elaboration) 构建(Construction) 产品化(Transition)每一个阶段的工作分为9个流程： 业务建模 需求 分析设计 实施 测试 部署 配置与变更管理 项目管理 环境其中，前6个流程被统称为”engineering disciplines”，后3个流程被称为”supporting disciplines”。当然，我们主要关注前6个流程。那么，这些工作流程和开发阶段又有什么关系呢？上图中其实已经阐明了这些关系。RUP指导迭代开发。在软件开发的这4个阶段中，每一个阶段会被分为若干次迭代。而每一次迭代则涵盖了这9个工作流程。随着开发阶段向产品化靠近，自然而然地，需求的变更、增加自然会减少，所以从图中可以看出，开发过程越到后期，其工作流程中关于需求的工作则越少。同样，在先启阶段，其需求相关的工作则占据了该阶段的主要工作内容。RUP中的迭代要求在每一次迭代中，都会完整地实施一遍整个工作流程。在软件实施阶段，甚至会在每一个迭代过程完后输出一个可运行的软件版本。这个版本可能会被交付给客户，以期进一步地在功能需求上取得与客户一致的意见。这倒是同敏捷开发有点类似。既然制定了工作流程，那每一个工作流程该如何去实施呢？RUP制定了每个工作流程需要参与的角色，这些角色需要从事的活动，以及这些活动产生的工件。这句话实际上反映了RUP的一个重要信息，摘自wiki： RUP is based on a set of building blocks, or content elements, describing what is to be produced, the necessary skills required and the step-by-step explanation describing how specific development goals are to be achieved. The main building blocks, or content elements, are the following: Roles (who) – A Role defines a set of related skills, competencies and responsibilities. Work Products (what) – A Work Product represents something resulting from a task, including all the documents and models produced while working through the process. Tasks (how) – A Task describes a unit of work assigned to a Role that provides a meaningful result. RUP建模在我看来，RUP每个工作流程所完成的工作，就是一个建模的过程。所谓建模，简单来说就是将需要描述的事物通过更系统的形式表达出来，以期获得对该事物更深入的理解。&lt;Thinking in UML&gt;中定义建模概念为： 建模(modeling)，是指通过对客观事物建立一种抽象的方法用以表征事物并获得对事物本身的理解，同时把这种理解概念化，将这些逻辑概念组织起来，构成一种对所观察的对象的内部结构和工作原理的便于理解的表达。在这里，建模的过程需要使用一些工具。在RUP中建模使用UML来完成。在&lt;Thinking in UML&gt;中讲述了UML的核心模型，包括： 业务用例模型 概念用例模型 系统用例模型 领域模型 分析模型 软件架构和框架 设计模型 组件模型 实施模型可能在大家的普遍认识中，UML无非就是几种图，并且粗看一眼理解起来也不困难，甚至还能用来画画类图做下代码结构设计。但UML的作用不仅仅如此。以上所描述的UML核心模型中，每个模型并不单指的的是一种UML图。每个模型实际上都会包含几种UML图，会包含若干张UML图。这些模型基本上渗透于RUP的9个工作流程中，只不过不同的工作流程使用的模型比重不一而已。例如在“分析设计”工作流程中，可能会使用到系统用例模型、分析模型、软件架构和框架、设计模型等，而业务用例模型可能在这个流程中根本不会用到；相反，业务用例模型则可能在“业务建模”流程中被广泛使用。前已述及在RUP的每个工作流程中，RUP定义了该流程需要参与的角色，以及这些角色需要进行的活动，例如这里可以看看“分析设计”流程中的角色和活动集（摘自&lt;Thinking in UML&gt;）：相应的，在该工作流程中需要产出的工件集为（摘自&lt;Thinking in UML&gt;）：既然使用了UML作为建模工具，所以可以简单地说这些工件主要就是UML图，当然也会有其他文档性质的事物，例如网络协议结构、数据库表等UML无法描述的东西则通过普通文字性文档描述。RUP最佳实践到目前为止我们已经了解到RUP定义了开发过程(phase)，定义了每个过程包含的若干工作流程，还定义了每个工作流程需要哪些角色从事哪些活动来完成哪些工件。除此之外，RUP还提供了6条最佳实践用以指导软件开发： 迭代开发 管理需求 使用基于组件的架构 可视建模 持续的质量验证 控制变更这些实践在我看来仅仅是一些项目开发的指导原则，它们渗透到每一个过程，每一个工作流程。在项目过程中实践这些原则，用以确保项目的成功。例如我们使用UML建模，以达到“可视建模”。我们通过建立需求用例，以“管理需求”。RUP核心思想似乎没有文档来专门阐述RUP的核心思想，但我觉得掌握其核心思想才是学习的要点所在。要理解一种软件开发方法学的核心思想，其实最好是将其与别的方法学做比较。这里先就我的一些感想做阐述。用例驱动用例驱动指的是整个软件项目的推进过程，是依靠“用例”来完成。&lt;Thinking in UML&gt;： 在实际的软件项目中，一个软件要实现的功能通过用例来捕获，接下来的所有分析、设计、实现、测试都由用例来取得，即以实现用例为目标。在统一过程中用例能够驱动的不仅仅是分析设计。用例简单来说就是描述了一个系统功能。但必须注意的是，这仅仅是它定义的一小部分。用例主要分布在“业务建模”、“需求”、“分析设计”这些工作过程中。在不同的过程中用例的粒度和性质都不一样。例如对于一个借书系统而言，在业务建模阶段，我们可以获取出一个“借书”用例，其系统边界甚至不是系统而可能仅关注这个业务本身（因为这个阶段还没有考虑到计算机如何实现这个借书业务）；在系统分析阶段，我们就可以将“借书”这个用例细化为用户和计算机软件系统的交互；进一步地，我们可能会进一步精化这个用例，例如用户通过网页终端“借书”。（这里描述了很多建模的细节，可不必深究，本文只给出一个概要性的介绍）我们说用例驱动软件开发，但它如何驱动的呢？我在实际的建模过程中，最明显的感受就是用例驱动了整个建模过程。 在需求分析阶段，我以系统使用者的角度绘制出了一份用例图，用于表达使用者对该系统的需求 然后我绘制序列图（活动图等）来实现这些用例，也就是阐述使用者具体是如何与系统交互的 从之前的建模过程中我获得对系统功能需求方面的认识 基于前面的分析我可以绘制出系统用例图，以明确系统的各个功能需求 同样针对用例绘制用例实现图 用例本身应该包含更多的文档，因此我编写用例规约用以详细描述各个用例 从用例规约、用例实现中我可以抽离出一些分析类（较设计类更高抽象的类），包含用例场景中涉及到的实体，控制逻辑 细化这些分析类，将分析类组织起来形成系统，我会用界面类去衔接各个控制类 将得到的分析类按模块来划分，从而可以得到一个初步的系统架构 初步考虑系统实现，我甚至会得到一个初步是的系统部署图 回过头不断审视系统用例，以确认我是否实现了所有用例，这可以保证我的分析实现了所有需求，我不用枚举所有系统特性是否被我考虑周全，我仅需在已有用例图中核实 基于模块实现各个用例，或者基于分析类来实现系统用例 通过重新绘制以及核实用例，可以进一步精化分析类，分析类在很大程度上会一一对应到设计类，而设计类则对应到实际的代码 可以进入设计阶段，设计阶段会考虑到系统的实现细节，例如使用的语言，使用的框架等进入设计阶段后，虽然可以进一步建模，得到会直接映射到代码的类图、序列图等，但这样的图在面临需求变更时，基本上会面临修改，这意味着维护这些文档需要耗费精力。所以，&lt;Thinking in UML&gt;中主张将精力放在维护分析类模型中，而通过其他约定实现从分析类到实际代码的转换。我觉得这个也在理。规范化整个过程我个人觉得RUP的一大特点在于规范化了整个软件开发过程，每一个步骤需要哪些角色参与，该干什么，怎么去干都有指导。加之这些活动的”可推导性“，这意味着不论参与角色属于什么水平，都可以稳固地推进项目进程。此外，这种规范化也会给项目留下详细的演化过程。你可以明确地看到整个软件是如何演化出最终的产品代码，可以深入地理解项目代码中的设计。总结我只是一个RUP新手，即便如此，我依然不觉得RUP是软件开发的万能药。我相信任何软件开发方法都是有局限性的。我们在实际使用的时候也只是吸取其精华。不同的开发方法其适用范围也是不一样的。正如有人将RUP和XP做比较时说，如果你使用RUP去开一个杂货铺，在没开张之前你就已经破产了；同样如果你用XP去做飞机，飞机毁了十来次也许才能做出来（from &lt;Thinking in UML&gt; again）。参考文档 &lt;Thinking in UML&gt; RUP和IPD流程的优缺点 IBM Rational Unified Process(wiki) 軟體工程三大陣營, RUP, CMMI, Agile Method(需翻墙) XP与RUP的比较" }, { "title": "分布式程序开发平台ICE概览", "url": "/posts/ice-overview/", "categories": "c/c++, ICE", "tags": "ice", "date": "2013-02-15 00:00:00 +0800", "snippet": "本文基于ICE Manual及相关文档就ICE的一些主要特性做一个概览，它不是一个tutorial，不是一个guid，更不是manual。概览ICE，Internet Communications Engine，按照官方介绍，是一个支持C++、.Net、Java、Python、Objective-C、Ruby、PHP及ActionScript等语言的分布式程序开发平台。按照我的理解，简单来说它是一个核心功能包装RPC的库。要把这个RPC包装得漂亮，自然而然，对于使用者而言，调用一个远端的接口和调用一个本地的接口没有什么区别，例如： Object *obj = xxx obj-&gt;sayHello(); ICE包装sayHello接口，当应用层调用该接口时，ICE发送调用请求到远端服务器，接收返回结果并返回给应用层。ICE在接口提供方面，做到了这一点。以下，我将逐个给出ICE中的一些工具、组件、特性说明，以展示它作为一个分布式程序开发平台所拥有的能力。到目前为止，所有这些信息均来自于ICE相关文档，总结出来权当为自己服务。SliceSlice(Specification Language for Ice)是ICE定义的一种中间语言，其语法类似于C++。对于一个RPC过程而言，例如上面调用远端的sayHello接口，其主要涉及到调用这个接口的参数和返回值传递，当然接口本身的传递不在话下，ICE为了包装这个过程，其使用了这样一种方式：使用者使用Slice语言描述RPC过程中调用的接口，例如该接口属于哪个类，该接口有哪些参数哪些返回值；然后使用者使用ICE提供的Slice编译器（实际上是一个语言翻译程序）将Slice源码翻译成目标语言。而这个目标语言，则是使用者开发应用程序的开发语言，即上文提到的C++、.Net、Java等。这些翻译出来的目标代码，就封装了sayHello底层实现的一切细节。当然事情没有这么简单，但我们目前只需关注简单的这一部分。ICE之所以支持那么多种开发语言，正是Slice立下的功劳。Slice语言本身的语言特性，实际上受限于目标语言的语言特性，例如Slice支持异常，恰是因为Slice转换的所有语言都包含异常这个语法特性。Slice还有一个重要特性，在于一份Slice源码被翻译出来的目标代码，一般情况是被服务器和客户端同时使用。开发步骤使用ICE开发应用程序，其步骤遵循： 编写Slice，说明整个RPC中涉及到的接口调用，编译它 基于Slice目标代码和ICE库编写Server 基于Slice目标带啊和ICE库编写Client一个例子有必要展示一个例子，以获得使用ICE开发应用程序的感性认识。这个例子是一个简单的hello world程序，客户端让服务器打印一个字符串。 编写Slice // Printer.ice，Slice源码后缀为ice module Demo { interface Printer { void printString(string s); }; };使用ICE提供的程序翻译为C++代码： $ slice2cpp Printer.ice得到Printer.cpp和Printer.h。Slice翻译出来的目标代码除了封装RPC交互的一些细节外，最重要的，因为本身Slice文件其实是定义接口，但接口的实现，则需要应用层来做。 服务器端使用生成的Printer.cpp/.h，并实现Printer接口 // 翻译出来的Printer.h中有对应于Slice中定义的Printer类，及需要实现的printString接口 class PrinterI : public Printer { public: virtual void printString(const string&amp; s, const Ice::Current&amp;) { count &lt;&lt; s &lt;&lt; endl; } }; 客户端使用生成的Printer.cpp/.h，通过ICE获得一个Printer对象，然后调用其printString接口 // don't care about this PrinterPrx printer = PrinterPrx::checkedCast(base); printer-&gt;printString(\"Hello World!\");使用ICE开发应用程序，整体过程即为以上展示。概念ICE包含了很多概念，作为一个开发平台而言，有其专有术语一点不过分，熟悉这些概念可以更容易学习ICE。这里罗列一些关键概念。服务器端和客户端ICE中的服务器端和客户端和一般网络程序中的概念不太一样。在若干个交互的网络程序中，我们都很好理解这样一种现象：某个程序有多个角色，它可能是作为A程序的服务器端，也可能是作为B程序的客户端。ICE中的服务器和客户端角色更容易变换。以Printer例子为例，如果我们的printString接口有一个回调函数参数（这在ICE中很常见），服务器实现printString时，当其打印出字符串后，需通过该回调函数通知客户端。这样的回调机制在ICE的实现中，会创建一个新的网络连接，而此时，这个原有的服务器端就变成了原有客户端的客户。当然，你也可以避免这样的情况出现。ICE Objects/Object Adapter/Facet对于Printer例子，一个Printer对象可以被看作是一个ICE Objects。Object可以说是服务器端提供给客户端的接口。所以在服务器端通常会创建出很多个Object。服务器端使用Object Adapter对象去保存这些Object。例如，一个典型的ICE对象在初始化时可能包含以下代码： // 创建一个Object Adapter Ice::ObjectAdapterPtr adapter = communicator()-&gt;createObjectAdapter(\"Hello\"); // 创建一个Object，形如Printer Demo::HelloPtr hello = new HelloI; // 将Object加入到Object Adapter adapter-&gt;add(hello, communicator()-&gt;stringToIdentity(\"hello\"));Facet是Object的一部分，或者说Object是Facet的一个集合，摘Ice manual中的一句话： An Ice object is actually a collection of sub-objects known as facets whose types are not necessarily related.ProxyProxy是ICE客户端里的概念。客户端通过Proxy访问服务器端上的Object，通过Proxy调用服务器端Object上提供的接口。在客户端上一般有类似以下代码： Ice::ObjectPrx base = ic-&gt;stringToProxy(\"SimplePrinter:default -p 10000\"); // Printer Proxy PrinterPrx printer = PrinterPrx::checkedCast(base); printer-&gt;printString(\"Hello World!\");Proxy又分为几种，包括：Direct ProxyDirect Proxy，这里的direct意指这个proxy访问的object时，是否携带了地址(EndPoint)信息，例如上面例子中SimplePrinter:default -p 10000就是一个地址。Indirect ProxyIndirect Proxy相对Direct Proxy而言，其没有具体的地址，仅仅是一个符号。通常包含两种形式： SimplePrinter SimplePrinter@PrinterAdapter为了获取真正的地址，客户端需要一个定位服务（location service）来获取这个符号对应的地址。ICE中提供了一些默认的服务程序，IceGrid就是其中之一，而IceGrid的作用就包括定位具体的地址，即翻译符号地址到具体的地址。这里Indirect Proxy可以看作一个域名，而Direct Proxy可以看作是IP地址。Indirect Proxy使用时，就需要借助DNS翻译得到域名对应的IP地址。Fixed Proxy由于Proxy是用于与服务器端的Object通信的，客户端借助Proxy来访问服务器端的Object，所以Proxy通常都会对应一个真实的网络连接。在ICE中，一般的Proxy于网络连接(Connection)实际上是没有太大关联的。一个Proxy可以没有Connection，也可以在建立这个Connection后又断开之。但是，ICE提供了一种特殊的Proxy，Fixed Proxy，这种Proxy紧密地与一个Connection绑定在一起，其生命周期被强制关联起来。关于Fixed Proxy可以参看ICE Manual Connection Management。其他 AMIAsynchronous Method Invocation，对于客户端而言，用于表示某个服务器端接口是异步操作，需在Slice中使用metadata来修饰这个接口，例如： [\"ami\"] void sayHello(int delay) AMDAsynchronous method dispatch，这个针对于服务器端，同样表示这个接口是异步操作，需在Slice中使用metadata来修饰这个接口： [\"ami\", \"amd\"] void sayHello(int delay)通常对于这种异步接口而言，都需要使用Slice metadata ami和amd同时修饰。 idempotentidempotent是Slice中的概念，同const一样用于修饰某个接口的特性。idempotent表示该接口无论调用多少次，其执行结果都是相同的，例如一般的get类接口。 batched invocation客户端调用服务器端的接口这个动作称为invocation。就像网络层的数据缓存一样，ICE对于接口调用也可能暂时缓存，当多个提交请求缓存起来后，然后调用刷新接口全部刷新到服务器端，则称为batched invocation。服务ICE除了提供一个库之外，还提供了一些应用程序。这些应用程序本身也是一些服务器，提供了一些方便的功能方便我们开发分布式程序。FreezeFreeze用于将Slice对象持久化到数据库中，按照Manual里的说法，它应该是一个编译器，可以生成一些持久化操作的代码。Freeze持久化对象时使用的数据库是Berkeley DB。 Ice has a built-in object persistence service, known as Freeze. Freeze makes it easy to store object state in a database: you define the state stored by your objects in Slice, and the Freeze compiler generates code that stores and retrieves object state to and from a database. Freeze uses Berkeley DB as its database.FreezeScript有点类似于Rails中的数据库操作工具，可用于操作持久化到数据库中的对象数据。 Ice also offers a tool set collectively called FreezeScript that makes it easier to maintain databases and to migrate the contents of existing databases to a new schema if the type definitions of objects change.IceBoxIceBox可用于管理服务器中的动态组件。这些动态组件本质上也是提供服务的ICE程序。在形式上，这些组件可以是动态连接库。 IceBox is a simple application server that can orchestrate the starting and stopping of a number of application components. Application components can be deployed as a dynamic library instead of as a process.IceGridIceGrid相当于一个DNS解析服务，可以让服务器不用配置EndPoint，客户端也不用指定服务器的EndPoint，以方便大量的服务器部署。在一般的应用中，我们需要为ICE服务器指定绑定的网络地址（IP和端口），同时也需要为客户端指定服务器端的地址信息。当服务增加到一定数量时，就会存在管理上和配置上的麻烦。而IceGrid则是用于避免这种麻烦，将服务器端和客户端上的地址信息通过一个符号代替，就像我们把Internet上的服务器使用域名来标识一样。但IceGrid的作用不仅如此，通过配合部署一系列称为IceGrid Node的程序，IceGrid还可以管理各个服务器的启动、关闭、宕机重启等，其中甚至包括负载均衡。 IceGrid provides a facility to activate servers on demand, when a client first invokes an operation.Server activation is taken care of by IceGrid nodes. You must run an IceGrid node on each machine on which you want IceGrid to start servers on demand.简要介绍可以参看ICE Manual Teach Yourself IceGrid in 10 minutesGlacier2 Glacier2 is a lightweight firewall traversal solution for Ice applications.按我的理解，Glacier2就像一个网关服务器。它被部署在服务器和客户端之间，我们的服务器群部署在内网，外网不可访问，然后通过Glacier2，外部网络的客户端就可以访问内网的服务器群提供的服务。对于服务器的开发而言，使用Glacier2，服务器端不需要做任何改动。客户端需要配置Glacier2服务的地址信息，也需要配置要使用服务器的地址信息。Glacier2通过客户端欲访问的服务器地址，在内网定位到真实的服务器，并转发请求提供服务。Glacier2支持验证客户端，从这一点看来，它又有点像一个验证服务器。通过验证客户端，以提供被正确授权的客户端以完整服务。Glacier2的工作过程可以描述为： When a client invokes an operation on a routed proxy, the client connects to one of Glacier2’s client endpoints and sends the request as if Glacier2 is the server. Glacier2 then establishes an outgoing connection to the client’s intended server in the private network, forwards the request to that server, and returns the reply (if any) to the client. Glacier2 is essentially acting as a local client on behalf of the remote client.一个Glacier2可服务于若干个客户端和服务器。详细参看ICE Manual Glacier2管理ICE服务器可以提供给外部一定的管理功能，包括：关闭服务器、读取服务器配置。这个功能是通过操作Ice.Admin这个Ice Object来实现的。这个Object包含两个Facet：Process和Property，分别对应于关闭服务器和读取服务器配置功能。对于需要管理服务器的客户端而言，可以大致通过如下代码来完成： // 可以通过communicator来获取这个admin object Ice::ObjectPrx adminObj = ...; // 获取admin object里的property facet Ice::PropertiesAdminPrx propAdmin = Ice::PropertiesAdminPrx::checkedCast(adminObj, \"Properties\"); Ice::PropertyDict props = propAdmin-&gt;getPropertiesForPrefix(\"\");详细参看ICE Manual Administrative Facility连接管理前已述及，ICE中的网络连接隐藏于Proxy之下。Proxy有两个接口可以获取这个连接对象： ice_getConnection ice_getCachedConnection例如： HelloPrx hello = HelloPrx::uncheckedCast(communicator-&gt;stringToProxy(\"hello:tcp -h remote.host.com -p 10000\")); ConnectionPtr conn = hello-&gt;ice_getConnection();ICE隐藏了网络连接的细节。当ICE发现需要建立连接时才会去建立，例如以上例子中当获得一个Proxy时（这里是HelloPrx），ICE并不建立网络连接，当某个时刻通过该Proxy调用服务器端的某个接口时，ICE发现对应的网络连接没有建立，则发起网络连接。以上例子在获取Proxy时，使用了uncheckCast，关于checkedCast和uncheckedCast，也影响着网络连接的建立逻辑： On the other hand, if the code were to use a checkedCast instead, then connection establishment would take place as part of the checkedCast, because a checked cast requires a remote call to determine whether the target object supports the specified interface.关于连接管理，ICE使用了一个称为ACM的机制，即Active connection management。当某个连接非active一段时间后，ICE就会主动关闭此连接。应用层当然可以控制这个行为。详细参看ICE Manual Connection Management" }, { "title": "使用Clang实现C语言编程规范检查", "url": "/posts/using-clang/", "categories": "clang, c/c++", "tags": "clang", "date": "2013-02-12 00:00:00 +0800", "snippet": "概述Clang是LLVM编译器工具集的前端部分，也就是涵盖词法分析、语法语义分析的部分。而LLVM是Apple在Mac OS上用于替代GCC工具集的编译器软件集合。Clang支持类C语言的语言，例如C、C++、Objective C。Clang的与众不同在于其模块化的设计，使其不仅实现编译器前端部分，并且包装成库的形式提供给上层应用。使用Clang可以做诸如语法高亮、语法检查、编程规范检查方面的工作，当然也可以作为你自己的编译器前端。编程规范一般包含编码格式和语义规范两部分。编码格式用于约定代码的排版、符号命名等；而语义规范则用于约定诸如类型匹配、表达式复杂度等，例如不允许对常数做逻辑运算、检查变量使用前是否被赋值等。本文描述的主要是基于语义方面的检查，其经验来自于最近做的一个检查工具，该工具实现了超过130条的规范。这份规范部分规则来自于MISRA C编程模式编译器前端部分主要是输出代码对应的抽象语法树(AST)。Clang提供给上层的接口也主要是围绕语法树来做操作。通过google一些Clang的资料，你可能会如我当初一样对该如何正确地使用Clang心存疑惑。我最后使用的方式是基于RecursiveASTVisitor。这是一种类似回调的使用机制，通过提供特定语法树节点的接口，Clang在遍历语法树的时候，在遇到该节点时，就会调用到上层代码。不能说这是最好的方式，但起码它可以工作。基于RecursiveASTVisitor使用Clang，程序主体框架大致为：// 编写你感兴趣的语法树节点访问接口，例如该例子中提供了函数调用语句和goto语句的节点访问接口class MyASTVisitor : public RecursiveASTVisitor&lt;MyASTVisitor&gt; {public: bool VisitCallExpr(CallExpr *expr); bool VisitGotoStmt(GotoStmt *stmt); ...};class MyASTConsumer : public ASTConsumer {public: virtual bool HandleTopLevelDecl(DeclGroupRef DR) { for (DeclGroupRef::iterator b = DR.begin(), e = DR.end(); b != e; ++b) { Visitor.TraverseDecl(*b); } return true; } private: MyASTVisitor Visitor;};int main(int argc, char **argv) { CompilerInstance inst; Rewriter writer; inst.createFileManager(); inst.createSourceManager(inst.getFileManager()); inst.createPreprocessor(); inst.createASTContext(); writer.setSourceMgr(inst.getSourceManager(), inst.getLangOpts()); ... // 其他初始化CompilerInstance的代码 const FileEntry *fileIn = fileMgr.getFile(argv[1]); sourceMgr.createMainFileID(fileIn); inst.getDiagnosticClient().BeginSourceFile(inst.getLangOpts(), &amp;inst.getPreprocessor()); MyASTConsumer consumer(writer); ParseAST(inst.getPreprocessor(), &amp;consumer, inst.getASTContext()); inst.getDiagnosticClient().EndSourceFile(); return 0;}以上代码中，ParseAST为Clang开始分析代码的主入口，其中提供了一个ASTConsumer。每次分析到一个顶层定义时(Top level decl)就会回调MyASTConsumer::HandleTopLevelDecl，该函数的实现里调用MyASTVisitor开始递归访问该节点。这里的decl实际上包含定义。这里使用Clang的方式来源于Basic source-to-source transformation with Clang。语法树Clang中视所有代码单元为语句(statement)，Clang中使用类Stmt来代表statement。Clang构造出来的语法树，其节点类型就是Stmt。针对不同类型的语句，Clang有对应的Stmt子类，例如GotoStmt。Clang中的表达式也被视为语句，Clang使用Expr类来表示表达式，而Expr本身就派生于Stmt。每个语法树节点都会有一个子节点列表，在Clang中一般可以使用如下语句遍历一个节点的子节点：for (Stmt::child_iterator it = stmt-&gt;child_begin(); it != stmt-&gt;child_end(); ++it) { Stmt *child = *it;}但遗憾的是，无法从一个语法树节点获取其父节点，这将给我们的规范检测工具的实现带来一些麻烦。TraverseXXXStmt在自己实现的Visitor中（例如MyASTVisitor），除了可以提供VisitXXXStmt系列接口去访问某类型的语法树节点外，还可以提供TraverseXXXStmt系列接口。Traverse系列的接口包装对应的Visit接口，即他们的关系大致为：bool TraverseGotoStmt(GotoStmt *s) { VisitGotoStmt(s); return true;}例如对于GotoStmt节点而言，Clang会先调用TraverseGotoStmt，在TraverseGotoStmt的实现中才会调用VisitGotoStmt。利用Traverse和Visit之间的调用关系，我们可以解决一些因为不能访问某节点父节点而出现的问题。例如，我们需要限制逗号表达式的使用，在任何地方一旦检测到逗号表达式的出现，都给予警告，除非这个逗号表达式出现在for语句中，例如：a = (a = 1, b = 2); /* 违反规范，非法 */for (a = 1, b = 2; a &lt; 2; ++a) /* 合法 */逗号表达式对应的访问接口为VisitBinComma，所以我们只需要提供该接口的实现即可：class MyASTVisitor : public RecursiveASTVisitor&lt;MyASTVisitor&gt; {public: ... bool VisitBinComma(BinaryOperator *stmt) { /* 报告错误 */ return true; } ...};（注：BinaryOperator用于表示二目运算表达式，例如a + b，逗号表达式也是二目表达式）但在循环中出现的逗号表达式也会调用到VisitBinComma。为了有效区分该逗号表达式是否出现在for语句中，我们可以期望获取该逗号表达式的父节点，并检查该父节点是否为for语句。但Clang并没有提供这样的能力，我想很大一部分原因在于臆测语法树（抽象语法树）节点的组织结构（父节点、兄弟节点）本身就不是一个确定的事。这里的解决办法是通过提供TraverseForStmt，以在进入for语句前得到一个标识：class MyASTVisitor : public RecursiveASTVisitor&lt;MyASTVisitor&gt; {public: ... // 这个函数的实现可以参考RecursiveASTVisitor的默认实现，我们唯一要做的就是在for语句的头那设定一个标志m_inForLine bool TraverseForStmt(ForStmt *s) { if (!WalkUpFromForStmt(s)) return false; m_inForLine = true; for (Stmt::child_range range = s-&gt;children(); range; ++range) { if (*range == s-&gt;getBody()) m_inForLine = false; TraverseStmt(*range); } return true; } bool VisitBinComma(BinaryOperator *stmt) { if (!m_inForLine) { /* 报告错误 */ } return true; } ...};（注：严格来说，我们必须检查逗号表达式是出现在for语句的头中，而不包括for语句循环体）类型信息对于表达式(Expr)而言，都有一个类型信息。Clang直接用于表示类型的类是QualType，实际上这个类只是一个接口包装。这些类型信息可以用于很多类型相关的编程规范检查。例如不允许定义超过2级的指针(例如int ***p)：bool MyASTVisitor::VisitVarDecl(VarDecl *decl) { // 当发现变量定义时该接口被调用 QualType t = decl-&gt;getType(); // 取得该变量的类型 int pdepth = 0; // check pointer level for ( ; t-&gt;isPointerType(); t = t-&gt;getPointeeType()) { // 如果是指针类型就获取其指向类型(PointeeType) ++pdepth; } if (pdepth &gt;= 3) /* 报告错误 */}可以直接调用Expr::getType接口，用于获取指定表达式最终的类型，基于此我们可以检查复杂表达式中的类型转换，例如：float f = 2.0f;double d = 1.0;f = d * f; /* 检查此表达式 */对以上表达式的检查有很多方法，你可以实现MyASTVisitor::VisitBinaryOperator（只要是二目运算符都会调用），或者MyASTVisitor::VisitBinAssign（赋值运算=调用）。无论哪种方式，我们都可以提供一个递归检查两个表达式类型是否相同的接口：bool HasDiffType(BinaryOperator *stmt) { Expr *lhs = stmt-&gt;getLHS()-&gt;IgnoreImpCasts(); // 忽略隐式转换 Expr *rhs = stmt-&gt;getRHS()-&gt;IgnoreImpCasts(); if (lhs-&gt;getType() == rhs-&gt;getType())) { if (isa&lt;BinaryOperator&gt;(lhs) &amp;&amp; HasDiffType(cast&lt;BinaryOperator&gt;(lhs))) return true; if (isa&lt;BinaryOperator&gt;(rhs) &amp;&amp; HasDiffType(cast&lt;BinaryOperator&gt;(rhs))) return true; return false; } return true;}（注：此函数只是简单实现，未考虑类型修饰符之类的问题）该函数获得二目运算表达式的两个子表达式，然后递归检测这两个表达式的类型是否相同。Expr类提供了更多方便的类型相关的接口，例如判定该表达式是否为常数，是否是布尔表达式，甚至在某些情况下可以直接计算得到值。例如我们可以检查明显的死循环:while (1) { }可以使用：ASTContext &amp;context = inst.GetASTContext();bool result;// 假设stmt为WhileStmtif (stmt-&gt;getCond()-&gt;EvaluateAsBooleanCondition(result, context)) { if (result) /* 死循环 */符号表符号表这个概念比较广义，这里我仅指的是用于保存类型和变量信息的表。Clang中没有显示的符号表数据结构，但每一个定义都有一个DeclContext，DeclContext用于描述一个定义的上下文环境。有一个特殊的DeclContext被称为translation unit decl，其实也就是全局环境。利用这个translation unit decl，我们可以获取一些全局符号，例如全局变量、全局类型：// 获取全局作用域里指定名字的符号列表DeclContext::lookup_result GetGlobalDecl(const std::string &amp;name) { ASTContext &amp;context = CompilerInst::getSingleton().GetASTContext(); DeclContext *tcxt = context.getTranslationUnitDecl(); IdentifierInfo &amp;id = context.Idents.get(name); return tcxt-&gt;lookup(DeclarationName(&amp;id));}// 可以根据GetGlobalDecl的返回结果，检查该列表里是否有特定的定义，例如函数定义、类型定义等bool HasSpecDecl(DeclContext::lookup_result ret, Decl::Kind kind) { for (size_t i = 0; i &lt; ret.size(); ++i) { NamedDecl *decl = ret[i]; if (decl-&gt;getKind() == kind) { return true; } } return false;}有了以上两个函数，我们要检测全局作用域里是否有名为”var”的变量定义，就可以：HasSpecDecl(GetGlobalDecl(\"var\"), Decl::Var);每一个Decl都有对应的DeclContext，要检查相同作用域是否包含相同名字的符号，其处理方式和全局的方式有点不一样：// 检查在ctx中是否有与decl同名的符号定义bool HasSymbolInContext(const NamedDecl *decl, const DeclContext *ctx) { for (DeclContext::decl_iterator it = ctx-&gt;decls_begin(); it != ctx-&gt;decls_end(); ++it) { Decl *d = *it; if (d != decl &amp;&amp; isa&lt;NamedDecl&gt;(d) &amp;&amp; cast&lt;NamedDecl&gt;(d)-&gt;getNameAsString() == decl-&gt;getNameAsString()) return true; } return false;}bool HasSymbolInContext(const NamedDecl *decl) { return HasSymbolInContext(decl, decl-&gt;getDeclContext());}可以看出，这里检查相同作用域的方式是遍历上下文环境中的所有符号，但对于全局作用域却是直接查找。对于DeclContext的详细信息我也不甚明了，只能算凑合使用。实际上，这里使用“作用域”一词并不准确，在C语言中的作用域概念，和这里的context概念在Clang中并非等同。如果要检查嵌套作用域里不能定义相同名字的变量，例如：int var;{ int var;}通过Clang现有的API是无法实现的。因为Clang给上层的语法树结构中，并不包含作用域信息（在Clang的实现中，用于语义分析的类Sema实际上有作用域的处理）。当然，为了实现这个检测，我们可以手动构建作用域信息（通过TraverseCompoundStmt）。宏宏的处理属于预处理阶段，并不涵盖在语法分析阶段，所以通过Clang的语法树相关接口是无法处理的。跟宏相关的接口，都是通过Clang的Preprocessor相关接口。Clang为此提供了相应的处理机制，上层需要往Preprocessor对象中添加回调对象，例如：class MyPPCallback : public PPCallbacks {public: // 处理#include virtual void InclusionDirective(SourceLocation HashLoc, const Token &amp;IncludeTok, StringRef FileName, bool IsAngled, CharSourceRange FilenameRange, const FileEntry *File, StringRef SearchPath, StringRef RelativePath, const Module *Imported) { } // 处理#define virtual void MacroDefined(const Token &amp;MacroNameTok, const MacroInfo *MI) { } virtual void MacroUndefined(const Token &amp;MacroNameTok, const MacroInfo *MI) { } }inst.getPreprocessor().addPPCallbacks(new MyPPCallback());即，通过实现PPCallbacks中对应的接口，就可以获得处理宏的通知。Clang使用MacroInfo去表示一个宏。MacroInfo将宏体以一堆token来保存，例如我们要检测宏体中使用##和#的情况，则只能遍历这些tokens:// 分别记录#和##在宏体中使用的数量int hash = 0, hashhash = 0;for (MacroInfo::tokens_iterator it = MI-&gt;tokens_begin(); it != MI-&gt;tokens_end(); ++it) { const Token &amp;token = *it; hash += (token.getKind() == tok::hash ? 1 : 0); hashhash += (token.getKind() == tok::hashhash ? 1 : 0);}其他在我们所支持的编程规范中，有些规范是难以支持的，因此我使用了一些蹩脚的方式来实现。手工解析在针对函数的参数定义方面，我们支持的规范要求不能定义参数为空的函数，如果该函数没有参数，则必须以void显示标识，例如：int func(); /* 非法 */int func(void); /* 合法 */对于Clang而言，函数定义（或声明）使用的是FunctionDecl，而Clang记录的信息仅包括该函数是否有参数，参数个数是多少，并不记录当其参数个数为0时是否使用void来声明（记录下来没多大意义）。解决这个问题的办法，可以通过SourceLocation获取到对应源代码中的文本内容，然后对此文本内容做手工分析即可。（注：SourceLocation是Clang中用于表示源代码位置的类，包括行号和列号，所有Stmt都会包含此信息）通过SourceLocation获取对应源码的内容：std::pair&lt;FileID, unsigned&gt; locInfo = SM.getDecomposedLoc(loc);bool invalidTemp = false;llvm::StringRef file = SM.getBufferData(locInfo.first, &amp;invalidTemp);if (invalidTemp) return false;// tokenBegin即为loc对应源码内容的起始点const char *tokenBegin = file.data() + locInfo.second;要手工分析这些内容实际上还是有点繁杂，为此我们可以直接使用Clang中词法分析相关的组件来完成这件事：Lexer *lexer = new Lexer(SM.getLocForStartOfFile(locInfo.first), opts, file.begin(), tokenBegin, file.end());Token tok;lexer-&gt;Lex(tok); // 取得第一个tok，反复调用可以获取一段token流DiagnosticClang中用Diagnostic来进行编译错误的提示。每一个编译错误（警告、建议等）都会有一段文字描述，这些文字描述为了支持多国语言，使用了一种ID的表示方法。总之，对于一个特定的编译错误提示而言，其diagnostic ID是固定的。在我们的规范中，有些规范检测的代码在Clang中会直接编译出错，例如函数调用传递的参数个数不等于函数定义时的形参个数。当Clang编译出错时，其语法树实际上是不完善的。解决此问题的最简单办法，就是通过diagnostic实现。也就是说，我是通过将我们的特定规范映射到特定的diagnostic，当发生这个特定的编译错误时，就可以认定该规范实际上被检测到。对于简单的情况而言，这样的手段还算奏效。// `TextDiagnosticPrinter`可以将错误信息打印在控制台上，为了调试方便我从它派生而来class MyDiagnosticConsumer : public TextDiagnosticPrinter {public: // 当一个错误发生时，会调用此函数，我会在这个函数里通过Info.getID()取得Diagnostic ID，然后对应地取出规范ID virtual void HandleDiagnostic(DiagnosticsEngine::Level DiagLevel, const Diagnostic &amp;Info) { TextDiagnosticPrinter::HandleDiagnostic(DiagLevel, Info); // 例如检查三字母词(trigraph)的使用 if (Info.getID() == 816) /* 报告使用了三字母词 */ }};// 初始化时需传入自己定义的diagnosticinst.createDiagnostics(0, NULL, new MyDiagnosticConsumer(&amp;inst.getDiagnosticOpts()));该例子代码演示了对三字母词(wiki trigraph)使用限制的规范检测。全文完。" }, { "title": "C++陷阱：构造函数中的多态", "url": "/posts/c-plus-plus-ctor-virtual/", "categories": "c/c++", "tags": "c/c++, virtual", "date": "2012-09-17 16:01:00 +0800", "snippet": "C++中主要是通过给函数加上virtual关键字来实现多态。多态可用于改变一个接口的实现，也算是一种嵌入应用层代码到底层的实现手段。就算你用不到C++那些复杂的技术，多态肯定会被用到。但加上virtual不一定能保证多态成功：#include &lt;stdio.h&gt;class Base {public: Base() { Init(); } virtual ~Base() { Release(); } virtual void Init() { printf(\"Base::Init\\n\"); } virtual void Release() { printf(\"Base::Release\\n\"); }};class Derived : public Base {public: virtual void Init() { printf(\"Derived::Init\\n\"); } virtual void Release() { printf(\"Derived:Release\\n\"); }};int main(){ Base *obj = new Derived(); delete obj; return 0;}当在构造函数，包括析构函数中调用virtual函数时，预想中的多态是无法完成的，以上代码输出结果为：Base::InitBase::Release从语言设计角度来看，我个人是不接受这种行为的。我觉得对一门语言而言，几乎所有特性都应该是一致的，不应该或尽量少地出现这种“例外“。如果我构造一个对象，让它以不同的方式被构造，这和改变它的某个行为有什么区别？（从这句话来看，似乎还真有区别）当然，从语言实现来看，这样的运行结果又似乎是必然的。因为，基类的构造是早于派生类的（作为其一部分），只有当构造完派生类后，其用于支持多态的虚表才会被正确构造。也就是说，在基类中调用虚函数时，既然虚表都为正确构造，自然调用的不会是派生类的虚函数了。析构函数按照析构的顺序来看，也会面临同样的情况。UPDATE因为我接触了很多编程语言，2010年之前甚至是C++的重度粉，在学习各种编程语言的过程中我领略到语言设计里的很多艺术及美感，以及各种妥协。遗憾的是我不能站在更高的计算机程序语言理论层面评论这些语言。所以，对于本文描述的问题，我并不需要找到C++ language manual里某section里提到的standard。我想从语言设计者的角度来考虑这个问题。语言设计者需要让语言的设计思想贯穿整个语言的设计，而同时也需要考虑到语言实现的可行性。lisp虽然我觉得易用性是个问题，但它的设计是非常统一的：所有操作符都被视作函数，它们同函数拥有相同的语法；lisp的编译器实现也是相对容易的，因为前缀表达式基本就是语法树。erlang的基础API设计得非常糟糕，因为其API原型很不一致。派生类用于扩展基类功能，同时依赖了基类。所以如果在基类构造函数中可以多态地调用到派生类里的函数，那必然会引起问题：Base::Base() { init(); // if we called Derived::init init io }Derived::init() { use base io file descriptor etc}这个结论其实我之前已经说过析构函数面临相同的问题：Base::~Base() { release();}Derived::~Derived() { release my io file descriptor etc} // Base::~Base will be called Derived::release() { use my io file descriptor}从语言设计角度，派生类就是可以在任意地方使用基类的东西，这也是为什么基类构造函数要先于派生类构造函数调用的很大原因。另一方面，一个类在自己的任意地方使用自己的东西也是很自然的事情。上面的代码都再自然不过，但是语言设计者如果设定这里的多态要起作用，那这些代码将非常危险。" }, { "title": "C++陷阱：virtual析构函数", "url": "/posts/c-plus-plus-virtual-destructor/", "categories": "c/c++", "tags": "c/c++, destructor, virtual", "date": "2012-09-13 17:03:00 +0800", "snippet": "有一天有个同事在通过vld调试一个内存泄漏问题，折腾了很久然后找到我。我瞥了一眼他的代码，发现问题和我曾经遇到的一模一样：class Base {public: ~Base();};class Derived : public Base {privated: std::vector&lt;int&gt; m_data; };Base *obj = new Derived();delete obj;当然，实际代码比这个复杂得多(这也是导致从发现问题到找到问题耗费大量时间的原因)。vld在报内存泄漏时，当然报的位置是new的地方。这个同事检查了这个对象的整个生命周期，确定他正确地释放了这个对象。问题的关键就在于：Base类的析构函数不是virtual的。因为不是virtual，所以在对一个Base类型的指针进行delete时，就不会调用到派生类Derived的析构函数。而派生类里的析构函数会用于析构其内部的子对象，也就是这里的m_data。这样，就造成了内存泄漏。这其实是一个很低级的失误。但毫不客气地说C++中有很多这种少个关键字或者代码位置不对就会造成另一个结果的例子。事实上，针对这些悲剧也有很多书提出一些准则来让大家去无脑遵守。例如针对这个例子，我就记得曾有书说，只要你觉得你的类会被继承，那么最好给析构函数加上virtual。" }, { "title": "Octopress中的SEO", "url": "/posts/octopress-seo/", "categories": "tips", "tags": "tips, octopress", "date": "2012-09-06 19:02:00 +0800", "snippet": "来自SEO for OctopressOctopress默认为每个页面添加meta description，其内容为当前文章的前150个字符，如果是首页就会是第一篇文章的前150个字符。这里主要通过增加meta keywords来提高SEO。为每篇文章增加keywors和description就像我的这篇博客，这下文章头得填很多数据了，有点麻烦：---layout: posttitle: \"Octopress中的SEO\"date: 2012-09-06 19:02comments: truecategories: tipstags: [tips, octopress]keywords: seo, octopressdescription: Octopress默认为每个页面添加`meta description`，其内容为当前文章的前150个字符，如果是首页就会是第一篇文章的前150个字符。这里主要通过增加`meta keywords`来提高SEO。---这样，每篇文章页面头就会自动增加meta keywords项，description也会使用这里填的，而不是自动为文章前若干个字符。这个功能的实现在_includes/head.html中。&lt;meta name=\"author\" content=\"Kevin Lynx\"&gt; &lt;meta name=\"description\" content=\" Octopress默认为每个页面添加`meta description`，其内容为当前文章的前150个字符，如果是首页就会是第一篇文章的前150个字符。这里主要通过增加`meta keywords`来提高SEO。 \"&gt; &lt;meta name=\"keywords\" content=\"seo, octopress\"&gt; 为页面(Page)增加keywords上面只是修正了每篇博客页面的meta信息，octopress中还有几个页面需要修正，例如首页，这个可以通过修改_includes/head.html来完成。替换相关内容为以下：&lt;meta name=\"author\" content=\"{{ site.author }}\"&gt;{% capture description %}{% if page.description %}{{ page.description }}{% elsif site.description %}{{ site.description }}{%else%}{{ content | raw_content }}{% endif %}{% endcapture %}&lt;meta name=\"description\" content=\"{{ description | strip_html | condense_spaces | truncate:150 }}\"&gt;{% if page.keywords %}&lt;meta name=\"keywords\" content=\"{{ page.keywords }}\"&gt;{%else%}&lt;meta name=\"keywords\" content=\"{{ site.keywords }}\"&gt;{% endif %}如果页面没有提供keywords或者description的话，就使用site里的设置，也就需要修改_config.yml：description: loop in codes, Kevin Lynx blogkeywords: c/c++, mmo, game develop, lisp, ruby, lua, web development" }, { "title": "c/c++中几种操作位的方法", "url": "/posts/bit-operation-in-c-slash-c-plus-plus/", "categories": "tips, c/c++", "tags": "tips, c/c++", "date": "2012-09-04 19:49:00 +0800", "snippet": "参考How do you set, clear and toggle a single bit in C?c/c++中对二进制位的操作包括设置某位为1、清除某位（置为0）、开关某位(toggling a bit)、检查某位是否为1等。这些操作较为常见并且可以作为其他位运算的基础接口，以下罗列几种方法：传统方法 设置某位为1number |= 1 &lt;&lt; x; // 设置第x位为1 清除某位number &amp;= ~(1 &lt;&lt; x); // 置第x位为0 开关某位number ^= 1 &lt;&lt; x; 检查某位if (number &amp; (1 &lt;&lt; x))相应地我们可以将其封装起来，简便的方法是使用宏来封装：#define BIT_SET(a,b) ((a) |= (1&lt;&lt;(b)))#define BIT_CLEAR(a,b) ((a) &amp;= ~(1&lt;&lt;(b)))#define BIT_FLIP(a,b) ((a) ^= (1&lt;&lt;(b)))#define BIT_CHECK(a,b) ((a) &amp; (1&lt;&lt;(b)))使用位结构操作这个使用起来简单很多：struct bits { unsigned int a:1; unsigned int b:1; unsigned int c:1;};struct bits mybits;// set/clear a bitmybits.b = 1;mybits.c = 0;// toggle a bitmybits.a = !mybits.a;mybits.b = ~mybits.b;mybits.c ^= 1;// check a bitif (mybits.c)使用STL的std::bitset这个方法其实类似于使用位结构，只不过STL包装了这个结构定义，当然还提供了很多便捷的接口：std::bitset&lt;5&gt; bits;bits[0] = true;bits[1] = false;bits.set(2);bits.flip(3);bits.reset(2);" }, { "title": "c/c++中的-->运算符", "url": "/posts/goes-to-operator/", "categories": "tips, c/c++", "tags": "tips", "date": "2012-09-03 15:14:00 +0800", "snippet": "参考What is the name of this operator: “–&gt;”?c/c++中以下代码是合法的：#include &lt;stdio.h&gt;int main(){ int x = 10; while( x --&gt; 0 ) // x goes to 0 { printf(\"%d \", x); }}--&gt;是一个合法的操作符，我打赌自认c/c++熟手的你们都不知道这个操作符。有人称它为goes to操作符，x--&gt;0表示x向0趋近。其实我在忽悠你们。 并且我相信有很多人对此把戏相当熟悉。没错，--&gt;只是两个操作符恰好遇在了一起，他们是自减运算符--和大于比较运算符&gt;：while (x-- &gt; 0) ...类似的把戏还有：while (x -- \\ \\ \\ \\ &gt; 0) printf(\"%d \", x);" }, { "title": "为什么处理排序的数组要比非排序的快？", "url": "/posts/branch-predictor/", "categories": "c/c++, other", "tags": "branck predictor, c/c++", "date": "2012-08-29 19:55:00 +0800", "snippet": "参考Why is processing a sorted array faster than an unsorted array?问题看以下代码：#include &lt;algorithm&gt;#include &lt;ctime&gt;#include &lt;iostream&gt;int main(){ // generate data const unsigned arraySize = 32768; int data[arraySize]; for (unsigned c = 0; c &lt; arraySize; ++c) data[c] = std::rand() % 256; // !!! with this, the next loop runs faster std::sort(data, data + arraySize); // test clock_t start = clock(); long long sum = 0; for (unsigned i = 0; i &lt; 100000; ++i) { // primary loop for (unsigned c = 0; c &lt; arraySize; ++c) { if (data[c] &gt;= 128) sum += data[c]; } } double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC; std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl; std::cout &lt;&lt; \"sum = \" &lt;&lt; sum &lt;&lt; std::endl;}问题就在于，去掉std::sort那一行，以上代码将运行更长的时间。在我的机器上未去掉std::sort耗时8.99s，去掉后耗时24.78s。编译器使用的是gcc4.4.3。事实上，以上代码跟编译器没有关系，甚至跟语言没有关系。那这是为什么呢？这跟处理这个数组的逻辑有非常大的关系。如以上代码所示，这个循环里有个条件判断。条件判断被编译成二进制代码后，就是一个跳转指令，类似：jl SHORT $LN3@main具体为什么会不同，这涉及到计算机CPU执行指令时的行为。CPU的流水线指令执行想象现在有一堆指令等待CPU去执行，那么CPU是如何执行的呢？具体的细节可以找一本计算机组成原理的书来看。CPU执行一堆指令时，并不是单纯地一条一条取出来执行，而是按照一种流水线的方式，在CPU真正执行一条指令前，这条指令就像工厂里流水线生产的产品一样，已经被经过一些处理。简单来说，一条指令可能经过这些过程：取指(Fetch)、解码(Decode)、执行(Execute)、放回(Write-back)。假设现在有指令序列ABCDEFG。当CPU正在执行(execute)指令A时，CPU的其他处理单元（CPU是由若干部件构成的）其实已经预先处理到了指令A后面的指令，例如B可能已经被解码，C已经被取指。这就是流水线执行，这可以保证CPU高效地执行指令。Branch Prediction如上所说，CPU在执行一堆顺序执行的指令时，因为对于执行指令的部件来说，其基本不需要等待，因为诸如取指、解码这些过程早就被做了。但是，当CPU面临非顺序执行的指令序列时，例如之前提到的跳转指令，情况会怎样呢？取指、解码这些CPU单元并不知道程序流程会跳转，只有当CPU执行到跳转指令本身时，才知道该不该跳转。所以，取指解码这些单元就会继续取跳转指令之后的指令。当CPU执行到跳转指令时，如果真的发生了跳转，那么之前的预处理（取指、解码）就白做了。这个时候，CPU得从跳转目标处临时取指、解码，然后才开始执行，这意味着：CPU停了若干个时钟周期！这其实是个问题，如果CPU的设计放任这个问题，那么其速度就很难提升起来。为此，人们发明了一种技术，称为branch prediction，也就是分支预测。分支预测的作用，就是预测某个跳转指令是否会跳转。而CPU就根据自己的预测到目标地址取指令。这样，即可从一定程度提高运行速度。当然，分支预测在实现上有很多方法。简单的预测可以直接使用之前的实际执行结果。例如某个跳转指令某一次产生了跳转，那么下一次执行该指令时，CPU就直接从跳转目标地址处取指，而不是该跳转指令的下一条指令。答案了解了以上信息后，文章开头提出的问题就可以解释了。这个代码中有一个循环，这个循环里有一个条件判断。每一次CPU执行这个条件判断时，CPU都可能跳转到循环开始处的指令，即不执行if后的指令。使用分支预测技术，当处理已经排序的数组时，在若干次data[c]&gt;=128都不成立时（或第一次不成立时，取决于分支预测的实现），CPU预测这个分支是始终会跳转到循环开始的指令时，这个时候CPU将保持有效的执行，不需要重新等待到新的地址取指；同样，当data[c]&gt;=128条件成立若干次后，CPU也可以预测这个分支是不必跳转的，那么这个时候CPU也可以保持高效执行。相反，如果是无序的数组，CPU的分支预测在很大程度上都无法预测成功，基本就是50%的预测成功概率，这将消耗大量的时间，因为CPU很多时间都会等待取指单元重新取指。本文完。最后感叹下stackoverflow上这个帖子里那个老外回答问题的专业性，我要是楼主早就感动得涕泪横飞了。感谢每一个传播知识的人。参考资料 http://blog.sina.com.cn/s/blog_6c673e570100zfmo.html http://www.cnblogs.com/dongliqian/archive/2012/04/05/2433847.html http://en.wikipedia.org/wiki/Branch_predictor" }, { "title": "Null Object模式", "url": "/posts/null-object-pattern/", "categories": "tips, c/c++", "tags": "tips, c/c++", "date": "2012-08-29 15:57:00 +0800", "snippet": "Null Object模式用于代替空指针（C++中），以避免上层模块对返回值做空值判定。Null Object模式返回的不是一个空指针，而是一个空对象，上层模块对返回值做操作时，不需要做空判定，而是按正常逻辑调用这个对象的某个接口，只不过对于空对象而言，这个接口什么事也没做，例如：class animal {public: virtual void make_sound() = 0;}; class dog : public animal { void make_sound() { cout &lt;&lt; \"woof!\" &lt;&lt; endl; }}; class null_animal : public animal { void make_sound() { }};在我看来这个模式在C++中其实挺扯淡的，因为去判断一个指针是否为NULL，远比创建一个空类，并且添加若干个空函数代价小更多。更何况，我们还不知道null_animal的生命周期如何管理。但是在我以往写的代码中，我也写过一些避免空指针判定的代码，例如我会使用引用。注意，引用肯定不能保证所对应的对象是合法的，这就像无法确定一个指针是不是野指针一样：const Item &amp;Container::FindItem(int id) const { static Item null_item; Table::const_iterator it = m_items.find(id); return it == m_items.end() ? null_item : it-&gt;second;}参考http://en.wikipedia.org/wiki/Null_Object_pattern" }, { "title": "MMO聊天服务器设计", "url": "/posts/mmo-chat-server/", "categories": "game develop", "tags": "mmo, chat server", "date": "2012-08-29 09:54:00 +0800", "snippet": "MMO中的聊天服务主要功能就是做客户端之间的聊天内容转发。但是聊天的形式有很多，例如私聊、同场景聊、队伍内聊、工会内聊、全服务器聊、甚至临时组建房间聊。这些逻辑功能其实都是可以做在逻辑服务器上的，最多改改世界服务器，但是这样完成功能的话，不免将聊天本身的逻辑与游戏逻辑关联起来。我们希望做得更上一层，将聊天服务本身脱离开来。但是独立聊天服务还不够，因为就算独立出来了，也有可能在实现上与具体的游戏逻辑相关联。所以，我们做了进一步的抽象，想实现一个更为通用的聊天服务器。设计实现实体设计聊天这个过程，我们将其抽象为实体(entity)与实体间的对话。这个实体概念其实很宽泛。任何可接收聊天消息的都算做实体，例如单个玩家、一个场景、一个队伍、一个房间、一个工会、甚至整个服务器。这个思想其实就是支持整个聊天服务器设计的最根本思想。最开始，我将聊天服务器分为个体和组两个概念，其实这个抽象程度都太低，并且会导致实现上的复杂。相反，将整个系统完全使用实体这个概念来组装，就简单很多。当然，实体是有很多种类的，在处理接收聊天消息这个动作时，其处理方式就不同。例如单个玩家实体仅做消息的发送，场景实体则是将消息发给场景内的所有玩家，队伍实体就是将消息发给队伍内的所有玩家。从这一点来看，我们的实体种类其实并不多，因为场景、队伍这些，都是组实体(group entity)。用C++来描述：class Entity {public: // send text to this entity virtual bool Send(Entity *sender, const std::string &amp;text) = 0;protected: GUID m_id; int m_type;};class SockEntity : pubilc Entity {public: virtual bool Send(Entity *sender, const std::string &amp;text) { // find the map socket and send text to the socket long socket = FindSocket(this); Message msg(MSG_CS2E_SENDTEXT); msg.Add(sender-&gt;ID()); msg.Add(text); msg.SendToSocket(socket); return true; }};class GroupEntity : public Entity {public: virtual bool Send(Entity *sender, const std::string &amp;text) { for (std::list&lt;Entity*&gt;::const_iterator it = m_mems.begin(); it != m_mems.end(); ++it) { (*it)-&gt;Send(sender, text); } return true; }private: std::list&lt;Entity*&gt; m_mems;};SockEntity用于表示物理上聊天服务器的客户端，例如游戏客户端。网络拓扑实际上，除了转发聊天内容外(Entity::Send)，实体还有很多其他行为，例如最起码的，创建组实体，往组实体里添加成员等。在设计上，组实体的创建由逻辑服务器或者其他服务器来完成，目前游戏客户端是没有创建组实体的权限的（实现上我们还为实体添加了权限验证机制）。在网络拓扑上，聊天服务器始终是作为服务器角色，而它的客户端则包括游戏客户端、逻辑服务器、甚至其他服务器，这样聊天服务器在提供了固定的协议后，它就是完全独立的，不依赖任何其他组件： CS / | \\ / | \\ / | \\ GC GC GS(CS: Chat Server, GC: Game Client, GS: Game Server)基于此，我们扩充了Entity的类体系：class ClientEntity : public SockEntity {private: GUID m_gsEntity; // 标示该客户端实体位于哪个逻辑服务器实体上};class GSEntity : public SockEntity {};消息协议聊天服务器的核心实现，其实就是针对以上实体做操作。因此，聊天服务器的消息协议方面，也主要是针对这些实体的操作，包括： 创建 实体的创建很简单，不同的实体其创建所需的参数都不一样。例如客户端实体创建时需要传入一个逻辑服务器实体的ID，组实体的创建可以携带组成员实体列表。为了处理权限和安全问题，在具体实现上，逻辑服务器实体的创建是由聊天服务器本地的配置决定，即聊天服务器启动则根据配置创建好逻辑服务器实体；客户端实体是当角色进入逻辑服务器后，由服务器创建，客户端无法创建实体。 删除 实体的删除为了处理方便，约定删除请求必须由实体的创建者发起。因为从逻辑上将，某个模块如果可以创建一个实体，那么其必然知道什么时候该删除这个实体。 修改 修改指的是修改实体内部实现的一些属性，例如组实体修改其组成员。这个操作是非常重要的。对于SockEntity而言，修改意味着修改其连接状态，例如当逻辑服务器在聊天服务器上创建了客户端实体后，实际上此时客户端并没有在网络方面连接聊天服务器，此时这个Entity实际上是不可用的，因为它无法用于发送消息。这个时候我们标志该实体的状态为非连接状态。当客户端主动连接上聊天服务器后，客户端就主动发起修改自己对应的客户端实体请求，该请求将自己的状态修改为连接状态。当客户端关闭时，聊天服务器网络层接收到连接断开通知，该通知肯定是早于逻辑服务器发来的删除实体通知的，此时将该客户端实体状态修改为断开状态，并在接收到逻辑服务器删除实体通知时将其真正删除。这里展示的这种状态修改策略，实际上在整个系统中是非常重要的。它用于指导网络连接和上层逻辑之间的关系，因为整个聊天系统中，各个进程的状态是不可预料的（随时可能宕掉），当某个进程尤其是逻辑服务器宕掉后，聊天服务器是得不到任何正常逻辑通知的，它只能得到网络连接的通知。 总结整个系统实现下来，实际上是非常简单的，代码量也很少。当然还有很多细节问题，例如聊天信息中携带物品信息，这涉及到异步预处理聊天内容，这里就不方便细说了。" }, { "title": "C++11中lambda概览", "url": "/posts/c-plus-plus-11-lambda-overview/", "categories": "tips, c/c++", "tags": "tips, c/c++", "date": "2012-08-21 16:44:00 +0800", "snippet": "虽然我对C++11没有什么兴趣，因为C++03就已经有很多复杂的技术了。我曾经试图把我学到的那些复杂的C++技术应用到项目中，但悲剧地发现这给团队其他成员带来了不小的负担。其实也给未来一段时间的自己带来了不小的负担。尤其是template的应用，template代码从外表上就一副唬人的样子，就像即使你会Lisp，并且对Lisp中的括号不以为然，但看到满屏幕的括号时依然内心不安。但是稍微对C++11的一些特性做了解后，单从理论上来说，还是挺让人有兴趣的。我感觉C++11加入了不少函数式语言的特性和思想，这是我感兴趣的最大理由。今天来看看C++11中的lambda。C++03中，在使用STL容器时，或者我自己写的类中，常有遍历的需求，本来写个functor传进去就可以，但是这functor偏偏写的很恶心。因为你需要局部定义一个结构体，重载operator()，并且，如果这个operator()依赖这个functor构建时的上下文信息，你得往这个结构体里塞入若干成员，当然还得让构造函数的参数变得越来越长。最后，在包含你这个functor使用以及结构体定义的这个代码块中，在其代码格式上就变得非常奇怪。如果你像我一样常这样应用，一定深有感触。然后，C++11来了，C++11中的lambda，就我个人而言，其语法还是非常现代的。来看看其文法形式（截自N2550）：lambda-expression: lambda-introducer lambda-parameter-declaration compound-statementlambda-introducer: [ lambda-capture ]lambda-capture: capture-default capture-list capture-default , capture-listcapture-default: &amp; =capture-list: capture capture-list , capturecapture: identifier &amp; identifier thislambda-parameter-declaration: ( lambda-parameter-declaration-list ) exception-specification lambda-return-type-clauselambda-parameter-declaration-list: lambda-parameter lambda-parameter , lambda-parameter-declaration-listlambda-parameter: decl-specifier-seq declaratorlambda-return-type-clause: -&gt; type-id翻译过来大致就是这样的形式：[capture] (parameter) spec -&gt;return-type { body }capture就是这个lambda实现里可以访问的这个lambda定义时作用域里的变量列表，就像Lua里的upvalue。其实我觉得这个才是lambda最方便程序员的地方，一般的函数式语言其实不需要显示声明这个列表，直接引用这些变量即可。后面的部分都比较好理解，parameter就是这个lambda被调用时的形参列表，return-type就是这个lambda的返回值类型，body自然就是这个lambda的实现。至于spec，主要就是指定异常及body里对capture里的变量的使用权限。一个例子：vector&lt;int&gt; ints;ints.push_back(99);ints.push_back(100);ints.push_back(101);int threhold = 100;int sum = 0;for_each(ints.begin(), ints.end(), [threhold, &amp;sum] (int v) { if (v &gt;= threhold) ++ sum; });printf(\"%d\\n\", sum);capture使用了threhold和sum，但是threhold仅使用其值，而sum则使用了其引用，通过结果可以看出lambda中改变了sum的值。C++11正在被越来越多的编译器支持，也慢慢地支持得更好。这里有个表，罗列了C++11的各个特性在各个编译器上的支持情况，仅供查阅（以上示例代码测试于vs2010，即MSVC10.0）。" }, { "title": "使用memcmp比较两个变量结果一定吗？", "url": "/posts/memcmp-on-copy-value/", "categories": "tips, c/c++", "tags": "tips, c/c++", "date": "2012-08-17 11:37:00 +0800", "snippet": "参考Is using memcmp on array of int strictly conforming?以下代码一定会输出ok吗？#include &lt;stdio.h&gt;#include &lt;string.h&gt;struct S { int array[2]; };int main () { struct S a = { { 1, 2 } }; struct S b; b = a; if (memcmp(b.array, a.array, sizeof(b.array)) == 0) { puts(\"ok\"); } return 0;}我在vs2005以及gcc4.4.3上做了测试，都输出了ok。但这并不意味这个代码会永远输出ok。问题主要集中于这里使用了赋值语句来复制值，但却使用了memcmp这个基于内存数据比较的函数来比较值。c语言中的赋值运算符（=）被定义为基于值的复制，而不是基于内存内容的复制。 C99 section 6.5.16.1 p2: In simple assignment (=), the value of the right operand is converted to the type of the assignment expression and replaces the value stored in the object designated by the left operand.这个其实很好理解，尤其在不同类型的数字类型间复制时，例如：float a = 1.1;int b = a;因为浮点数和整形数的内存布局不一样，所以肯定是基于值的一种复制。另外，按照语言标准的思路来看，内存布局这种东西一般都属于实现相关的，所以语言标准是不会依赖实现去定义语言的。上面的定理同样用于复杂数据类型，例如结构体。我们都知道结构体每个成员之间可能会有字节补齐，而使用赋值运算符来复制时，会不会复制这些补齐字节的内容，是语言标准未规定的。这意味着使用memcmp比较两个通过赋值运算符复制的两个结构体时，其结果是未定的。但是上面的代码例子中，比较的其实是两个int数组。这也无法确认结果吗？这个问题最终集中于，难道int也会有不确定的补齐字节数据？ C99 6.2.6.2 integer types For signed integer types, the bits of the object representation shall be divided into three groups: value bits, padding bits, and the sign bit. […] The values of any padding bits are unspecified.这话其实我也不太懂。一个有符号整数int，其内也有补齐二进制位(bits)？但无论如何，这个例子都不算严谨的代码。人们的建议是使用memcpy来复制这种数据，因为memcpy和memcmp都是基于内存内容来工作的。" }, { "title": "Lisp中定义变量*var*和var有什么不同？", "url": "/posts/dynamic-scope-in-lisp/", "categories": "lisp", "tags": "lisp", "date": "2012-08-14 15:53:00 +0800", "snippet": "参考What’s difference between var and var when using defvar?其实，Common Lisp中使用defvar定义变量加不加星号没有区别。这只是一种Lisp程序员的约定。Lisp中并不使用特定的符号来影响语法元素，例如Ruby中通过给变量添加@前缀来标示该变量为类成员变量。这个问题引出了lisp总dynamic scope这个话题。Lisp中变量分为两种，分别为lexical和special。这两种不同的变量有不同的作用域(scope)：词法作用域(lexical scope)和动态作用域(dynamic scope)。special variables通过defvar/defparameter/declare来定义。而lexical variables通常在let中定义。这两种作用域有什么不同呢？引用&lt;ANSI Common Lisp&gt;里说的： Under lexical scope, a symbol refers to the variable that has that name in the context where the symbol appears (define) With dynamic scope, we look for a variable in the environment where the function is called, not in the environment where it was defined.所以：(defvar b 3)(defun add-to-b (x) (+ x b))(add-to-b 1) =&gt; 4(let ((b 4)) (list (add-to-b 1) b))=&gt; (5 4)(let ((a 3)) (defun add-to-a (x) (+ x a)))(add-to-a 1) =&gt; 4(let ((a 4)) (list (add-to-a 1) a))=&gt; (4 4)add-to-b这个函数中使用的变量b是special variable，所以在调用add-to-b时，取的就是调用(called)这个函数时环境中的变量，所以：(let ((b 4)) (list (add-to-b 1) b))=&gt; (5 4)取的就是let中临时出现的b。而add-to-a这个函数中使用的变量a是lexical variable，所以调用这个函数时，取的就是这个函数定义(defined)时的a，所以无论在哪里调用add-to-a，都是取的：(let ((a 3)) (defun add-to-a (x) (+ x a)))这里的a，也就是一直是3。" }, { "title": "Lua中动态产生函数", "url": "/posts/dynamic-method-in-lua/", "categories": "tips, lua", "tags": "tips, lua", "date": "2012-08-13 15:56:00 +0800", "snippet": "可以结合Lua里实现简单的类-对象看。在我的应用中，存在类似以下代码：function Item.new() local o = { property = {} } return newObject(o, Item)endproperty是一个key-value的表，里面的内容不是固定的。最开始我为Item类写了get/set函数，用于存取property表里的值。但这样写起来还是有点麻烦。Ruby里可以动态产生类成员函数，其实Lua里也可以。其思路就是通过metatable来做：-- 为newObject增加一个可选参数，该参数是一个函数，当在表示类的table里无法找到成员时就调用该可选参数function newObject(o, class, after) class.__index = function (self, key) return class[key] or after(self, key) end return setmetatable(o, class)end然后就是编写这个after函数，我的理想方式是，例如property里有Name和Index的key-value，那么就可以通过这样的方式来存取：item = Item.new()print(item:Name())item:SetName(\"hello\")print(item:Index()item:SetIndex(101)after函数的实现：function Item.new() local o = { property = {} } local function after(self, key) local name = string.match(key, \"Set(%a+)\") if name then return function (self, value) self:set(name, value) end else return function (self) return self.property[key] and self.property[key].value end end end return newObject(o, Item, after)end执行过程就为： 当item:Name()执行时，首先试图获取Item上的Name成员，没找到就调用传入的after函数，这个函数检查Name这个字符串是否是SetXX的形式，如果不是则返回一个获取函数；这个时候取得Name成员，然后将其作为函数调用，相当于调用了after刚才返回的函数 item:SetName(“hello”)过程类似，只不过调用了另一个返回函数。" }, { "title": "Ruby应用几则（解析HTML、XMLRPC）", "url": "/posts/ruby-usage-example/", "categories": "tips, ruby", "tags": "tips, ruby, nokogiri", "date": "2012-08-09 14:26:00 +0800", "snippet": "Ruby解析HTMLRuby解析HTML（或XML）可以使用nokogiri。我的应用里需要查找HTML页面里的某个元素，结果发现实现方式非常简单，就像使用jquery一样。例如我要获取到octopress博客文章里的文章内容、文章标题、文章分类，就像这篇博客：# get post title and content for an octopress postdef post_info(url) doc = Nokogiri::HTML(open(url)) content = doc.css('div.entry-content').to_s title = doc.css('header h1.entry-title').inner_html categories = doc.css('a.category').collect do |link| link.content end return title, content, categoriesend最关键就是doc.css('div.entry-content')。想起以前用lisp写的那个版本，还手工遍历了整个HTML页面，实在太落后了。上面这个函数的作用就是取得一篇博文的HTML页面，然后返回该博文的内容、标题和分类。Ruby调用xml-rpc可以使用rails-xmlrpc这个库，直接使用gem安装：gem install rails-xmlrpc。这个库分为客户端和服务器两部分，我的应用是使用metaweblog API：class MetaWeblogClient &lt; XMLRPC::Client def initialize(username, password, host, url) super(host, url) @username = username @password = password end def newPost(post, publish) call(\"metaWeblog.newPost\", \"0\", \"#{@username}\", \"#{@password}\", post, publish) end # other methodsenddef new_post(api, url) title, content, categories = post_info(url) if title.nil? or content.nil? puts \"get post info failed at #{url}\\n\" return end post = { :title =&gt; title, :description =&gt; content, :categories =&gt; categories } api.newPost(post, true) puts \"new post #{title} in #{categories} done\\n\"endapi = MetaweblogClient.new(username, password, host, url)new_post(api, \"http://codemacro.com/2012/08/07/write-standalone-ruby-script/\")Ruby读取yaml就像Rails里那些配置文件一样，都属于yaml配置文件。我的应用里只需使用简单的key-value形式的yaml配置，就像：host: www.cppblog.comurl: /kevinlynx/services/metaweblog.aspxusername: kevinlynxpassword: xxxxxx解析的时候需要使用yaml库：file = File.open(filename)cfg = YAML::load(file)针对以上配置，YAML::load得到的结果就是一个hash表：puts cfg[\"host\"]puts cfg[\"url\"]以上，我写了一个小工具，可以让我每次在codemacro.com发表博客后，使用这个工具自动解析生成的文章，然后发表到CPPBLOG上。完整源码可在这个上：https://gist.github.com/3301662" }, { "title": "编写独立的Ruby脚本", "url": "/posts/write-standalone-ruby-script/", "categories": "tips, ruby", "tags": "tips, ruby", "date": "2012-08-07 14:33:00 +0800", "snippet": "Ruby肯定不仅仅用于编写Rails程序。要使用Ruby编写独立的脚本/程序，就像shell一样，其方式也很简单：#!/usr/bin/env rubyif ARGV.size == 0 puts 'usage: program arg1 arg2' exitendARGV.each do |arg| print arg end脚本内容没有什么限制，函数、类、模块的组织方式也随意。ARGV是一个特殊的变量，是一个数组，其内保存了传入脚本的参数，不包含程序名。当然，不要忘记给脚本加上可执行权限。" }, { "title": "让wxListCtrl支持子item编辑", "url": "/posts/edit-item-wxlistctrl/", "categories": "tips, lua", "tags": "tips, lua, wxLua", "date": "2012-08-07 13:48:00 +0800", "snippet": "我使用的wxLua版本信息为wxLua 2.8.7.0 built with wxWidgets 2.8.8，也就是LuaForWindows_v5.1.4-40.exe这个安装包里自带的wxLua。我不知道其他wxWidgets版本里wxListCtrl怎样，但我使用的版本里wxListCtrl是不支持编辑里面的子item的。在我使用的report模式下，子item也就是特定某一行一列的item。google了一下，发现悲剧地需要自己实现，主要就是自己显示一个wxTextCtrl：---- file: wxListCtrlTextEdit.lua-- author: Kevin Lynx-- date: 08.06.2012--local EditList = {}-- get the column by an abs pointfunction EditList:getColumn(x) local cols = self.listctrl:GetColumnCount() local cx = 0 for i = 0, cols - 1 do local w = self.listctrl:GetColumnWidth(i) if x &lt;= cx + w then return i end cx = cx + w end return -1end-- when a mouse down, show a text edit control function EditList:onLeftDown(evt) if self.editor:IsShown() then self:closeEditor() end local p = evt:GetPoint() local row = evt:GetIndex() local col = self:getColumn(p.x) local rect = wx.wxListCtrlEx.GetSubItemRect(self.listctrl, row, col) rect:SetHeight(rect:GetHeight() + 5) -- adjust self.editor:SetSize(rect) self.editor:Show() self.editor:SetValue(wx.wxListCtrlEx.GetItemText(self.listctrl, row, col)) self.editor:SetFocus() self.col = col self.row = rowendfunction EditList:closeEditor() if not self.editor:IsShown() then return end self.editor:Hide() self.listctrl:SetItem(self.row, self.col, self.editor:GetValue())endfunction EditList:initialize() self.editor = wx.wxTextCtrl(self.listctrl, wx.wxID_ANY, \"\", wx.wxDefaultPosition, wx.wxDefaultSize, wx.wxTE_PROCESS_ENTER + wx.wxTE_RICH2) self.editor:Connect(wx.wxEVT_COMMAND_TEXT_ENTER, function () self:closeEditor() end) -- not work actually self.editor:Connect(wx.wxEVT_COMMAND_KILL_FOCUS, function () self:closeEditor() end) self.editor:Hide()endfunction wx.wxListCtrlTextEdit(listctrl) local o = { listctrl = listctrl, editor = nil, } local editlist = newObject(o, EditList) editlist:initialize() listctrl:Connect(wx.wxEVT_COMMAND_LIST_ITEM_RIGHT_CLICK, function (evt) editlist:onLeftDown(evt) end) listctrl:Connect(wx.wxEVT_COMMAND_LIST_ITEM_FOCUSED, function () editlist:closeEditor() end) return listctrlend其原理就是获取到当前鼠标点击所在的子item位置，然后在此位置显示一个wxEditCtrl即可。以上代码需要依赖我之前写的Lua里实现简单的类-对象中的代码，同时依赖以下针对wxListCtrl的扩展接口：---- file: wxListCtrlExtend.lua-- author: Kevin Lynx-- date: 08.07.2012-- brief: extend some util functions to wx.wxListCtrl-- wx.wxListCtrlEx = {}function wx.wxListCtrlEx.GetSubItemRect(listctrl, item, col) local rect = wx.wxRect() listctrl:GetItemRect(item, rect) local x = 0 local w = 0 for i = 0, col do w = listctrl:GetColumnWidth(i) x = x + w end return wx.wxRect(x - w, rect:GetY(), w, rect:GetHeight())endfunction wx.wxListCtrlEx.GetItemText(listctrl, item, col) local info = wx.wxListItem() info:SetId(item) info:SetColumn(col) info:SetMask(wx.wxLIST_MASK_TEXT) listctrl:GetItem(info) return info:GetText()end在我看到的wxWidgets官方文档里，其实wxListCtrl已经有GetSubItemRect接口，并且在另一些示例代码里，也看到了GetItemText接口，但是，我使用的版本里没有，所以只好自己写。基于以上，要使用这个可以支持编辑子item的wxListCtrl，可以：list = wx.wxListCtrlTextEdit(wx.wxListCtrl(dialog, wx.wxID_ANY, wx.wxDefaultPosition, wx.wxDefaultSize, wx.wxLC_REPORT))也就是通过wx.wxListCtrlTextEdit这个函数做下处理，这个函数返回的是本身的wxListCtrl。当然更好的方式是使用继承之类的方式，开发一种新的控件，但在Lua中，针对usedata类型的扩展貌似只能这样了。最好吐槽下，这个控件扩展其实很恶心。本来我打算当编辑控件失去焦点后就隐藏它，但是往编辑控件上注册KILL_FOCUS事件始终不起作用；我又打算弄个ESC键盘事件去手动取消，但显然wxTextCtrl是不支持键盘事件的。好吧，凑合用了。" }, { "title": "『你会把Ruby的哪些特性加入Java』", "url": "/posts/ruby-element-to-java/", "categories": "ruby", "tags": "ruby, java", "date": "2012-08-03 14:14:00 +0800", "snippet": "参考（翻译、摘抄）于Can Ruby Live without Rails?。这篇文章发表于2006年，受访者在回答“如果可以你会把Ruby的哪些特性加入Java“这个问题时，提到了Ruby的一些我个人认为比较突出的语法特性。其实并不是针对Java语言，何况6年时间过去，以Java语法特性的加入速度怕早就有Ruby这些特性了。我对Java不熟，仅限于曾经写的几个简单的android应用，买了&lt;Java编程思想&gt;也没翻完。以下内容半翻译自原文。Closure闭包支持将代码块作为函数参数传递。这在写很多代码时会比较方便，例如以下代码打印10次字符串：10.times { puts \"Hello\" }又例如针对数组的每个元素做一些事情（do…end是上例中{}的替代）：array.each do |item| item.do_somethingend也可以构建一个新的数组：array.collect { |number| number * number }Ruby中闭包的使用随处可见，它的语法形式太简单，这使得要使用它时所付出的代价很小（想想其他语言里得手动构造一个函数对象吧）。Continuation使用continuation你可以保存一块代码的执行状态，以便将来某个时刻恢复执行。这就像游戏存档一样，玩到一半存档，一段时间回来后取出存档从上次的进度继续玩。require 'continuation' # 原文中未给这句，须加上def loop for i in 1..10 puts i callcc { |c| return c } if i == 5 endendloop函数执行里面那个循环时，当i==5就调用callcc函数（貌似现在Java已有这个了），该函数在回调传入的闭包时构建了一个continuation对象，以上代码直接将此对象返回，循环暂停于i==5。执行代码continuation = loop输出：12345然后你可以在任意时刻恢复执行那个循环：continuation.call，得到：678910这个continuation和Lua里的coroutine很像，可以用于实现轻量级的线程。mix-ins这节没看懂。提到了AOP、POJO之类的术语，大概是Java世界里的什么东西。看起来像是针对before/after method的东西，意思就是执行某个函数时，会先去执行before函数，完了后再执行after函数，Lisp里有这个概念。Open class这个算是Ruby里用的比较多的特性。open classes可以让你在很多情况下“打开“并重定义某个类，这个类可以是你使用的任意库里的类。Ruby里的类并不是一个封闭的代码集合，作为一个类库的使用者你甚至可以不用修改类库的代码而重新定义、扩展里面的接口。例如Ruby中的数字其实就是Fixnum类，而我们可以为Fixnum直接添加更多的接口（原文的代码有问题，以下我做了修改）：class Fixnum def days self.hours * 24 end def hours self.minutes * 60 end def minutes self.seconds * 60 end def seconds self end def from_now Time.now + self end def ago Time.now - self endend基于以上，我们可以写出10.days.ago或者6.hours.from_now这样的代码。这有助于构建DSL(domain specific language)。Full object orientationRuby中一切都是对象。这让我们写代码变得更容易，因为不用处理特殊情况。这些特殊情况主要就是很多基础数据类型并非对象，但Ruby里是。Ruby里每个对象都有一个函数class，表示该对象的类型：1.class # =&gt; Fixnum2.5.class # = &gt; Float\"hello\".class # =&gt; String[1, 2].class # =&gt; Array(1..2).class # =&gt; Range全文完。" }, { "title": "Lua里实现简单的类-对象", "url": "/posts/simple-oo-in-lua/", "categories": "tips, lua", "tags": "tips, lua, rapanui, moai", "date": "2012-08-02 10:18:00 +0800", "snippet": "要在Lua里实现面向对象有很多方法，为了支持面向对象的一些特性（类、对象、继承、重载等），其实现可能会比较复杂。看看云风的这篇，以及后面的评论，有总结的不错的。这真是让人对Lua刮目相看。但是我并不需要这些机制，一般情况下我只需要支持类即可。类其实就是定义一个对象的函数模板，避免我写出带模块名并且第一个参数是操作对象的函数（像C一样）。以下代码提炼于rapanui（基于moai的高层封装），摘抄于几个月前我基于rapanui移植到android上的一个小游戏：local function newindex(self, key, value) getmetatable(self).__object[key] = valueendlocal function index(self, key) return getmetatable(self).__object[key]endfunction newObject(o, class) class.__index = class setmetatable(o, class) return setmetatable({}, { __newindex = newindex, __index = index, __object = o })end基于newObject函数，可以这样定义类：Button = {}function Button.new(text, x, y, onclick, parent) -- 定义这个类的数据成员 local obj = { text = text, onclick = onclick, normal_img = nil, text_inst = nil, hover_img = nil, } obj = newObject(obj, Button) ... return objendfunction Button:onTouchDown(x, y) ... -- 可以访问成员，即使看起来normal_img不属于Button这个table self.normal_img.visible = trueendfunction Button:onTouchUp(x, y) ...end通过以上定义后，就可以以面向对象的方式来使用Button类了：local btn = Button.new()btn:OnTouchDown(100, 100)btn:OnTouchUp(100, 100)其实现原理，主要就是将类的函数集通过__index开放给对象，在这些函数中，其self就像c++ 中的this一样拥有多态性，即其是创建出来的对象，而不是作为类角色的那个table（例如Button）。8.13.2012更新其实根本没必要这么复杂，newObject函数多引入了一个空表，实在看不出有什么作用，修改后的版本简单直接：function newObject(o, class) class.__index = class return setmetatable(o, class)end因为只需要将类定义的函数引入到实际对象里，使用方法相同。另外上文中提到的一句话： 在这些函数中，其self就像c++ 中的this一样拥有多态性，即其是创建出来的对象其实这是不对的，这个self应该就是触发这个metamethod的table，不具备什么多态性。" }, { "title": "像写函数式语言代码一样写C++", "url": "/posts/write-cpp-like-fp/", "categories": "tips, c/c++", "tags": "tips, c/c++", "date": "2012-07-30 17:11:00 +0800", "snippet": "忘记最早接触函数式编程语言是什么时候了，也忘记接触的第一门函数式语言是哪一门。断断续续接触过好几种函数式语言（当然都算不纯的，ruby/lisp不算纯吧），这些语言的思想在潜移默化中多多少少对我有所影响。我是个C++程序员，我不知道我平时写的都是些什么代码。最让人印象深刻就是我会经常写遍历STL容器的代码，是经常，这样的遍历你可能也不陌生：for (ListType::iterator it = con.begin(); it != con.end(); ++it) { something}或者针对std::map/set等的查找：Table::iterator it = table.find(key);if (it == table.end()) do-somethingdo-something多亏STL接口的一致性，这让我们写出了很多“一致性“代码。慢慢地我觉得恶心，不禁想起函数式编程语言中，对于这种需求一般都会提供类似的接口：con.map(function (it) if (it-&gt;some-filed == some-value) return something end)# 或者con.each do |it| if it.some-filed == some-value then return something end end# 或者(con.map (lambda (it) (if ((= it.some-filed some-value)) (return something))))（好吧，lisp我又忘了）总之，这种针对容器的遍历操作，都会成为一种内置接口，并且通过lambda来让用户直接编写处理代码，少去写循环的冗余。然后，我写了类似下面的一组宏（随手敲的不保证能运行）：#define IT_N __it#define TRAVERSE_MAP(type, map, exps) \\ for (type::iterator IT_N = map.begin(); IT_N != map.end(); ++IT_N) { \\ exps; \\ }#define I_KEY (IT_N-&gt;first)#define I_VALUE (IT_N-&gt;second)#define TRAVERSE_LIST(type, list, exps) \\ for (type::iterator IT_N = list.begin(); IT_N != list.end(); ++IT_N) { \\ exps; \\ }#define L_VALUE (*IT_N)#define FIND_MAP_ITEM(type, map, key, fexps, texps) \\ do { \\ type::iterator IT_N = map.find(key); \\ if (IT_N == map.end()) { \\ fexps; \\ } else { \\ texps; \\ } \\ } while(0)#define VAL_N __val#define FIND_LIST_ITEM_IF(type, list, cmp, fexps, texps) \\ do { \\ struct Comp { \\ bool operator() (const type::value_type &amp;VAL_N) const { \\ return cmp; \\ } \\ }; \\ type::iterator IT_N = std::find_if(list.begin(), list.end(), Comp()); \\ if (IT_N != list.end()) { \\ texps; \\ } else { \\ fexps; \\ } \\ } while(0)#define NULL_EXP ;当然，以上接口都还包含一些const版本，用于const容器的使用。使用的时候（截取的项目中的使用例子）：TRAVERSE_MAP(TimerTable, m_timers, I_VALUE.obj-&gt;OnTimerCancel(I_KEY, I_VALUE.arg); TIMER_CANCEL(I_VALUE.id)); TRAVERSE_LIST(AreaList, areas, ids.push_back(L_VALUE-&gt;ID()));FIND_MAP_ITEM(PropertyTable, m_properties, name, LogWarn(\"set a non-existed property %s\", name.c_str()); return NIL_VALUE, if (val.Type() != I_VALUE.type()) { return NIL_VALUE; } else { GValue old = I_VALUE; I_VALUE = val; return old; });多亏了C/C++宏对一切内容的可容纳性，可以让我往宏参数里塞进像if这种复合语句，甚至多条语句（例如最后一个例子）。这些宏我使用了一段时间，开始觉得挺爽，很多函数的实现里，我再也不用写那些重复的代码了。但是后来我发觉这些代码越来越恶心了。最大的弊端在于不可调试，我只能将断点下到更深的代码层；然后就是看起来特不直观，连作者自己都看得觉得不直观了，可想而知那些连函数式编程语言都不知道是什么的C++程序员看到这些代码会是什么心情（可以想象哥已经被诅咒了多少次）。函数式语言让人写出更短的代码，这一点也对我有影响，例如我最近又写下了一些邪恶代码：// split a string into several sub strings by a split character i.e:// \"a;b;c;\" =&gt; \"a\", \"b\", \"c\"// \"a;b;c\" =&gt; \"a\", \"b\", \"c\"std::vector&lt;std::string&gt; SplitString(const std::string &amp;str, char split) { std::vector&lt;std::string&gt; ret; size_t last = 0; for (size_t pos = str.find(split); pos != std::string::npos; last = pos + 1, pos = str.find(split, last)) { ret.push_back(str.substr(last, pos - last)); } return last &lt; str.length() ? ret.push_back(str.substr(last)) : 0, ret;}恶心的就是最后那条return语句，因为我需要处理”a;b;c”这种c后面没加分隔符的情况，但我并不愿意为了这个需求再写一个会占超过一行的if语句。因为，我太喜欢ruby里的if了：do-something if exp也就是ruby里允许这种只有一行if的代码将if放在其后并作为一条语句。我的不愿意其实是有理由的，在c/c++中有太多只有一行条件体的if语句，对这些语句参合进编程风格/可读性进来后，就不得不让你写出不安的代码，例如：if (something) return something; // 某些编程风格里不允许这样做，因为它不方便调试if (something) return something; // 某些风格里又有大括号的统一要求if (something) { return something; // 就算符合风格了，但这一条语句就得多个大括号}if (something) { return something; // 某些风格里这大括号就更奢侈了}这个return除了乍看上去有点纠结外，其实也不算什么大问题，但是那个问号表达式返回的0实在没有任何意义，而正是没有意义才会让它误导人。本来我是可以写成：return last &lt; str.length() &amp;&amp; ret.push_back(str.substr(last)), ret;这样利用条件表达式的短路运算，代码也清晰多了。但是，std::vector::push_back是一个没有返回值的函数，所以。全文完。" }, { "title": "为octopress每篇文章添加一个文章信息", "url": "/posts/post-footer-plugin-for-octopress/", "categories": "tips, other", "tags": "tips, octopress, blog", "date": "2012-07-26 14:27:00 +0800", "snippet": "当你的博客文章被转载时，你肯定希望转载者能添加一个原始地址。或者你的文章被各种RSS抓取器抓取时，你也希望能在明显的位置显示这个原始地址。使用octopress写博客时，可以通过插件来做这件事。最开始，我只是想单纯地添加这个“原始地址“，一番google未能找到现成的插件，所以只好动手。话说编写octopress真不是件容易事，因为我实在没找到编写插件的文档。octopress基于jekyll，jekyll又使用了liquid。最后我把这几个项目的文档都翻了下，也仅仅看到几个代码示例，而且liquid的API页面居然出错。无奈之下只好多翻了些现有插件的代码，摸索着来写。写octopress的插件，主要分为generator/tag/filter几种。tag很好理解，就是在文章中插入一个插件注册的tag，然后生成页面时就会调用到对应的插件。filter大概就是把文章内容过滤一遍转换成其他内容输出。后来发现了一篇文章&lt;给中英文间加个空格&gt;，这人写的插件从流程上大致是我需要的，模仿如下：## post_footer_filter.rb# Append every post some footer infomation like original url # Kevin Lynx# 7.26.2012#require './plugins/post_filters'module AppendFooterFilter def append(post) author = post.site.config['author'] url = post.site.config['url'] pre = post.site.config['original_url_pre'] post.content + %Q[&lt;p class='post-footer'&gt; #{pre or \"original link:\"} &lt;a href='#{post.full_url}'&gt;#{post.full_url}&lt;/a&gt;&lt;br/&gt; &amp;nbsp;written by &lt;a href='#{url}'&gt;#{author}&lt;/a&gt; &amp;nbsp;posted at &lt;a href='#{url}'&gt;#{url}&lt;/a&gt; &lt;/p&gt;] end endmodule Jekyll class AppendFooter &lt; PostFilter include AppendFooterFilter def pre_render(post) post.content = append(post) if post.is_post? end endendLiquid::Template.register_filter AppendFooterFilter大概就是当传入的页面是post时，就添加页脚信息，我这里主要添加了原始地址和作者信息，并且留了个post-footer作为这个段落的样式定制。附加的信息对于RSS输出同样有效。这个插件的使用方式很简单，直接放到plugins目录下即可。可以在_config.yml中配置下origional_url_pre，例如配置为“原始地址：“。" }, { "title": "ruby中的case...when语法", "url": "/posts/ruby-case-when/", "categories": "tips, ruby", "tags": "tips, ruby", "date": "2012-07-26 10:13:00 +0800", "snippet": "参考How to write a switch statement in Ruby?其实用Rails写个业务逻辑不算复杂的app根本用不上ruby的很多高级语法，更别说&lt;meta programming in ruby&gt;中的东西了（凡是打上meta programming标签的都不是什么简单的东西，参考c++/lisp）。ruby中的case…when语句和c/c++中的switch…case其实根本不是一回事。&lt;Programming in Ruby 2nd&gt;： case operates by comparing the target with each of the comparison expression after the when keywords. This test is done using comparison === target.也就是说case…when用的不是==操作符，不是使用相等逻辑去判断，而是使用===运算符。===运算符从C++的角度简单来说就是判定is-a关系，例如Fixnum === 1String === \"hello\"(1..3) === 21 is a Fixnum，hello is a String，2 is a (1..3) (in the range of)。比较让人产生误解的，大概就是1===1也为true。所以理解起来，也不纯碎是is-a关系。case awhen Fixnum puts \"fixnum\"when String puts \"string\"when (1..3) puts \"between 1 and 3\"else puts \"default\"end最后，作为一种functional-like language，其语句也算是表达式，意即也有返回值。case..when的返回值就是执行的分支的返回值。" }, { "title": "HTML中table的高亮以及tooltip", "url": "/posts/html-table-hover/", "categories": "tips, web", "tags": "tips, web, html", "date": "2012-07-24 16:08:00 +0800", "snippet": "在一个需要显示很多数据的表格(table)中，为了更友好地查看一行数据，常常需要在鼠标指针移到某一行时，高亮此行。要实现这个效果有很多方法，这里列举一个方法：function setTableHover(t) { $(t + \" tbody tr\") .mouseover(function() { $(this).addClass(\"hover\");}) .mouseout(function() { $(this).removeClass(\"hover\"); })}主要就是在鼠标移到某一行时，为该行添加一个高亮的css class，鼠标离开时移除该class即可。可以为一个特定的table设定：&lt;table id=\"test\"&gt;&lt;/table&gt;&lt;script&gt; setTableHover('#test')&lt;/script&gt;甚至可以为将某个页面的所有table设为高亮：&lt;script&gt; setTableHover('table')&lt;/script&gt;css里需要编写这个hover：.hover { background: #e9cffa;}除了高亮显示某一行外，可能还需要在鼠标移动到某个单元格时，弹出一个tooltip。这里的tooltip可以是弹出窗口，也就是一个div元素。&lt;tr&gt; &lt;td class=\"tip\"&gt; hello &lt;div class='popup' style='display:none;'&gt;this is the tip&lt;/div&gt; &lt;/td&gt;&lt;/tr&gt;要实现此效果，可以通过修改包含tip class的鼠标事件响应：$(function () { $('.tip').hover( function () { show_popupex($(this).find(\"div\"), $(this)); }, function () { $(this).find(\"div\").hide(); } );});hover的第一个参数表示鼠标进入的响应，第二个参数表示鼠标离开的响应。show_popupex用于将一个元素以绝对位置显示在指定元素（这里是单元格）附近，可以参看弹出窗口那篇文章。" }, { "title": "Rails中获取客户端时区", "url": "/posts/get-client-timezone-in-rails/", "categories": "tips, web", "tags": "tips, rails", "date": "2012-07-20 16:42:00 +0800", "snippet": "开发网站功能时，有时候需要获取客户端（浏览器）所在的时区，然后根据不同的时区做一些不同的逻辑功能。这里提供一种方法，其思路为客户端通过js获取时区，然后发送给服务器，服务器存储时区到session中。function submit_timezone(url) { $.get(url, {'offset_min' : (-1 * (new Date()).getTimezoneOffset())});}$(document).ready(function() { submit_timezone('&lt;%= sys_timezone_path %&gt;');});sys_timezone_path是一个特地用来处理时区的route。其实主要需要的是offset_min这个请求参数，你可以把这个参数附加到其他请求里。然后根据offset_min获取到时区名：def timezone offset_sec = params[:offset_min].to_i * 60 zone = ActiveSupport::TimeZone[offset_sec] zone = ActiveSupport::TimeZone[\"UTC\"] unless zone session[:zone_name] = zone.name if zone respond_to do |format| format.js endend以上，获取到时区名后存储到session[:zone_name]里。在之后处理这个客户端的请求时，就可以通过这个时区名取得对应的时区，例如：zone_name = session[:zone_name] zone = ActiveSupport::TimeZone[zone_name] if zone_name但经过我实际测试，部署在heroku上的应用偶尔会发现session[:zone_name]取出来是nil，尽管我确认了timezone函数是被调用过的。这难道跟session的超时有关？后来我只好将timezone name写到客户端页面中，然后在其他请求中再把这个时区名发回来。" }, { "title": "HTML中实现弹出窗口", "url": "/posts/popup-window-in-html/", "categories": "tips, web", "tags": "tips, web, html", "date": "2012-07-19 14:56:00 +0800", "snippet": "做网页时弹出一个窗口显示一些内容是一种很常见的交互方式，如图中用户点击“个人资料“时并不是转到一个新页面，而是在当前页面弹出修改密码的窗口。弹出窗口的实现方式有很多，这里罗列一种。弹出窗口的内容是作为一个单独的div存在的，这个div可以在页面刚开始载入时不填入内容，而在以后通过json或者直接返回js来填入。其次，弹出窗口的显示位置一般是绝对位置，一方面是不影响页面布局，另一方面也希望其作为一个顶层窗口来呈现，所以需要指定其position css。&lt;div id='userprofile' class='popup' style=\"display:none;\"&gt;&lt;/div&gt;.popup { position: absolute; z-index: 200; left: 0px; top: 0px; border: 1px solid #666; background: white; padding: 8px 5px 5px; margin: 10px 5px;}我这里div里的内容是后面填入的，预先填入也可以。当要显示时，就通过js将这个div显示即可。为此我封装了几个js函数。function show_popupex(pannel, target, manual) { var pos = target.position(); var height = target.outerHeight(); pannel.css('left', pos.left + 'px'); pannel.css('top', pos.top + height + 'px'); pannel.show(); if (!manual) { pannel.mouseleave(function() { pannel.hide(); }); }}function show_popup(pannel_id, target_id, manual) { var target = $(target_id); var pannel = $(pannel_id); show_popupex(pannel, target, manual);}function hide_popup(pannel_id) { $(pannel_id).hide();}show_popup函数主要就是将目标元素的位置做调整，然后显示。通常情况下我只需传入元素的id，manual属性指定弹出窗口是否手动关闭。对于tooltip的实现，则需要让其自动关闭。针对以上例子，使用方式为：show_popup('#userprofile', '#profile-link', true);其中profile-link就是那个“个人资料“链接。" }, { "title": "开始记录编程方面的技巧", "url": "/posts/start-to-write-tips/", "categories": "other, tips", "tags": "", "date": "2012-07-18 17:01:00 +0800", "snippet": "回首上篇博客的发表时间，又2个月时间过去了。在我博客生涯的过去两三年里，总会有好几个月的时间没有编写任何文章。我觉得这真是一个不好的习惯。这个情况的产生，有很多原因。例如自己太懒、工作偶尔忙、自己偶尔处于混沌时期、自己偶尔怀疑人生，如是种种。但最大的原因还是，不敢写。在刚出来工作那会，作为一个懵懂的青年，接触个什么新技术都内心激动骄傲，然后就特别有动力将所学记录下来，注意下言辞还能折腾个像那么回事的教程出来。后来慢慢地，我就觉得，这些东西太肤浅。先别说教人用个什么IDE，配置个什么数据库，就算你是学个新语言，好好研究下TCP，甚至还能折腾个IOCP框架，这些都还是他妈的特肤浅。你说任何一个有那么点经验和学习能力的程序员，谁花点时间整不出来这些？谁他妈要你在这里装逼卖萌，甚至贻笑大方。除此之外，我个人也觉得无聊了。另一方面我觉得写博客还有个好处就是帮助自己记录技术，以便将来万一又需要曾经学习过的技术了，回头温习一下就好。但是后来慢慢地我又觉得，这也是没必要的事情。因为反正需要这个技术的时候，也花不了多少时间。基于这些乱七八糟的原因，我虽然经常打开自己的博客，看看有没人评论啊，留言啊，但发表博客的频率始终上不去。后来呢，在google reader上断断续续也看了些别的程序员的故事。例如有傻逼坚持1年每天一篇博客，后来竟然写了本书；例如有傻逼坚持每天翻译一篇英文文章。我琢磨着这些人该有多么大的毅力啊，就算是翻译文章，这从找文章筛选文章到最好发表出来这尼玛又该睡觉了啊亲。心生佩服之余，我觉得自己应该向这些傻逼们学习。作为一个已经没有那么多青年时光的青年，试想以后每天下班回家带娃的日子，而曾经竟碌碌无为地磨过每一个工作日耍过每一个工作日晚上，这是件比带娃更悲剧的事情。所以，我也决定坚持干一件虽一日不用一次但也望每周那么几次的事情。我决定在博客上记录一些编程方面的技巧(tips)，集中于某个小问题的解决、某个小功能的实现。这些技巧相比前文说的，就更肤浅了，肤浅到你一google出来的结果你都吓一跳的程度。但是我依然觉得这是有用的，就像我用rails做网站，每一个小功能我都得google一遍，然后积累于心，然后一段时间后忘掉。为了不忘掉，为了查阅起来简单，我决定记录下来。但是仅靠我自己的经验，是肯定无法做到频繁地更新的，所以，我决定上stackoverflow上随机找些问题/答案翻译出来。stackoverflow非常适合满足这种需求，我发现我google某个rails技巧时，基本是从stackoverflow上获取下来的。这样，我的博客http://codemacro.com的rss输出可能会繁杂点，这对于某些人而言估计会起到恶心的效果。而我自己的博客可能也会变得不那么像个人博客。我也想过单独做个网站出来，但仔细想想还是制止自己少瞎折腾了。如有建议欢迎批评。好，就这样，没了。" }, { "title": "为octopress添加tag cloud", "url": "/posts/add-tag-to-octopress/", "categories": "tips", "tags": "tips, octopress", "date": "2012-07-18 16:37:00 +0800", "snippet": "同添加category list一样，网络上有很多方法，这里列举一种。首先到https://github.com/robbyedwards/octopress-tag-pages和https://github.com/robbyedwards/octopress-tag-cloudclone这两个项目的代码。这两个项目分别用于产生tag page和tag cloud。 针对这两个插件，需要手工复制一些文件到你的octopress目录。octopress-tag-pages复制tag_generator.rb到/plugins目录；复制tag_index.html到/source/_layouts目录。需要注意的是，还需要复制tag_feed.xml到/source/_includes/custom/目录。这个官方文档里没提到，在我机器上rake generate时报错。其他文件就不需要复制了，都是些例子。octopress-tag-cloud仅复制tag_cloud.rb到/plugins目录即可。但这仅仅只是为liquid添加了一个tag（非本文所提tag）。如果要在侧边导航里添加一个tag cloud，我们还需要手动添加aside。复制以下代码到/source/_includes/custom/asides/tags.html。&lt;section&gt; &lt;h1&gt;Tags&lt;/h1&gt; &lt;ul class=\"tag-cloud\"&gt; {% tag_cloud font-size: 90-210%, limit: 10, style: para %} &lt;/ul&gt;&lt;/section&gt;tag_cloud的参数中，style :para指定不使用li来分割，limit限定10个tag，font-size指定tag的大小范围，具体参数参看官方文档。最后，当然是在_config.xml的default_asides 中添加这个tag cloud到导航栏，例如：default_asides: [asides/category_list.html, asides/recent_posts.html, custom/asides/tags.html]" }, { "title": "为octopress添加分类(category)列表", "url": "/posts/add-category-list-to-octopress/", "categories": "tips", "tags": "tips, octopress", "date": "2012-07-18 16:10:00 +0800", "snippet": "参考http://paz.am/blog/blog/2012/06/25/octopress-category-list-plugin/。大致步骤为：增加category_list插件保存以下代码到plugins/category_list_tag.rb：module Jekyll class CategoryListTag &lt; Liquid::Tag def render(context) html = \"\" categories = context.registers[:site].categories.keys categories.sort.each do |category| posts_in_category = context.registers[:site].categories[category].size category_dir = context.registers[:site].config['category_dir'] category_url = File.join(category_dir, category.gsub(/_|\\P{Word}/, '-').gsub(/-{2,}/, '-').downcase) html &lt;&lt; \"&lt;li class='category'&gt;&lt;a href='/#{category_url}/'&gt;#{category} (#{posts_in_category})&lt;/a&gt;&lt;/li&gt;\\n\" end html end endendLiquid::Template.register_tag('category_list', Jekyll::CategoryListTag)这个插件会向liquid注册一个名为category_list的tag，该tag就是以li的形式将站点所有的category组织起来。如果要将category加入到侧边导航栏，需要增加一个aside。增加aside复制以下代码到source/_includes/asides/category_list.html。&lt;section&gt; &lt;h1&gt;Categories&lt;/h1&gt; &lt;ul id=\"categories\"&gt; {% category_list %} &lt;/ul&gt;&lt;/section&gt;配置侧边栏需要修改_config.yml文件，修改其default_asides项：default_asides: [asides/category_list.html, asides/recent_posts.html]以上asides根据自己的需求调整。" }, { "title": "tolua的tolua_toxxx系列API设计", "url": "/posts/tolua-api/", "categories": "lua", "tags": "lua, tolua", "date": "2012-05-10 00:00:00 +0800", "snippet": "我们使用tolua++手工绑定c/c++接口到lua中，在绑定的接口实现里，就需要取出传入的参数。tolua++中提供了一系列tolua_toxxx函数，例如：lua_Number tolua_tonumber(lua_State *L, int narg, lua_Number def)const char *tolua_tostring(lua_State *L, int narg, const char *def)这些函数都有一个def参数。乍一看，这些函数使用起来很简单。传入lua_State，传入参数在栈中的位置，然后再传一个失败后返回的默认值。我重点要说的是这里这个失败，按正常程序员的理解，针对lua而言，什么情况下算失败呢？lua语言里函数参数支持不传，此时实参为nil，将nil转换为一个c类型必然失败；参数类型不正确算不算失败？你传一个user data，c里按数字来取，这也算失败。这么简单的API还需要多纠结什么呢？然后我们浩浩荡荡地写了上百个接口，什么tolua_tostring/tolua_tonumber的使用少说也有500了吧？然后有一天，服务器宕机了，空指针:/* 失败返回\"\"，还能省空指针的判断 */const char *name = tolua_tostring(L, 1, \"\");if (name[0] == '\\0') { /* 空串总得判断吧 */ ...}跟踪后发现，脚本里传入的是nil，这里的name取出来是NULL，而不是”“（的地址）。然后吐槽了一下这个API，辛苦地修改了所有类似代码，增加对空指针的判断。我没有多想。故事继续，有一天服务器虽然没宕机，但功能不正常了:float angle = (float) tolua_tonumber(L, 1, 2 * PI);...这个意思是，这个函数的参数1默认是2*PI，什么是默认？lua里某函数参数不传，或传nil就是使用默认。因为不传的话，这个实参本身就是nil。但，tolua_tonumber的行为不是这样的，它的实现真是偷懒:TOLUA_API lua_Number tolua_tonumber (lua_State* L, int narg, lua_Number def){ return lua_gettop(L)&lt;abs(narg) ? def : lua_tonumber(L,narg);}TOLUA_API const char* tolua_tostring (lua_State* L, int narg, const char* def){ return lua_gettop(L)&lt;abs(narg) ? def : lua_tostring(L,narg);}意思是，只有当你不传的时候，它才返回默认值，否则就交给lua的API来管，而lua这些API是不支持应用层的默认参数的，对于lua_tonumber错误时就返回0，lua_tostring错误时就返回NULL。这种其行为和其带来的common sense不一致的API设计，实在让人蛋疼。什么是common sense呢？就像一个UI库里的按钮，我们都知道有click事件，hover事件，UI库的文档甚至都不需要解释什么是click什么是hover，因为大家看到这个东西，就有了共识，无需废话，这就是common sense。就像tolua的这些API，非常普通，大家一看都期待在意外情况下你能返回def值。但它竟然不是。实在不行，你可以模仿lua的check系列函数的实现嘛:LUALIB_API lua_Number luaL_checknumber (lua_State *L, int narg) { lua_Number d = lua_tonumber(L, narg); if (d == 0 &amp;&amp; !lua_isnumber(L, narg)) /* avoid extra test when d is not 0 */ tag_error(L, narg, LUA_TNUMBER); return d;}即，根本不用去检查栈问题，直接在lua_tonumber之后再做包装检查。何况，lua需要你去检查栈吗？当你访问了栈外的元素时，lua会自动返回一个全局常量luaO_nilobject:static TValue *index2adr(lua_State *L, int idx) { ... if (o &gt;= L-&gt;top) return cast(TValue*, luaO_nilobject);}另，程序悲剧也来源于臆想。" }, { "title": "谈谈我们的游戏逻辑服务器实现（二）", "url": "/posts/game-server-info-2/", "categories": "game develop", "tags": "game develop", "date": "2012-04-25 00:00:00 +0800", "snippet": "上一篇谈了一些关键技术的实现方案。本篇描述一些遇到的问题。一在策划制作完了几个职业后（主要是技能制作），大概去年年底公司内部进行了一次混战测试。30个角色在一个场景进行混战，测试结果从技术上来说非常不理想。首先是客户端和服务器都巨卡无比。服务器CPU一直是满负载状态。而客户端又频繁宕机。我们关注的主要问题，是服务器CPU满负载问题。最开始，我通过日志初步定位为网络模块问题，因为逻辑线程表现不是那么差。然后考虑到技能过程中的特效、动作都是通过服务器消息驱动，并且本身特效和动作就比一般网游复杂，通过逐一屏蔽这一部分功能，最终确认确为网络模块导致。然后团队决定从两方面努力：重写网络模块，改善性能；改善技能实现机制，将表现类逻辑移到客户端。至于网络模块，在后来才发现，虽然网络流量过高，但导致网络线程CPU满的原因竟然是网络模块自身的流量限制导致。而技能实现机制的改善，考虑到改动的成本，最终使用了一种RPC机制，让服务器脚本可以调用客户端脚本，并且支持传入复杂参数。然后策划通过一些关键数据在客户端计算出特效、动作之类。此外，程序将更多的技能属性广播给客户端，一个客户端上保存了周围角色的技能数据，从而可以进行更多的客户端逻辑。这一块具体的修改当然还是策划在做（我们的脚本策划基本就是半个程序员）。后经测试，效果改善显著。二在策划制作了一个PVP竞技副本后，服务器在10V10测试过程中又表现出CPU负载较高的情况。这个问题到目前为止依然存在，只不过情况略微不同。首先是触发器生命周期的问题。触发器自身包含最大触发次数、存留时间等需求，即当触发一定次数，或超过存留时间后，需要由程序自动删除；另一方面，触发器可以是定时器类型，而定时器也决定了触发器的生命周期。这一块代码写的非常糟糕，大概就是管理职责划分不清，导致出现对象自己删除自己，而删除后还在依赖自己做逻辑。但这样的逻辑，最多就是导致野指针的出现。不过，这种混乱的代码，也更容易导致BUG。例如，在某种情况下触发器得不到自动删除了。但这个BUG并不是直接暴露的，直接暴露的，是CPU满了。我们的怪物AI在脚本中是通过定时器类触发器驱动的，每次AI帧完了后就注册一个触发器，以驱动下一次AI帧。由于这个BUG导致触发器没有被删除，从而导致服务器上触发器的数量急剧增加。但，这也就导致内存增长吧？另一个巧合的原因在于，在当时的版本中，触发器是保存一个表里的，即定时器类触发器、属性类触发器、移动类触发器等都在一个表里。每次任意触发器事件发生时，例如属性改变，都会遍历这个表，检查其是否触发。基于以上原因，悲剧就发生了。在这个怪物的AI脚本里，有行代码设置了怪物的属性。这会导致程序遍历该怪物的所有触发器。而这个怪物的触发器数量一直在增长。然后就出现了在很多游戏帧里出现过长的遍历操作，CPU就上去了。找到这个问题了几乎花了我一天的时间。因为脚本代码不是我写的，触发器的最初版本也不是我写的。通过逐一排除可能的代码，最终竟然发现是一行毫不起眼的属性改变导致。这个问题的查找流程，反映了将大量逻辑放在脚本中的不便之处：查起问题来实在吃力不讨好。修复了这个BUG后，我又对触发器管理做了简单的优化。将触发器列表改成二级表，将触发器按照类型保存成几个列表。每次触发事件时，找出对应类型的表遍历。改进除了修改触发器的维护数据结构外，程序还实现了一套性能统计机制，大概就是统计某个函数在一段时间内的执行时间情况。最初这套机制仅用于程序，但考虑到脚本代码在整个项目中的比例，又决定将其应用到脚本中。这个统计需要在函数进入退出时做一些事情，C++中可以通过类对象的构建和析构完成，但lua中没有类似机制。最初，我使用了lua的调试库来捕获函数进入/退出事件，但后来又害怕这种方式本身存在效率消耗，就取消了。我们使用lua的方式，不仅仅是全局函数，还包括函数对象。而函数对象是没有名字标示的，这对于日志记录不是什么好事。为了解决这个问题，我只好对部分功能做了封装，并让策划显示填入函数对于的字符串标示。除此之外，因为触发器是一种重要的敏感资源，我又加入了一个专门的触发器统计模块，分别统计触发器的类型数量、游戏对象拥有的触发器数量等。END到目前为止，导致服务器CPU负载过高，一般都是由BUG导致。这些BUG通常会造成一个过长的列表，然后有针对这个列表的遍历操作，从而导致CPU负载过高。更重要的，我们使用了这么多的脚本去开发这个游戏，如何找到一个更有效合理的监测方法，如何让程序框架更稳定，则是接下来更困难而又必须去面对的事情。" }, { "title": "谈谈我们的游戏逻辑服务器实现（一）", "url": "/posts/game-server-info-1/", "categories": "game develop", "tags": "game develop", "date": "2012-04-23 00:00:00 +0800", "snippet": "我们的逻辑服务器(Game Server，以下简称GS)主要逻辑大概是从去年夏天开始写的。因为很多基础模块，包括整体结构沿用了上个项目的代码，所以算不上从头开始做。转眼又快一年，我觉得回头总结下对于经验的积累太有必要。整体架构GS的架构很大程度取决于游戏的功能需求，当然更受限于上个项目的基础架构。基础架构包括场景、对象的关系管理，消息广播等。需求这一回，程序员其实已经不需要太过关心需求。因为我们决定大量使用脚本。到目前为止整个项目主要还是集中在技能开发上。而这个使用脚本的度，就是技能全部由策划使用脚本制作，程序员不会去编写某个具体技能，也不会提供某种配置方式去让策划通过配置来开发技能。这真是一个好消息，不管对于程序员而言，还是对于策划而言。但后来，我觉得对于这一点还是带来了很多问题。实现基于以上需求，程序员所做的就是开发框架，制定功能实现方案。脚本为了与整个游戏框架交互，我们制定了“触发器“这个概念，大概就是一种事件系统。这个触发器系统，简单来说，就是提供一种“关心“、”通知“的交互方式，也就是一般意义上的事件机制。例如，脚本中告诉程序它关心某个对象的移动，那么当程序中该对象产生移动时，就通知脚本。脚本中可以关心很多东西，包括对象属性，其关心的方式包括属性值改变、变大、变小，各种变化形式；对象开始移动，移动停止；对象碰撞，这个会单独谈谈；定时器等。除了触发器系统外，还有个较大的系统是游戏对象的属性系统。对象的属性必然是游戏逻辑中策划最关心最容易改动的模块。既然我们程序的大方向是尽可能地不关心策划需求，所以对象属性在设计上就不可能去编写某个具体属性，更不会编写这个属性相关的逻辑功能。简单来说，程序为每个对象维护一个key-value表，也就是属性名、属性值表。该表的内容由脚本填入，脚本享有存取权限。然后脚本中就可以围绕某个属性来编写功能，而程序仅起存储作用。第三，怪物AI模块。AI模块的设计在开发周期上靠后。同样，程序不会去编写某类AI的实现。程序提供了另一种简单的事件系统，这个系统其实就是一个调用脚本的方案。当关于某个怪物发生了某个事件时，程序调用脚本，传入事件类型和事件参数。这个事件分为两类：程序类和脚本类。脚本类程序不需关心，仅提供事件触发API。程序类事件非常有限：怪物创建、出生、删除。除了以上三块之外，还有很多零散的脚本交互。例如游戏对象属性初始化，角色进入游戏，角色进入场景等。这些都无关痛痒。接下来谈一些关键模块的实现。定时器整个GS的很多逻辑模块都基于这个定时器来实现。这个定时器接收逻辑模块的注册，在主循环中传入系统时间，定时器模块检查哪些定时器实例超时，然后触发调用之。这个主循环以每帧5ms的速率运行，也即帧率1000/5。这个定时器是基于操作系统的时间。随着帧率的不同，它在触发逻辑功能时，就必然不精确。游戏客户端（包括单机游戏）在帧率这块的实现上，一般逻辑功能的计算都会考虑到一个dt（也就是一帧的时间差），例如移动更新，一般都是x = last_x + speed * dt。但，我们这里并没有这样做。我们的几乎所有逻辑功能，都没有考虑这个时间差。例如，我们的移动模块注册了一个固定时间值的定时器，假设是200ms。理想情况下，定时器模块每200ms回调移动模块更新坐标。但现实情况肯定是大于200ms的更新频率，悲剧的是，移动模块每次更新坐标都更新一个固定偏移。这显然是不够精确的。更悲剧的是，定时器的实现中，还可能出现跳过一些更新帧。例如，理论情况下，定时器会在系统时间点t1/t2/t3/t4分别回调某个逻辑模块。某一帧里，定时器大概在t1回调了某逻辑模块，而当该帧耗时严重时，下一帧定时器模块在计算时，其时间值为t，而t大于t4，此时定时器模块跳过t2/t3。相当于该逻辑模块少了2次更新。这对于移动模块而言，相当于某个对象本来在1秒的时间里该走5格，但实际情况却走了1格。当然，当游戏帧率无法保证时，逻辑模块运行不理想也是情有可原的。但，不理想并不包含BUG。而我觉得，这里面是可能出现BUG的。如何改善这块，目前为止我也没什么方案。移动有很多更上层的模块依赖移动。我们的移动采用了一种分别模拟的实现。客户端将复杂的移动路径拆分为一条一条的线段，然后每个线段请求服务器移动。然后服务器上使用定时器来模拟在该线段上的移动。因为服务器上的阻挡是二维格子，这样服务器的模拟也很简单。当然，这个模块在具体实现上复杂很多，这里不细谈。碰撞检测我们的技能要求有碰撞检测，这主要包括对象与对象之间的碰撞。在最早的实现中，当脚本关心某个对象的碰撞情况时，程序就为该对象注册定时器，然后周期触发检测与周围对象的距离关系，这个周期低于100ms。这个实现很简单，维护起来也就很简单。但它是有问题的。因为它基于了一个不精确的定时器，和一个不精确的移动模块。首先，这个检测是基于对象的当前坐标。前面分析过在帧率掉到移动更新帧都掉帧的情况下，服务器的对象坐标和理论情况差距会很大，而客户端基本上是接近正确情况的，这个时候做的距离检测，就不可能正确。另一方面，就算移动精确了，这个碰撞检测还是会带来BUG。例如现在检测到了碰撞，触发了脚本，脚本中注册了关心离开的事件。但不幸的是，在这个定时器开始检测前，这两个对象已经经历了碰撞、离开、再碰撞的过程，而定时器开始检测的时候，因为它基于了当前的对象坐标，它依然看到的是两个对象处于碰撞状态。最开始，我们直觉这样的实现是费时的，是不精确的。然后有了第二种实现。这个实现基于了移动的实现。因为对象的移动是基于直线的（服务器上）。我们就在对象开始移动时，根据移动方向、速度预测两个对象会在未来的某个时间点发生碰撞。当然，对于频繁的小距离移动而言，这个预测从直觉上来说也是费时的。然后实现代码写了出来，一看，挺复杂，维护难度不小。如果效果好这个维护成本也就算了，但是，它依然是不精确的。因为，它也依赖了这个定时器。例如，在某个对象开始移动时，我们预测到在200ms会与对象B发生碰撞。然后注册了一个200ms的定时器。但定时器不会精确地在未来200ms触发，随着帧率的下降，400ms触发都有可能。即便不考虑帧率下降的情况，它还是有问题。前面说过，我们游戏帧保证每帧至少5ms，本来这是一个限帧手段，目的当然是避免busy-loop。这导致定时器最多出现5ms的延迟。如果策划使用这个碰撞检测去做飞行道具的实现，例如一个快速飞出去的火球，当这个飞行速度很快的时候，这5ms相对于这个预测碰撞时间就不再是个小数目。真悲剧。技能虽然具体的技能不是程序写的，但正如把几乎所有具体逻辑交给策划写带来的悲剧一样：这事不是你干的，但你得负责它的性能。所以有必要谈谈技能的实现。技能的实现里，只有一个技能使用入口，程序只需要在客户端发出使用技能的消息时，调用这个入口脚本函数。然后脚本中会通过注册一些触发器来驱动整个技能运作。程序员一直希望策划能把技能用一个统一的、具体的框架统一起来，所谓的变动都是基于这个框架来变的。但策划也一直坚持，他们心目中的技能是无法统一的。我们的技能确实很复杂。一个技能的整个过程中，服务器可能会和客户端发生多次消息交互。在最初的实现中，服务器甚至会控制客户端的技能特效、释放动作等各种细节；甚至于服务器会在这个过程中依赖客户端的若干次输入。下一篇我将谈谈一些遇到的问题。" }, { "title": "使用Github Page来写博客", "url": "/posts/blog-on-github/", "categories": "other", "tags": "github, jekyll, blog", "date": "2012-04-20 00:00:00 +0800", "snippet": "最开始知道Github Page，是通过codertrace上的某些注册用户，他们的BLOG就建立在Github Page上，并且清一色的干净整洁（简陋），这看起来很酷。Github提供了很多很合coder口味的东西，例如Gist，也包括这里提到的Page。Page并不是特用于建立博客的产品，它仅提供静态页面的显示。它最酷的地方，是通过Git的方式来让你管理这些静态页面。通过建立一个repository，并使用markdown语法来编写文章，然后通过Git来管理这些文章，你就可以自动将其发布出去。当然，要搭建一个像样点的博客，使用Github Page还不太方便。这里可以使用Jekyll。Jekyll是一个静态网页生成器，它可以将你的markdown文件自动输出为对应的网页。而Github Page也支持Jekyll。为了更方便地搭建博客，我还使用了Jekyll-bootstrap。jekyll-bootstrap其实就是一些模板文件，提供了一些博客所需的特殊功能，例如评论，访问统计。基于以上，我就可以像在Github上做项目一样，编写markdown文章，然后git push即可。可以使用jekyll –server在本地开启一个WEB SERVER，然后编写文章时，可以在本地预览。Github Page还支持custom domain，如你所见，我将我的域名codemacro.com绑定到了Github Page所提供的IP，而不再是我的VPS。你可以通过kevinlynx.github.com或者codemacro.com访问这个博客。当然实际情况并没有那么简单，例如并没有太多的theme可供选择，虽然jekyll-bootstrap提供了一些，但还是太少。虽然，你甚至可以fork别人的jekyll博客，使用别人定制的theme，但，这对于一个不想过于折腾的人说，门槛也过高了点。jekyll-bootstrap使用了twitter的bootstrap css引擎，但我并不懂这个，所以，我也只能定制些基本的页面样式。1年前我编写了ext-blog，并且在我的VPS上开启了codemacro.com这个博客。本来，它是一个ext-blog很好的演示例子，但维护这个博客给我带来诸多不便。例如，每次发布文章我都需要使用更早前用lisp写的cl-writer，我为什么就不愿意去做更多的包装来让cl-writer更好用？这真是一个垃圾软件，虽然它是我写的。另一方面，codemacro.com使用的主题，虽然是我抄的，但依然太丑，并且恶心。更别说那个消耗我VPS所有内存的lisp解释器，以及那恶心的两位数字乘法的验证码—你能想象别人得有多强烈的留言欲望，才愿意开一个计算器？说说codertrace.com。我其实写了篇关于codertrace.com的总结，但没有作为博客发布。做这个事情的结果，简单总结来说就是瞎JB折腾没有任何结果。我真的是个苦逼双子男，我每次做件事情都需要巨大的毅力才能让自己专注下去。整个过程中，收到了些网友的邮件，看到了些评论，虽然不多。邮件/评论中有建议的，也有单纯的交流的，也有单纯鼓励的。我想说的是，thanks guys。Anyway, try Github Page, save your VPS money :D.update具体的搭建步骤，其实Github Page以及Jekyll的帮助文档中其实已经有说明。而Jekyll-bootstrap给了更为详细的说明： 安装 发布其大概步骤，差不多为： Github上创建一个repository 安装jekyll（这是一个ruby gem），这是为了本地预览 clone Jekyll-bootstrap到你刚创建的repository 在_post目录下创建日志 提交日志到Github" }, { "title": "写了个简单的网站，codertrace.com", "url": "/posts/codertrace/", "categories": "other", "tags": "codertrace", "date": "2012-02-04 00:00:00 +0800", "snippet": "简介因为写 ext-blog的原因，慢慢喜欢上github_ 。然后突然有一天产生了一个想法：如果可以把自己的博客_ 和github主页集中到一块展示给别人，会不会是一种很方便的自我简介方式？然后我就动手写了codertrace.com 。所以， codertrace.com这个网站的作用就是用来集中让程序员炫耀的。它通过RSS抓取，将你的博客，github主页，或其他有RSS输出的信息集中到一块展示给别人。这些信息通常就可以代表一个程序员。如果你是程序员，也不妨试试。技术信息不知道哪个王八蛋说的，程序员每一年得学一门新语言。我2010年末接触了Lisp，然后莫名其妙地写了ext-blog，又莫名其妙地在2011年末接触了Ruby。因为大学期间太痴迷C++，我勤奋努力，几乎通晓这门语言的各种细节；后来又稍微实践了下编译原理。在这若干年间，断断续续也接触过其他脚本类语言，我甚至在android上用java写过几个小应用。基于这些积累，我发现我可以很快上手Ruby，然后再上手Rails，然后就有了codertrace.com （当然还做过一些小的APP )所以， codertrace.com 就是一个Ruby onRails的应用。当我用这货来做WEB的时候，我才发现曾经用Lisp写博客是多么geek。这种感觉就像你在用汇编写一个GUI程序一样。我的意思是，ruby/rails的世界里有太多现成的东西，但lisp的世界里没有。而且，ruby是一个很爽的语言。我太喜欢它的closure语法，简洁，不需要加其他关键字就可以构造（例如其他语言map(function(item) xxxx end)，或者map(lambda (item) xxx)）。但我不喜欢在使用的地方通过yield去调用—这就像一个hack。我更不喜欢ruby用proc去封装closure。好吧，这其实是我自我分裂，为什么我要把ruby看成一个函数式语言？脚本语言真是太酷了。服务器信息我很穷。不管你信不信，我真的舍不得花1000RMB买个VPS来架设codertrace.com 。目前，codertrace.com 架设在heroku.com ，而且还使用的是免费服务。免费服务竟然只有5M数据库。codertrace.com后台为了异步抓取用户提供的RSS，还使用了一个单独的进程(delayed_job ruby gem)。这也不是免费的。但ruby的世界里有太多现成的东西了，甚至有很多现成的库解决这里的两个问题：heroku_external_db，这个gem可以让codertrace使用heroku以外的数据库，然后我就在我的VPS上搭了个mysql，这下流量和网站响应速度悲剧了啊，你想你请求个页面，这个页面直接涉及到若干条数据库查询。而这些查询的请求和回应竟然是通过internet网络传输的。workless，这个gem可以在有异步任务时，例如codertrace上读取RSS，就会自动开启这个worker进程，然后heroku开始计费，当没有任务时，它又自动关闭这个进程。虽然省了美元，但再一次让网站的响应速度打了折扣。为了实现自定义域名，我需要将 codertrace.com 指向heroku.com提供的IP。但也许你会同我一样愤怒，因为它提供的几个IP都被GFW墙了！所以，目前的实现方案是，我将codertrace.com指向了我博客对应的VPS，然后在VPS上使用nginx反向代理到 heroku.com提供的IP。即使如此，我最近甚至发现 codertrace.com竟然神奇般地会域名解析错误，难道godaddy的name server也要被GFW和谐？？故事作为一个宅男，在工作的若干年中，若干个假期我都用来打游戏，或者写程序。所以，当这个成为习惯的时候， codertrace.com，就顺理成章地消费了我今年的春节假期。我发现一个人窝在租的小房子里写代码是件很爽的事情。在当前这个社会环境下，你可以专注地去干件喜欢的事情，还不用处理各种生活琐事，真是太爽了。但为什么我平时得不到这种感觉？因为，我，是一个没钱的程序员。我和我老婆租在一个标间里。在这样狭小的空间里，多个人就是多几倍干扰。这太残酷了。末了曾经我以为我很牛逼，曾经我以为程序员很牛逼。后来我慢慢发现自己很垃圾。我没有写出来过牛逼的程序，大概也没能力写。还记得那个程序员的故事吗？就是有个傻逼也以为程序员很牛逼，但不幸在一家非IT公司的IT部门工作，他的程序员同事的工作就是每周填个excel表格。他后来很绝望，因为他没有为世界贡献过任何代码。后来，这货丢下一切，坐上去某地的飞机走了。" }, { "title": "使用Lisp搭建独立博客", "url": "/posts/build-blog-by-lisp/", "categories": "lisp", "tags": "lisp", "date": "2011-09-29 00:00:00 +0800", "snippet": "本文描述如何使用Lisp工具集搭建一个完整的个人博客站点。一个搭建好的例子站点可以参看我的个人博客：http://codemacro.com。要搭建一个独立博客，需要两方面的支持。一是博客软件，二是根据选择的博客软件取得必须的“硬件“。例如我这里使用的是Lisp工具集，就需要一个可以完全控制的服务器，所以这里我需要一个VPS。当然，购买一个合适的域名也是必须的。以下将针对这些内容做描述。获取VPS及域名VPS提供商国内国外都有很多。我选择的是 rapidxen，128M内存，1年70来美元，算是国外比较便宜的，速度上还过得去。购买了VPS后，可以进入后台管理页面安装VPS操作系统。同样，因为我使用的是Lisp，我选择安装了Debian 6.0 squeeze(minimal)64位。实际上我更倾向于32位，因为我的PC系统就是32位，方便测试。安装系统非常简单，基本随意设置下即可。值得注意的是，除了修改root密码外，最好修改下ssh端口，具体设置方法可以另行搜索。此外，因为后面我会使用nginx作为HTTP前端服务器，为了方便安装nginx，最好更新下软件源列表，编辑etc/apt/source.list:deb http://ftp.us.debian.org/debian squeeze maindeb http://packages.dotdeb.org stable alldeb-src http://packages.dotdeb.org stable alldeb http://php53.dotdeb.org stable alldeb-src http://php53.dotdeb.org stable all购买VPS最主要的，就是获取到一个独立IP，如图：然后可以去购买域名。同样，也有很多域名服务商。这里我选择的是 godaddy，我选择的域名codemacro.com一年11美元。购买了域名后，就需要将域名和VPSIP关联起来。详细设置也可以另行搜索。这里简要提下：在成功登入godaddy后，选择My Account，进入自己的域名，选择DNSManager，然后添加域名映射即可，如图：通过以上设置后，你购买的域名就成功指向你购买的VPS地址了。可以通过ping来观察是否指向成功。使用Lisp构建博客系统要在VPS上安装软件，首先需要SSH上你的VPS，例如：ssh -p 1234root@codemacro.com。这里使用的软件集包括： nginx，Web服务器 SBCL ，Lisp编译器实现 quicklisp ，可以方便自动下载、安装Lisp库的工具 hunchentoot，Lisp实现的Web服务器（不用特意安装） ext-blog ，Lisp实现的博客系统实际上，可以完全使用Lisp作为Web服务器，但我担心效率问题（对个人博客而言完全没这回事），所以使用了nginx作为Web服务器前端，将hunchentoot放在后面。安装nginx在设置好debian软件源后，安装非常简单:apt-get install nginx安装完后，因为要将HTTP请求转发给Lisp服务器，所以需要修改下配置:vi /etc/nginx/sites-avaiable/default将/请求派发给Lisp服务器（假设监听于8000端口）:location / { proxy_pass http://127.0.0.1:8000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr;}然后可以启动nginx了:nginx这个时候通过浏览器访问，会得到503 bad gateway的错误提示，因为hunchentoot还没开启。安装Lisp相关软件SBCL 同样可以通过apt直接安装:apt-get instal sbcl装好SBCL后，就可以进一步安装 quicklisp。可以完全遵守quicklisp官方给的安装方法进行安装。大概就是先获取quicklisp.lisp文件，然后在SBCL中载入，根据提示即可。这里不再赘述。安装好quicklisp后，就可以使用它安装很多Lisp软件/库了。quicklisp在安装一个Lisp库时，会自动下载并安装依赖库，就像apt-get一样。因为ext-blog并未收入到quicklisp的软件列表里，所以ext-blog需要手动安装。首先，在本地（非VPS上）获取ext-blog源码:git clone git://github.com/kevinlynx/ext-blog.git进入到ext-blog目录。该目录下有几个方便的脚本可以用于博客管理。首先将ext-blog打包并上传到VPS上，例如:./upload-dist.sh root@codemacro.com 1234 /home/test该脚本会调用make-dist.sh将ext-blog全部源码打包，然后使用scp拷贝该文件及update-blog.sh到VPS指定的目录里（这里是/home/test），然后ssh上VPS。期间会两次输入VPS系统的密码。然后以下操作将在VPS上完成。首先进入到刚才拷贝文件的目录:cd /home/test解压ext-blog.tar.gz:tar xvf ext-blog.tar.gz然后ext-blog被解压到/home/test/dist目录。进入此目录运行SBCL:cd distsbclext-blog目录下dep.lisp会使用quicklisp安装依赖库，进入SBCL后，载入该文件即可安装所有依赖库，这可能需要一点时间:(load \"dep.lisp\")在没有其他问题下，可以暂时退出SBCL完成一些其他准备工作。ext-blog在最近的版本中加入了验证码生成功能，这需要一个pcf字体文件。因为字体文件一般较大，所以upload-dist.sh脚本并没有将该字体文件打包，所以这里需要手动复制，同样在本地的ext-blog目录下:scp -P 1234 data/wenquanyi_12ptb.pcf root@codemacro.com:/home/test/dist/data/另外，因为需要将Lisp解释器放置在系统后台执行，避免关掉SSH会话后终止SBCL进程，所以这里需要个工具gnuscreen。可以使用apt-get来安装:apt-get install screen然后，一切就OK了。在VPS上可以使用ext-blog目录下的run-blog.sh来运行这个博客（首先确定VPS上的nginx开启）:./run-blog.sh该脚本会使用screen在后台开启一个SBCL进程，并自动载入ext-blog，然后在8000端口上开启HTTP服务。这个启动过程可能会使用几十秒的时间，直接ctrl+z退出screen，这并不终止SBCL。一段时间后便可在浏览器里测试。设置博客如果一切正常，此时通过浏览器访问你的站点时，会被重定向到一个博客初始化页面，如下：上图中我是在本机测试的，所以域名是localhost，希望不至于产生误解。初始化仅需输入用户名和密码即可，以后可通过该用户名和密码进入博客后台管理页面。完成这一步后，就可以进入博客后台管理页面做更多的设置，例如博客标题等。ext-blog的管理页面使用了emlog博客系统的CSS及其他资源，因此有同学觉得管理页面很面熟就不奇怪了。ext-blog提供在线编辑博客功能，同时也支持简单的metaweblogAPI，因此可以使用一些博客客户端来发表文章（仅测过我自己写的博客客户端cl-writer）。最后本文描述较为粗略，主要是很多细节我自己也记不清。如有问题可以发邮件给我。" }, { "title": "传递Lua函数到C/C++中", "url": "/posts/lua-function-arg/", "categories": "lua", "tags": "lua", "date": "2011-05-09 00:00:00 +0800", "snippet": "问题在Lua中，因为函数也是第一类值，所以会出现将函数作为另一个函数的参数，或者函数作为函数的返回值。这种机制在很多地方都能代码更灵活更简洁，例如: table.sort(table [,comp])这里的comp就要求传入一个函数，我们在调用时，大概会有如下形式: table.sort(t, comp) -- 直接写函数名 table.sort(t, local_comp) -- 某个局部函数 table.sort(t, function (a, b) xxx end ) -- 临时构造一个匿名函数其中最后一种方式最为灵活，任意时候在需要的时候构造一个匿名函数。这种在Lua自身的环境中使用，自然没有问题。但是，当我们在C/C++中注册一些函数到Lua环境中，而这些 函数也需要使用函数参数的时候，问题就出来了。Lua本身是不支持将Lua函数作为函数参数传入C/C++的，不管这个想要传入的函数是全局的、局部的、或者匿名的（匿名的本质上也算局部的）。一般情况下，我们唯一的交互方式，不是传入一个函数，而是一个全局函数名。C/C++保存这个函数名，在需要回调Lua的时候，就在Lua全局表中找到这个函数（根据函数名），然后再调用之。情况大致如下: function lua_func () xxx end cfunc(lua_func) -- wrong cfunc(\"lua_func\") -- right我们这回的脚本模块，策划会大量使用需要回调函数的C/C++函数。显然，创建大量的全局 函数，先是从写代码的角度看，就是很伤神的。解决我们最终需要的方式，大概如下: cfunc(lua_func) -- ok cfunc(function () xxx end) -- ok local xxx = function () xxx end cfunc(xxx) -- ok要解决这个问题，我的思路是直接在Lua层做一些包装。因为C/C++那边仅支持传入一个全局函数名（当然不一定得全局的，根据实际情况，可能在其他自己构造的表里也行），也就是一个字符串，所以我的思路就是将Lua函数和一个唯一的字符串做映射。: function wrap (fn) local id = generate_id() local fn_s = \"__callback_fn\"..id _G[fn_s] = fn return fn_s end这个wrap函数，就是将一个函数在全局表里映射到一个字符串上，那么在使用时: cfunc(wrap(function () xxx end)) cfunc(const char *fn_name, xxx); -- cfunc的原型cfunc是C/C++方注册进Lua的函数，它的原型很中规中矩，即：只接收一个函数名，一个字符串，如之前所说，C/C++要调用这个回调函数时，就根据这个字符串去查找对应的函数。脚本方在调用时，如果想传入一个匿名函数了，就调用wrap函数包装一下即可。一个改进上面的方法有个很严重的问题，在多次调用wrap函数后，将导致全局表也随之膨胀。我们需要想办法在C/C++完成回调后，来清除wrap建立的数据。这个工作当然可以放到C/C++来进行，例如每次发生回调后，就设置下全局表。但这明显是不对的，因为违背了接口的设计原则，这个额外的机制是在Lua里添加的，那么责任也最好由Lua来负。要解决这个问题，就可以使用Lua的metamethods机制。这个机制可以在Lua内部发生特定事件时，让应用层得到通知。这里，我们需要关注__call事件。Lua中只要有__call metamethod的值，均可被当作函数调用。例如:ab(1, 2) 这里这个函数调用形式，Lua就会去找ab是否有__call metamethod，如果有，则调用它。这个事实暗示我们，一个table也可以被调用。一个改进的wrap函数如下: local function create_callback_table (fn, name) local t = {} t.callback = fn setmetatable (t, {__call = -- 关注__call function (func, ...) -- 在t(xx)时，将调用到这个函数 func.callback (...) -- 真正的回调 del_callback (name) -- 回调完毕，清除wrap建立的数据 end }) return t end function wrap (fn) local id = generate_func_id() -- 产生唯一的id local fn_s = \"_callback_fn\"..id _G[fn_s] = create_callback_table(fn, fn_s) -- _G[fn_s]对应的是一个表 return fn_s end在我们的C/C++程序中，依然如往常一样，先是从_G里取出函数名对应的对象。虽然这个对象现在已经是一个table。然后lua_call。上面的代码是否会在原有基础上增加不可接受的性能代价？虽然我没有做过实际测试，但是 从表明看来，排除metatable在Lua里的代价，也就多了几次Lua函数调用。最后，感叹一下，Lua里的table及metatable机制，实在非常强大。这种强大不是功能堆砌出来的强大，而是简单东西组合出来的强大。其背后的设计思想，着实让人佩服。4.26.2011 Update之前的文中说“Lua本身是不支持将Lua函数作为函数参数传入C/C++的“，这句话严格来说不正确（由某网友评论）。假设函数cfun由c/c++注册，我们是可以编写如下代码的:cfunc(print) -- 传入Lua函数但是问题在于，我们无法取出这个函数并保存在c/c++方。Lua提供了一些接口用于取cfunc的参数，例如luaL_checknumber（封装lua_tonumber）。但没有类似luaL_checkfunction的接口。Lua中的table有同样的问题。究其原因，主要是Lua中的函数没有直接的c/c++数据结 构对应。;; END" }, { "title": "MMO游戏对象属性设计", "url": "/posts/entity-property/", "categories": "game develop", "tags": "game develop", "date": "2011-05-02 00:00:00 +0800", "snippet": "一般的MMORPG中，游戏对象主要包括怪物和玩家。这两类对象在经过游戏性方面的不断“进化”后，其属性数量及与之相关的逻辑往往会变得很巨大。如何将这一块做得既不损失效率，又能保证结构的灵活、清晰、可维护？本文将提供一种简单的结构。原始结构最原始的结构，极有可能为这样:Player: +---------------+ | property-1 | +---------------+ | property-2 | +---------------+ | ... | +---------------+ | operator-1 | +---------------+ | operator-2 | +---------------+ | ... | +---------------+也就是，一个对象为一个C++类，然后里面直接塞满了各种属性名，然后是针对这个属性的逻辑操作（函数）。其结果就是Player成为巨类。针对这个情况，一直以来我觉得可以使用一种简单的方法来拆分这个类。冠以官腔，称之为Entity-Component-basedDesgin。产生这种想法和我的个人技术积累有一定关系，见下文。Policy-based DesignPolicy-based Design，基于决策的设计。这个概念来源于&lt;Modern C++Design&gt;。虽然这本书讲述的是针对C++模板的使用及设计技巧。但这种思想依然被我潜意识般地用在其他地方。Policy大致来说就是一个小的组件(Component)。它努力不依赖于其他东西，它可能就是个简单的类，它拥有极少的数据结构，及针对这些数据的极少操作接口。举例而言，玩家MP的自动回复功能，就可封装为一个Policy。将许多Policy组合起来，就可完成一个复杂的功能。这种思想还可指导很多程序结构方面的设计。例如在做功能的接口拆分时，就将每个函数设计得足够小，小到单纯地完成一个功能。一个功能的入口函数，就将之前实现的小函数全部组合起来，然后共同完成功能点。当然，&lt;Modern C++ Design&gt;里的Policy在表现形式上有所不同。但其核心思想相同，主要体现在 组合特点上。Entity-Component-based DesignEntity-Component-basedDesign按照google到的文章，严格来说算是与OOP完全不同的软件设计方法。不过在这里它将按照我的意思重新被解释。如果说Policy-basedDesign极大可能地影响着我们平时的细节编码，那么Entity-Component则是直接对游戏对象的结构设计做直接的说明。一个游戏对象就是一个Entity。 Entity拥有很少的属性，也许仅包含一个全局标示的ID。一个Component则是Entity的某个行为、或者说某个组成部分。其实说白了，以玩家为例，一个玩家对象就是一个Entity，而一个MP的自动回复功能就可被包装为一个Component。这个Component可能包含若干与该功能相关的数据，例如回复时间间隔，每次的回复量等。我们往玩家对象这个Entity添加各种Component，也就是给玩家添加各种逻辑功能。但是，Component之间可能会涉及到交互，玩家对象之外的模块可能也会与玩家内的某个Component交互。子功能点的拆分，不得不涉及到更多的胶水代码，这也算一种代价。游戏对象属性设计这份属性结构设计，基本就是参考了上面提到的设计思想。整个系统有如下组件:Entity: +-------------------+ | property-table | +-------------------+ | component-table | +-------------------+Property: +-------------------+ | observer-list | +-------------------+ Component: +--------------------+ | logic-related data | +--------------------+ | logic-related func | +--------------------+意即，所有Entity都包含一个属性表和组件表。这里的属性表并非硬编码的属性数据成员集合，而是一个key-value形式的表。Property包含一个观察者列表，其实就是一系列回调函数，但是这些观察者本质上也是组件，后面会提到。Component正如上文描述，仅包含Component本身实现的功能所需要的数据和函数。整个结构大致的代码如下:class Entity {private: GUID id; std::map&lt;std::string, IComponent*&gt; components; std::map&lt;std::string, Property*&gt; properties;};class Property {private: std::string name; Value val; std::vector&lt;IComponent*&gt; observers;};class IComponent {public: virtual bool Operate (const Args &amp;args) { return false; } virtual void OnNotify (const Property &amp;property, const Args &amp;args) {}protected: std::string name; Entity *entity;};属性本身是抽象的，这完全是因为我们将属性统一地放在了一个表里。从而又导致属性的值也需要做一个抽象包装。因为Component主要是针对游戏对象属性而存在的。而针对游戏对象属性的操作，我将其分为主动操作和被动操作，其对应的组件就被称为主动组件和被动组件。这里的主被动，主要是针对这个组件是通过哪种方式启动的。如果是某个地方直接需要某个组件启动，那么称为主动，例如玩家角色刚上线，需要编码角色属性到客户端，则启动属性更新组件；如果某个组件是因为某个属性的改变而启动，则称为被动，例如当玩家受到伤害，HP非满值时，则需要启动HP自动回复组件。针对组件的主被动特性，就得到主动接口Operate，被动接口OnNotify。因为不同的组件实现，依赖的启动参数可能完全不一样，所以这里对参数做了Args的封装。Args具体实现时，可以采用类继承方式根据具体应用塞入具体的参数；也可以直接使用tuple来包装不同类型不同个数的参数。因为有了个被动属性，所以就在属性身上放置了一个Observer列表。当然这里不一定要采用这种细粒度的方式—将Observer绑在属性身上，而可以将observer列表放到Entity身上。接下来看一些具体的用例。具体用例上线属性更新// serialize player to client// 取得ClientUpdater组件IComponent *updater = entity-&gt;GetComponent (\"ClientUpdater\");// 更新至client_socket客户端updater-&gt;Operate (Args (client_socket));玩家属性改变// hurt player// 取得属性存取组件IComponent *accessor = entity-&gt;GetComponent (\"PropertyAccessor\");// 改变属性accessor-&gt;Operate (Args (\"HP\", Value(10))); // decrease 10 HP...// dirty property updator component get calledvoid DirtyUpdator::OnNotify (const Property &amp;property, const Args &amp;args) { // 将此属性放到脏属性容器，稍候统一更新 dirties.push (property);}代码到真正应用时，可能会加入更多的接口，以下代码情景不追加叙述。游戏对象刚创建// in script, or by config file, or hard code, etc...entity-&gt;AddProperty (\"HP\", Args (10)) ;entity-&gt;AddProperty (\"MP\", Args (5));... entity-&gt;AddComponent (componentFactory-&gt;Create (\"ClientUpdater\"));entity-&gt;AddComponent (componentFactory-&gt;Create (\"PropertyAccessor\"));...组件被创建时ClientUpdater::ClientUpdater () { entity-&gt;GetProperty (\"HP\")-&gt;AddObserver (this); ...};;END;;" }, { "title": "多重继承和void*的糗事", "url": "/posts/multi-inherit-void/", "categories": "c/c++", "tags": "c/c++", "date": "2011-04-30 00:00:00 +0800", "snippet": "C++为了兼容C，导致了不少语言阴暗面。BjarneStroustrup在&lt;D&amp;E&gt;一书里也常为此表现出无奈。另一方面，强制转换也是C++的一大诟病。但是，因为我们的应用环境总是那么“不纯”，所以也就常常导致各种问题。本文即描述了一个关于强制转换带来的问题。这个问题几年前我曾遇到过(&lt;多线程下vc2003,vc2005对虚函数表处理的BUG？&gt;)，当时没来得及深究。深究C++的某些语法，实在是件辛苦事。所以，这里也不提过于诡异的用法。问题考虑下面非常普通的多重继承代码:class Left {public: virtual void ldisplay () { printf (\"Left::ldisplay\\n\"); }};class Right {public: virtual void rdisplay () { printf (\"Right::rdisplay\\n\"); }};class Bottom : public Left, public Right {public: virtual void ldisplay () { printf (\"Bottom::ldisplay\\n\"); }};这样子的代码在我们的项目中很容易就会出现，例如:class BaseObject;class EventListener;class Player : public BaseObject, public EventListener别紧张，我当然不会告诉你这样的代码是有安全隐患的。但它们确实在某些时候会出现隐患。在我们的C++项目中，也极有可能会与一些纯C模块打交道。在C语言里，极有肯能出现以下的代码:typedef void (*allocator) (void *u); void set_allocator (allocator alloc, void *u);之所以使用回调函数，是出于对模块的通用性的考虑。而在调用回调函数时，也通常会预留一个userdata的指针，用于让应用层自由地传递数据。以上关于多重继承和void*的使用中，都属于很常规的用法。但是当它们遇到一起时，事情就悲剧了。考虑下面的代码:Bottom *bobj = new Bottom(); // we HAVE a bottom objectRight *robj = bobj; // robj point to bobj?robj-&gt;rdisplay(); // display what ?void *vobj = bobj; // we have a VOID* pointerrobj = (Right*) vobj; // convert it backrobj-&gt;rdisplay(); // display what?这里的输出结果是什么呢？:Right::rdisplay Bottom::ldisplay // !!!!由void*转回来的robj调用rdisplay时，却调用了莫名其妙的Bottom::ldisplay！多重继承类的内存布局类对象的内存布局，并不属于C++标准。这里仅以vs2005为例。上面例子中，Bottom类的内存布局大概如下:+-------------+| Left_vptr |+-------------+| Left data |+-------------+| Right_vptr |+-------------+| Right data |+-------------+| Bottom data |+-------------+与单继承不同的是，多重继承的类里，可能会包含多个vptr。当一个Bottom对象被构造好时，其内部的两个vptr也被正确初始化，其指向的vtable分别为:Left_vptr ---&gt; +---------------------+ | 0: Bottom::ldisplay | +---------------------+Right_vptr ---&gt; +---------------------+ | 0: Right::rdisplay | +---------------------+转换的内幕类体系间的转换隐式转换相比强制转换而言，一定算是优美的代码。考虑如下代码的输出:Bottom *bobj = new Bottom();printf (\"%p\\n\", bobj);Right *robj = bobj;printf (\"%p\\n\", robj);其输出结果可能为:003B5DA0003B5DA4*结论就是，Rightrobj = bobj;时，编译器返回了bobj的一个偏移地址。**从语言角度看，就是这个转换，返回了bobj中Right*的那一部分的起始地址。但编译器并不总是在bobj上加一个偏移，例如:bobj = NULL;Right *robj = bobj;编译器不会傻到给你一个0x00000004的地址，这简直比NULL更无理。*void转换**编译器当然有理由做上面的偏移转换。那是因为在编译阶段，编译器就知道bobj和Right之间的关系。这个偏移量甚至不需要在运行期间动态计算，或是从某个地方取。如果你看过上面代码对应的汇编指令，直接就是:add eax, 4 ; 直接加 sizeof(Left)，记住，Right在Left之后void就没那么幸运了。void和Bottom没有任何关系，所以:void *vobj = bobj; // vobj的地址和bobj完全相同然后当你将vobj转换到一个Right*使用时:robj = (Right*) vobj; // 没有偏移转换，robj == vobj == bobjrobj-&gt;rdisplay();robj指向的是Bottom的起始地址，天啊，在我们学习C++时，我们可以说Bottom就是一个Left，也是一个Right，所谓的iskind of。但这里的悲剧在于，按照上面的逻辑，我们在使用Right时，其实应该使用Bottom里Right那一部分。但现在这个转换，却让robj指向了Bottom里Left那一部分。当调用 robj-&gt;rdisplay 时，编译器当然按照Right的内存布局，生成一个虚函数的调用指令，大概就是:mov vptr, robj-&gt;[0] ;; vptr在robj起始地址处mov eax, vptr[0] ;; rdisplay在vtable中位于第一个mov ecx, robjcall eax总而言之， robj-&gt;rdisplay就是使用偏移0处的值作为vptr，然后使用vptr指向的vtable中第一个函数作为调用。但，robj正指向bobj的起始地址，这个地址是放置Left_vptr的地方。这个过程，使用了Left_ptr，而Left_ptr指向的vtable中，第一个函数是什么呢？:Left_vptr ---&gt; +---------------------+ | 0: Bottom::ldisplay | +---------------------+正是Bottom::ldisplay！到这里，整个问题的原因就被梳理出来了。;;END;;" }, { "title": "浅谈代码分层：构建模块化程序", "url": "/posts/module-level/", "categories": "module", "tags": "module", "date": "2011-04-04 00:00:00 +0800", "snippet": "模块化的程序是怎样的程序？我们可以说一个具有明显物理结构的软件是模块化的，例如带插件的软件，一个完整的软件由若干运行时库共同构建；也可以说一个高度面向对象的库是模块化的，例如图形引擎OGRE；也可以说一些具有明显层次结构的代码是模块化的。模块化的软件具有很多显而易见的好处。在开发期，一个模块化的设计有利于程序员实现，使其在实现过程中一直保持清晰的思路，减少潜伏的BUG；而在维护期，则有利于其他程序 员的理解。在我看来，具有良好模块设计的代码，至少分为两种形式： 整体设计没有层次之分，但也有独立的子模块，子模块彼此之间耦合甚少，这些子模块 构成了一个软件层，共同为上层应用提供服务； 整个库/软件拥有明显的层次之分，从最底层，与应用业务毫无相关的一层，到最顶层，完全对应用进行直接实现的那一层，每一个相对高层的软件层依赖于更底层的软件层， 逐层构建。上述两种形式并非完全分离，在分层设计中，某一层软件层也可能由若干个独立的模块构成。另一方面，这里也不会绝对说低层模块就完全不依赖于高层模块。这种双向依赖绝对不是 好的设计，但事实上我们本来就无法做出完美的设计。本文将代码分层分为两大类：一是狭义上的分层，这种分层一般伴有文件形式上的表现；一 是广义上的分层，完全着眼于我们平时写的代码。软件分层软件分层一般我们可以在很多大型软件/库的结构图中看到。这些分层每一层本身就包含大量代码。每个模块，每一个软件层都可能被实现为一个运行时库，或者其他以文件形式为 表现的东西。Example AndroidAndroid是Google推出的智能手机操作系统，在其官方文档中有Android的系统架构图：这幅图中很好地反映了上文中提到的软件层次。整个系统从底层到高层分为Linux kernel，Libraries/Runtime，ApplicationFramework，Applications。最底层的Kernel可以说与应用完全不相关，直到最上层的Applications，才提供手机诸如联系人、打电话等应用功能。每一层中，又可能分为若干相互独立（Again，没有绝对）的模块，例如Libraries那一层 中，就包含诸如Surfacemanager/SGL等模块。它们可能都依赖于Kernel，并且提供接口给 上层，但彼此独立。Example Compiler在编译器实现中，也有非常明显的层次之分。这些层次可以完全按照编译原理理论来划分。 包括： 词法分析：将文本代码拆分为一个一个合法的单词 语法分析：基于 词法分析 得到的单词流构建语法树 语义分析：基于 语法分析 得到的语法树进行语义上的检查等 生成器：基于 语义分析 结果（可能依然是语法树）生成中间代码 编译器：基于 生成器 得到的中间代码生成目标机器上的机器代码 链接器：基于 编译器 生成的目标代码链接成最终可执行程序软件分层的好处之一就是对任务(task)的抽象，封装某个任务的实现细节，提供给其他 依赖模块更友好的使用接口。隔离带来的好处之一就是可轻易替换某个实现。例如很 多UI库隔离了渲染器的实现，在实际使用过程中，既可以使用Direct X的渲染方式，也可 以使用OpenGL的实现方式。但正如之前所强调，凡事没有绝对，凡事也不可过度。很多时候无法保证软件层之间就是单向依赖。而另一些时候过度的分层也导致我们的程序过于松散，效率在粘合层之间绕来绕去 而消失殆尽。代码分层如果说软件分层是从大的方面讨论，那么本节说的代码分层，则是从小处入手。而这也更是贴近我们日常工作的地方。本节讨论的代码分层，不像软件分层那样大。每一层可能就是 百来行代码，几个接口。Example C中的模块组织很多C代码写得少的C++程序员甚至对一个大型C程序中的模块组织毫无概念。这是对其他技 术接触少带来的视野狭窄的可怕结果。在C语言的世界里，并不像某些C++教材中指出的那样，布满全局变量。当然全局变量的使用也并不是糟糕设计的标志(goto不是魔鬼)。一个良好设计的C语言程序懂得如何去抽象、 封装模块/软件层。我们以Lua的源代码为例。lua.h文件是暴露给Lua应用（Lua使用者）的直接信息源。接触过Lua的人都知道有个结构体叫lua_State。但是lua.h中并没有暴露这个结构体的实现。因为一旦暴露了实现，使用者就可能会随意使用其结构体成员，而这并不是库设计者所希望的。 封装数据的实现，也算 是构建模块化程序的一种方法。大家都知道暴露在头文件中的信息，则可能被当作该头文件所描述模块的接口描述。所以， 在C语言中任何置于头文件中的信息都需要慎重考虑。相对的，我们可以在很多.c文件中看到很多static函数。例如lstate.c中的stack_init。static用于限定其修饰对象的作用域，用它去修饰某个函数，旨在告诉：这个函数仅被当前文件（模块）使用，它仅用于本模块实现所依赖，它不是提供给模块外的接口！封装内部实现 ，暴露够用的接口，也是保持模块清晰的方式之一。良好的语言更懂得对程序员做一种良好设计的导向。但相对而言，C语言较缺乏这方面的语言机制。在C语言中，良好的设计更依赖于程序员自己的功底。Example Java中的模块组织相较而言，Java语言则提供了模块化设计的语法机制。在Java中，如同大部分语言一样，一般一个代码文件对应于一个代码模块。而在Java中，每个文件内只能有一个public class。 publicclass作为该模块的对外接口。而在模块内部，则可能有很多其他辅助实现的class，但它们无法被外部模块访问。这是语言提供的封装机制，一种对程序员的导向。Example OO语言中类接口设计无论在C++中，还是在Java中，一个类中的接口，都大致有各种访问权限。例如public、private、protected。访问权限的加入旨在更精确地暴露模块接口，隐藏细节。在C中较为缺乏类似的机制，但依然可以这样做。例如将结构体定义于.c文件中，将非 接口函数以static的方式实现于.c文件中。OO语言中的这些访问权限关键字的应用尤为重要。C++新手们往往不知道哪些成员该public，哪些该private。C++熟手们在不刨根挖底的情况下，甚至会对每个数据成员写出get/set接口（那还不如直接public）。在public/private之间，我们需要做的唯一决策就是，哪些数据/操作并非外部模块所需。如果外部模块不需要，甚至目前不需要，那么此刻，都不要将其public。一个public信息少的class，往往是一个被使用者更喜欢的class。（至于protected，则是用于继承体系之间，类之间的信息隐藏。）Example Lisp中的模块设计又得提提Lisp。基于上文，我们发现了各种划分模块、划分代码层的方式，无论是语言提供，还是程序员自 己的应用。但是如何逐个地构建这些层次呢？Lisp中倡导了一种更能体现这种将代码分层的方式：自底而上地构建代码。这个自底而上，自然是按照软件层的高低之分而言。这个过程就像上文举的编译原理例子一样。我们先编写词法分析模块，该模块可能仅暴露一个接口：get-token。然后可以立马对该模块进行功能测试。然后再编写语法分析模块，该模块也可能只暴露一个接口：parse。语法分析模块建立于词法分析模块之上。因为我们之前已经对词法分析模块进行过测试，所以对语法分析的 测试也可以立即进行。如此下去，直至构建出整个程序。每一个代码层都会提供若干接口给上层模块。越上层的模块中，就更贴近于最终目标。每一层都感觉是建立在新的“语言“之上。按照这种思想，最终我们就可以构建出DSL，即Domain Specific Language。分层的好处基于以上，我们可以总结很多代码分层的好处，它们包括（但不限于）： 隐藏细节，提供抽象，隐藏的细节包括数据的表示（如lua_State）、功能的实现 在新的一层建立更高层的“语言” 接口清晰，修改维护方便 方便开发，将软件分为若干层次，逐层实现一个问题的解决有时候，我们的软件层很难做到单向依赖。这可能是由于前期设计的失误导致，也可能确实是情况所迫。在很多库代码中，也有现成的例子。一种解决方法就是通过回调。回调的实现方式可以是回调函数、多态。多态的表现又可能是Listener等模式。所有这些，主要是让底层模块不用知道高层模块。在代码层次上，它仅仅保存的是一个回调信息，而这个信息具体是什么，则发生在运行期（话说以前给同事讲过这个）。这样就简单 避免了底层模块依赖高层模块的问题。END精确地定义一个软件中有哪些模块，哪些软件层。然后再精确地定义每个模块，每个头文件，每个类中哪些信息是提供给外部模块的，哪些信息是私有的。这些过程是设计模块化程 序的重要方式。但需要重新强调的是，过了某个度，那又是另一种形式的糟糕设计。但其中拿捏技巧，则只 能靠实践获取。" }, { "title": "Lisp实践：开发RSS阅读器", "url": "/posts/lisp-rss/", "categories": "lisp", "tags": "lisp", "date": "2011-03-30 00:00:00 +0800", "snippet": "一、RSS阅读器的实现RSS Reader的实现并不像它看上去那么复杂。当初在决定写这个作为Lisp练习时，甚至觉得没有多少内容可做。其简单程度甚至用不了你启动一个慢速IDE的时间:D。对Lisp无兴趣的 TX只需要读完这一节即可，什么是RSS阅读器?RSS在实现上，可以说是XML的又一次扩张式的应用。因为RSS最重要的东西就是一个XML文件。RSS主要用于Web中的内容同步。例如我们写的博客，门户网站的新闻，都是内容。Web服务器将这些内容组织成XML，然后我们通过一个客户端来解析这些XML，就可以在不用直接访 问网站的情况下获取信息：RSS阅读器就是这样一个从Web服务器通过RSS（表现形式为XML）来获取信息内容的工具。它可以被实现为一个独立的客户端程序，也可以实现为像Google Reader这种网页形式。后者其核心功能其实是Google服务器在做，取得信息后再发给用户。RSS文件上已提及，RSS的实现其实就是个XML文件。这个XML文件格式非常简单，例如:&lt;?xml version=\"1.0\"?&gt;&lt;rss version=\"2.0\"&gt; &lt;channel&gt; &lt;title&gt;Liftoff News&lt;/title&gt; &lt;link&gt;http://liftoff.msfc.nasa.gov/&lt;/link&gt; &lt;description&gt;Liftoff to Space Exploration.&lt;/description&gt; &lt;item&gt; &lt;title&gt;Star City&lt;/title&gt; &lt;link&gt;http://liftoff.msfc.nasa.gov/news/2003/news-starcity.asp&lt;/link&gt; &lt;description&gt;Oh no, you wrote another blog!&lt;/description&gt; &lt;/item&gt; &lt;/channel&gt;&lt;/rss&gt;我们身边到处都是RSS文件，例如http://www.cppblog.com/rss.aspx。RSS文件的框架大 致为:&lt;rss&gt; &lt;channel&gt; &lt;item&gt; &lt;/item&gt; &lt;item&gt; &lt;/item&gt; ... &lt;/channel&gt;&lt;/rss&gt;对，其框架就是这样，一个channel节点，其下若干个item节点。举例来说，CPPBLOG首页就 是一个channel，该channel下有若干原创文章，每篇文章就是一个item。 无论是channel，还是item，都会有很多属性，例如title/description/link，有些属性是RSS规范里要求必须有的，有的是可选的。交互过程那么，服务器和客户端是如何交互的呢？首先，服务器上的程序针对其某个页面，生成对应的RSS文件。这个RSS文件基本上是有固定的URL的。客户端每次获取内容时，就从这个固定的URL获取这个RSS文件。客户端获取到这个RSS文件后，解析之，再呈现给用户。这就是整个过程。这个过程中客户端与服务器的交互，全部是正常的HTTP请求。而RSS阅读器，如果做得足够简单，则只需要从指定的地方获取到RSS文件，然后解析这个 XML文件，然后以相对友好的形式显示即可。扩展虽然RSS阅读器在核心功能上很简单，但是作为一个可以使用的工具，依然有很多功能点需 要实现。基本功能包括： 记录用户关注的RSS 缓存某个RSS过去一段时间更新的内容 对HTTP回应的处理，最重要的就是重定向处理我们还可以做很多扩展，例如Google Reader之类的在线RSS阅读器。这些阅读器的RSS抓取功能做在服务器端，它们除了上面提到的基础功能外，还会包含内容分类，给内容打一些 标签，分析用户的订阅习惯然后推荐类似的内容等等。二、Lisp实现本节描述在Lisp中实现上文的内容。主要包括： 通过HTTP请求获取到RSS文件、解析RSS文件 。获取RSS文件Lisp虽然历史悠久，但其扩展库标准却做得很拙劣。偏应用级的扩展库要么由编译器实现提供，要么就得自己在网上找。一方面使用者希望库使用起来方便，另一方面库开发者在跨编 译器实现方面也头疼不已。所幸现在有了quicklisp，安装第三方库就像Ubuntu里安装软件 一样简单（大部分）。socket支持就是面临的第一个问题。不过我这里并不考虑跨编译器实现的问题，直接使用 SBCL里的socket接口。要获取RSS文件，只需要连接Web服务器，发起HTTP的GET请求即可。当然，建立TCP连接，组建HTTP请求包，就不是这里的讨论了。我们还是拿CPPBLOG首页的RSS为例，该RSS的URL为:http://www.cppblog.com/rss.aspx拆分一下，得到host为www.cppblog.com（即我们要connect的地址），rss的uri为/rss.aspx（即HTTP请求里的文件URI），于是建立HTTP请求包:GET /rss.aspx HTTP/1.0Host: www.cppblog.com关于HTTP请求的一些基础知识，可以参考我很早前写的一篇博客：&lt;实现自己的http服务器&gt;。正常情况下，Web服务器就会返回RSS的文件内容。然后我们就可以继续解析。解析RSSRSS本身是一个XML格式的文件。之前连接Web服务器发起HTTP请求没有用到第三方库，但是解析XML文件不是几十来行代码能搞定的事情，所以这里需要选用一个第三方库。我用的是s-xml，这个库在我之前的关于Lisp的文章中提到过。s-xml与我之前在C++ 领域见到的XML解析库最大的不同点在于，它提供的API是基于事件模式的。意思是说，你不要去查询某个element的值是多少，当我解析到的时候会告诉你。事件模式的编程方式自然 离不开回调函数:(s-xml:start-parse-xml stream (make-instance 's-xml:xml-parser-state :new-element-hook #'decode-rss-new-element :finish-element-hook #'decode-rss-finish-element :text-hook #'decode-rss-text)))与s-xml交互的也就是上面代码里提到的三个函数：new-element-hook, finish-element-hook ,text-hook。这种类型的接口导致解析代码大量减少，但不利于理解。我们要在整个解析过程中传递数据，需要通过与s-xml交互的函数参数（当然不会蠢到去用全局变量）。解析过程中通过往函数参数指定的对象身上塞数据完成，整个解析实现也就几十行代码。 文章尾可下载代码看看。显示出来通过上面两步，我们得到了RSS文件、解析出了具体内容，最后一步就是呈现出来看看。RSS文件里每个Item都是一篇文章（新闻之类），这个文章内容可直接包含HTML标记，说白了，这些内容就是直接的HTML内容。要显示这些内容，最简单的方法就是把一个RSS转换成一种 简单的HTML文件，以供阅读。这里就涉及到HTML generator，几乎所有的Lisper都会写一个HTML产生器（库）（虽然目前我还没写）。这种库的作用就是方便地输出HTML文件。Lisp相对于其他语言很大的一个特点，或者说是优点，就是其语言本身的扩展能力。这种扩展不是简单的添加几个函数，也不是类，而是提供一些就像语言本身提供的特殊操作符一样 的东西。而HTMLgenerator正是这种东西大放异彩的地方。这种感觉有点像在C++中通过模板造出各种增强语言特性的东西一样（例如boost/loki）。因为我这里只是输出简单的HTML文件，何况我对HTML的标记了解的也不多，也懒得再花经历 。所以我暂时也就将就了些土方法:(with-output-to-string (stream) (let ((channel (rss-channel rss))) ;取出channel对象 (format stream \"&lt;html&gt;&lt;head&gt;&lt;title&gt;~a&lt;/title&gt;&lt;/head&gt;\" (get-property channel :|title|)) ;取出channel的title最后组合一些接口，即可将整个过程联系起来，导出html文件:(cl-rss-test:test-rss-http :uri \"/news/newshot/hotnewsrss.xml\" :host \"cd.qq.com\")然后在浏览器里查看，如图:其他当一些代码可以工作起来的时候，就可以着手测试这批代码。然后我就用这个工具测试我 GoogleReader里订阅的一些RSS。最大的问题，就是关于HTTP重定向的问题。当服务器返回301或者302的错误信息时（HTTP回应），就标示请求的URI被移动到了其他地 方，客户端需要访问新的地址。这个其实查查HTTP的规范就可以轻易解决。重定向时， 新的URI被指定在Response Header里的Location域，取出来发起第二次请求即可。下载代码参考文档 HTTP规范:http://www.w3.org/Protocols/rfc2616/rfc2616.html RSS2.0规范:http://feed2.w3.org/docs/rss2.html;;EOF;;" }, { "title": "Lisp一瞥：增强型变量Symbol", "url": "/posts/lisp-symbol/", "categories": "lisp", "tags": "lisp", "date": "2011-03-21 00:00:00 +0800", "snippet": "变量，是所有编程语言里都有的语法概念。在C/C++中，变量用于标示一个内存地址，而变量名则在语法层面上代表这个地址。当链接器最终链接我们的程序时，就将这些名字替换为实际的地址。在其他语言中，变量虽然或多或少有其他不同的含义，但也大致如此。Lisp中的变量也差不多这样，但若将variable和Lisp中的 symbol 放在一起，则多少会 带来些困惑。Lisp中的“变量”很多教授Lisp的书中，大概会简单地告诉我们可以使用如下的方式定义一个全局变量 [1]_.(defparameter *var* 1)如上代码，我们便定义了一个全局变量 *var* [2]_ ，它被初始化为数值1。同样，我们 还可以使用另一种基本相同的方式:(defvar *var* 1)除了全局变量，我们还可以定义局部变量。但局部变量的定义稍显麻烦（却可能是另一种设计考虑）。定义局部变量需要使用一些宏，或者特殊运算符，例如:(let ((var 1)) (format t \"~a\" var))好了，就这些了。Lisp中关于变量的细节，也就这些。你甚至能用你在C/C++中的经验来窥探一切。但是，我们很快就看到了很多困惑的地方。我遇到的第一个困惑的地方来源于函数，那么等我讲讲函数再来分享下坎坷。Lisp中的函数Lisp中的函数绝对不复杂，你绝对不用担心我在忽悠你 [3]_ 。作为一门函数式语言，其首要任务就是加强函数这个东西在整个语言里的功能。如果你喜欢广阅各种与你工作不相干的技术，你肯定已经对很多函数式语言世界中的概念略有耳闻。例如闭包，以及first class type [4]_ 。Lisp中的函数就是first class type。这什么意思呢？直白来说，Lisp中的函数和变量 没什么区别，享有同等待遇 。进一步来说，变量fn的值可以是数值1，也可以是字符串“hello”，甚至是某个函数。这其实就是C++程序员说的functor。Lisp中定义函数非常简单:(defun add2 (x) (+ 2 x))这样，我们就定义了一个名为add2，有1个参数，1个返回值的函数。要调用该函数时，只需 要 (add2 2)即可。这简直和我们在Lisp中完成一个加法一模一样:(+ 2 3)Lisp作为一门函数式语言，其函数也能作为另一个函数的参数和返回值 [5]_(defun apply-fn (fn x) (funcall fn x))apply-fn函数第一个参数是一个函数，它使用funcall函数间接地调用fn指向的函数。作为一个C++程序员，这简直太好理解了，这完全就是一个函数指针的语法糖嘛。于是，假设我 们要使用apply-fn来间接调用add2函数:(apply-fn add2 2) ;; wrong 可是这是不对的。我们需要通过另一个特殊操作符来完成这件事:(apply-fn #'add2 2) ;; right#‘操作符用于将add2对应的函数取出来，这么说当然不大准确。Again，作为一个C++程序员，这简直就是个取地址操作符&amp;的语法糖嘛。好吧，这么理解起来似乎没问题了。Lisp中能甚至能在任何地方定义一个函数，例如我们创建一个函数，该函数返回创建出来的 函数，这是一个典型的讲解什么是 闭包的例子:(defun get-add-n (n) #' (lambda (x) (+ x n)))无论如何，get-add-n函数返回一个函数，该函数是add2函数的泛型实现。它可以将你传入的参数加上n。这些代码里使用了lambda表达式。lambda表达式直白来说，就是创建一个字面上的函数。这又是什么意思呢？就像我们在代码中写出2，写出”hello”一样，2就是个字面上的数字，”hello”就是个字面上的字符串 [6]_ 。那么，总而言之，通过lambda创建一个函数体，然后通过#‘操作符即可得到一个函数，虽然 没有名字。有了以上知识后，Againand again，作为一个C++程序员，很快我们就能得到一个程序：定义变量，用变量去保存一个函数，然后通过这个变量来调用这个函数。这是多么天经地义的事，就像之前那个通过参数调用其指向的函数一样:;; wrong (defvar fn #' (lambda (x) (+ x 2)))(fn 3)这样的代码是不对的，错误发生于第二行，无论你使用的Lisp实现是哪种，大概会得到如下 的错误信息:\"The function FN is undefined.\"老实说，这已经算是多么有迹可循的错误提示了啊。将以上代码和之前的apply-fn对比，是多么得神似啊，可惜就是错的。这是我们遇到的第一个理解偏差导致的问题。如果你还不深入探究，你将会在这一块遇到更多麻烦。及时地拿出你的勇气，披荆斩棘，刨根究底，绝对 是学习编程的好品质。“万恶之源“：SYMBOL上文中提到的变量函数之类，之所以会在某些时候与我们的理解发生偏差，并且总是存在些神秘的地方无法解释。这完全是因为我们理解得太片面导致。Lisp中的Symbol可以说就是某个变量，或者某个函数，但这太片面。Lisp中的Symbol拥有更丰富的含义。Symbol的名字就像很多语言的变量、函数名一样，Lisp中的Symbol比其他语言在命名方面更自由：只 要位于’|’字符之间的字符串，就表示一个合法的Symbol名。 我们可以使用函数symbol-name来获取一个Symbol的名字，例如:(symbol-name '|this is a symbol name|)输出：\"this is a symbol name\"‘(quote)操作符告诉Lisp不要对其修饰的东西进行求值(evaluate)。但假如没有这个操作符会怎样呢？后面我们将看到会怎样。Symbol本质&lt;ANSI Common Lisp&gt;一书中有句话真正地揭示了Symbol的本质：Symbols are real objects。是的，Symbols是对象，这个对象就像我们理解的C++中的对象一样，它是一个复合的数据结构。该数据结构里包含若干域，或者通俗而言：数据成员。借用&lt;ANSI Common Lisp&gt;中的一图： 通过这幅图，可以揭开所有谜底。一个Symbol包含至少图中的几个域，例如Name、Value、Function等。在Lisp中有很多函数来访问这些域，例如上文中使用到的symbol-name，这个函数本质上就是取出一个Symbol的Name域。Symbol与Variable和Function的联系自然而然地，翻阅Lisp文档，我们会发现果然还有其他函数来访问Symbol的其他域，例如:symbol-functionsymbol-valuesymbol-packagesymbol-plist但是这些又与上文提到的变量和函数有什么联系呢？真相只有一个，变量、函数粗略来 说就是Symbol的一个域，一个成员。变量对应Value域，函数对应Function域。一个Symbol 这些域有数据了，我们说它们发生了绑定(bind)。而恰好，我们有几个函数可以用于判 定这些域是否被绑定了值:boundp ;判定Value域是否被绑定fboundp;判定Function域是否被绑定通过一些代码来回味以上结论:(defvar *var* 1)(boundp '*var*) ; 返回真(fboundp '*var*) ; 返回假(defun *var* (x) x) ; 定义一个名为*var*的函数，返回值即为参数(fboundp '*var*) ; 返回真上面的代码简直揭秘了若干惊天地泣鬼神的真相。首先，我们使用我们熟知的defvar定义了 一个名为 *var*的变量，初值为1，然后使用boundp去判定 *var* 的Value域是否 发生了绑定。这其实是说：原来定义变量就是定义了一个Symbol，给变量赋值，原来就 是给Symbol的Value域赋值！其实，Lisp中所有这些符号，都是Symbol。 什么变量，什么函数，都是浮云。上面的例子中，紧接着用fboundp判断Symbol *var* 的Function域是否绑定，这个时候为假。 然后我们定义了一个名为*var* 的函数，之后再判断，则已然为真。这也是为什么， 在Lisp中某个函数可以和某个变量同名的原因所在。从这段代码中我们也可以看出 defvar/defun这些操作符、宏所做事情的本质。More More More事情就这样结束了？Of course not。还有很多上文提到的疑惑没有解决。首先，Symbol是如此复杂，那么Lisp如何决定它在不同环境下的含义呢？Symbol虽然是个对象，但它并不像C++中的对象一样，它出现时并不指代自己！不同应用环境下，它指代的东西也不一样。这 些指代主要包括变量和函数，意思是说：Symbol出现时，要么指的是它的Value，要么是 它的Function。 这种背地里干的事情，也算是造成迷惑的一个原因。当一个Symbol出现在一个List的第一个元素时，它被处理为函数。这么说有点迷惑人，因为它带进了Lisp中代码和数据之间的模糊边界特性。简单来说，就是当Symbol出现在一个括号表达式(s-expression)中第一个位置时，算是个函数，例如:(add2 3) ; add2位于第一个位置，被当作函数处理(*var* 3) ; 这里*var*被当作函数调用，返回3除此之外，我能想到的其他大部分情况，一个Symbol都被指代为它的Value域，也就是被当 作变量，例如:(*var* *var*) ; 这是正确的语句，返回1这看起来是多么古怪的代码。但是运用我们上面说的结论，便可轻易解释：表达式中第一个 *var*被当作函数处理，它需要一个参数；表达式第二部分的 *var* 被当作变量 处理，它的值为1，然后将其作为参数传入。再来说说’(quote)操作符，这个操作符用于防止其操作数被求值。而当一个Symbol出现时，它总是会被求值，所以，我们可以分析以下代码:(symbol-value *var*) ; wrong这个代码并不正确，因为 *var* 总是会被求值，就像 (*var* *var*) 一样，第二 个 *var*被求值，得到数字1。这里也会发生这种事情，那么最终就等同于:(symbol-value 1) ; wrong我们试图去取数字1的Value域，而数字1并不是一个Symbol。所以，我们需要quote运算符:(symbol-value '*var*) ; right这句代码是说，取Symbol *var* 本身的Value域！而不是其他什么地方。至此，我们 便可以分析以下复杂情况:(defvar *name* \"kevin lynx\")(defvar *ref* '*name*) ; *ref*的Value保存的是另一个Symbol(symbol-value *ref*) ; 取*ref*的Value，得到*name*，再取*name*的Value现在，我们甚至能解释上文留下的一个问题:;; wrong (defvar fn #' (lambda (x) (+ x 2)))(fn 3)给fn的Value赋值一个函数， (fn 3) 当一个Symbol作为函数使用时，也就是取其Function域来做调用。但其Function域什么也没有，我们试图将一个Symbol的Value域当作Function来使用。如何解决这个问题？想想，symbol-function可以取到一个Symbol的 Function域:(setf (symbol-function 'fn) #' (lambda (x) (+ x 2)))(fn 3)通过显示地给fn的Function域赋值，而不是通过defvar隐式地对其Value域赋值，就可以使 (fn 3)调用正确。还有另一个问题也能轻易解释:(apply-fn add2 2) ; wrong本意是想传入add2这个Symbol的function域，但是直接这样写的话，传入的其实是add2的 Value域 [7]_，这当然是不正确的。对比正确的写法，我们甚至能猜测#‘运算符就是一个取Symbol的Function域的运算符。进一步，我们还可以给出另一种写法:(apply-fn (symbol-function 'add2) 2)深入理解事情的背后，你会发现你能写出多么灵活的代码。END关于Symbol的内容还有更多，例如Package。正确理解这些内容以及他们之间的关系，有助 于更深刻地理解Lisp。注解 [1] 在Lisp中全局变量又被称为dynamic variables [2] Lisp中按照习惯通常在为全局变量命名时会加上星号，就像我们习惯使用g_一样 [3] 因为我确实在忽悠你 [4] first class type，有人翻译为“一等公民”，我觉得压力巨大 [5] 即高阶函数 [6] “字面“主要是针对这些信息会被词法分析程序直接处理 [7] 这可能导致更多的错误" }, { "title": "用lisp开发博客客户端", "url": "/posts/lisp-writer/", "categories": "lisp", "tags": "lisp", "date": "2011-03-13 00:00:00 +0800", "snippet": "最近一直在学习Lisp这门语言。回头一看，基本上接近1个月了。刚开始接触Lisp是因为看了&lt;Lisp本质&gt;，然后我发现有很多人宗教般地忠诚这门语言，于是就来了兴趣。当然并不是每次因为某篇写得很geek技术文章就去学习某个新的技术点。一个月时间对我来说还是很珍贵了。但是Lisp绝对是大部分程序员都值得一学的语言（就像Haskell一样）。我能给出的简单理由包括： 大部分程序员只会命令式语言（C/C++/C Like etc)，缺乏函数式语言解决编程问题的思想（当然Lisp不是纯函数式) Lisp是仅次于Fortran的古老语言，很多优秀的语言设计思想在现代的一些语言里都找得到 装B党必备另一方面，结合我一个月以来的读书和两个练习工程的实践经历，我觉得也有些理由值得你不去学习Lisp： 你会Haskell或者其他函数式语言 我目前还是觉得Lisp学习曲线高(大概是因为我读到的书都在应用语法层兜圈子，事实上Lisp的语法之统一，全特么的是s-expression)，你不愿意花费这些成本 you are too old bo to be a B关于这篇文档这篇博客我使用reStructuredText格式编写，然后用docutls导出为html，再然后使用这回用lisp开发的基于metaweblog API的博客客户端，自动发布到CPPBLOG。他们怎么说Lisp我就摘录些书上的观点(历史)： 1958年，John McCarthy和他的学生搞出了Lisp，包括其第一个实现，最初貌似也是以一篇论文起头 Lisp可以让你做其他语言里无法做的事情(&lt;ANSI common Lisp&gt;) 大部分编程语言只会告诉你不能怎样做，这限制了你解决问题的思路，Lisp not (&lt;ANSICommon Lisp&gt;) Lisp让你以Lisp的思维思考问题，换到其他语言你会说：为什么X语言就不支持这个特性呢(Once you’ve leanred Lisp, you’ll even dream in Lisp) (&lt;Land Of Lisp&gt;) Lisp代码更清晰地体现你的想法(&lt;Practical Common Lisp&gt;)And my opinion我可还没到把Lisp捧上天的地步。如果Lisp如此之好，为什么用的人不多？&lt;Land Of Lisp&gt;里作者恰好对这个问题做了回答(bla bla bla，懒得细读)。 Lisp也是一门杂和型风格的语言，函数式、命令式、面向对象，以及最被人吹捧的宏编程–程序自己写自己 Lisp的语句全部以(xxx xxx)的形式出现，被称为s-expression，我看称为括号表达式还差不多 Lisp每条语句都有返回值，没基础过函数式编程的同学，if语句也是有返回值的 函数式编程语言的一个重要特性就是闭包(closure)，这个东西用来避免全局变量实在太geek了开始学习LispLisp不像有些语言，有个直接的机构来维护。感觉它更像C/C++一样，只有个标准，然后有若干编译器（解释器）实现。Lisp在几十年的发展中，产生了很多种方言。方言也就是形变神不变的语言变种，本文说的Lisp均指Lisp的方言Common Lisp。另一个比较有名的方言是Scheme，关于各个方言的特点，&lt;Land Of Lisp&gt;里也给了一个图片：其中，最左边那只wolf就是Common Lisp，右边那只sheep就是Scheme。要学习Lisp，首先就是选择方言。然后最重要的就是选择一个编译器实现。世界上知名的有十几种实现（也许更多）。一些商业版本非常强大，甚至能编译出很小的本地代码执行文件，不过价格也不菲。当然也有很多开源免费的实现，例如CLISP、SBCL。我选用的是SBCL。SBCL交互式命令行不支持括号匹配，甚至没有输入历史。要实现这两个功能，可以装一个lisp工具：linedit。在lisp的世界中，要获得一个lisp的库实在不是件方便的事。尤其是这些免费的编译器实现，并不像有些语言一样，直接随编译器带个几十M的库。然后就有了quicklisp这个工具。该工具就像Ubuntu系统里的软件管理器一样，你可以在lisp里直接获取某个库。quicklisp检查该库是否存在，不存在直接从它的服务器上下载人然后自动安装。此外，在lisp的世界里，写出来的程序不再是跨OS。OS的差异由编译器实现来解决。但是，写lisp程序却需要考虑跨编译器实现（egg hurt）。这也是个无比伤神的事，比跨OS更伤神。因为OS就那么几个，但lisp的编译器实现，流行的也有好几个。lisp的世界里，工程组织也有特殊的一套，就像makefile一样，这就是asdf。博客客户端如何实现像我们这种基本没接触过Web开发的人，可能完全没有思路去实现一个博客客户端。事实上实现起来非常简单。使用过其他博客客户端（例如Windows Live writer）的人肯定知道metaweblog API，在配置客户端的时候需要填入。例如CPPBLOG的这个地址就是http://www.cppblog.com/kevinlynx/services/metaweblog.aspx。这个页面展示了一些API说明。这些API就是博客客户端和服务器进行操作通信的接口。意思是说，服务器端提供这这些接口，我们的客户端调用这些接口即可。例如:blogger.deletePost，调用该接口即可删除一篇博客文章但是客户端如何调用到这个接口呢？这需要通过一种新的技术（或者说标准），即 xml rpc。rpc大家应该清楚，xml rpc其实说白了， 就是把接口调用的细则塞进 http请求发给web服务器，服务器接收请求完成操作后再把结果以http回应的形式丢给客户端，即完成了一次接口调用 。至于http请求回应的细则就不提了，无非就是一些特殊格式的数据，通过tcp连接与服务器交互这些数据。所以，基本上，整个过程还是非常简单。如何来将调用细节塞进http请求，则是以xml rpc标准来做，其格式正好是xml格式。举个例子吧:&lt;?xml version='1.0'?&gt;&lt;methodCall&gt; &lt;methodName&gt;title_or_id&lt;/methodName&gt; &lt;params&gt; &lt;/params&gt;&lt;/methodCall&gt;当然这部分数据之前就是若干http请求的数据。服务器回应也是以xml格式组织:&lt;?xml version='1.0'?&gt;&lt;methodResponse&gt; &lt;params&gt; &lt;param&gt; &lt;value&gt;&lt;string&gt;Welcome to Zope.org&lt;/string&gt;&lt;/value&gt; &lt;/param&gt; &lt;/params&gt;&lt;/methodResponse&gt;我们的博客客户端所要做的，就是把这些博客发布相关的操作封装起来提供给使用者。底层实现主要包括http请求、xml-rpc的组织等。何况，这两部分在各个语言里都有大量的库存在，lisp自然也有。我这里直接选取了lisp的一个xml-rpc库：s-xml-rpc，基本上百来行代码就可以把各个功能跑一遍。例如以下lisp代码就实现了通过s-xml-rpc删除CPPBLOG的一篇文章:(defun delete-post (postid) (rpc-call \"blogger.deletePost\" postid \"kevinlynx\" \"password\" t))发布博客也很简单，根据metaweblog API接口的说明，发布博客时需要填充一个结构体。但主要涉及到的数据仅包括：文章内容、文章标题、文章分类（可选）:(defun new-post (title context &amp;optional (cates)) (rpc-call \"metaWeblog.newPost\" \"\" \"kevinlynx\" \"password\" (new-post-struct title context cates) t))值得注意的是，如果文章中有贴图，则需要事先将图片文件上传到服务器。CPPBLOG的metaweblog API里恰有API提供:(defun new-media-object (filename) (rpc-call \"metaWeblog.newMediaObject\" \"\" \"kevinlynx\" \"password\" (new-media-object-struct filename)))该函数读入图片文件，然后调用metaWeblog.newMediaObject接口，即可完成上传。上传成功后，服务器会返回该图片的URL。然后在我们的文章中就可以使用该图片了。完整实现方案仅仅将metaweblog的一些接口做封装，对于一个可以使用的博客客户端来说还远远不够。大部分同类工具都有一个友好的GUI编辑界面。我并不打算弄一个编辑界面出来，吃力不讨好的事情。我的打算是先用其他工具对文章做排版处理，最后导出为html格式。因为CPPBLOG支持直接发布一个html文件。然后在用这个lisp工具将整个文件作为博客文章内容发布。恰好公司最近打算用reStructureText(rst)格式来编辑文档，作为熟悉手段，我决定拿这个来练手。rst格式非常简单，同wiki命令很相似。在vim里编辑该文件非常合适，因为默认支持。见图:由图即可看出，rst是一种半所见即所得的格式。即：它遵循你在编辑器里的排版，同时也通过一些tag（例如image）来控制更丰富的输出。rst有很多前端工具，可以将rst文件输出，例如rst2html.py就可以输出为html。好吧，最最终我们得到了html格式的博客文章。但是如果文章中出现了图片，而图片基本上在本地，转成html后也是相对路径。我需要我的lisp writer(cl-writer)能自动扫描文章，发现有图片的地方，就自动将图片上传。最恶心的是上传后还得替换图片引用路径。这个工作可以在rst格式上做，也可以在结果格式html上做。通过xml解析库解析html比直接解析rst格式更简单，并且在扩展性上更好。最终这个html中图片路径替换工作只消耗了不到100行lisp代码。这在很大程度上也依赖于s-xml库的接口设计。最终封装好的发布接口如下，从这里也可以看出，函数式语言锻炼我们写出功能单一代码度短小的接口:(defun writer-post-new (post-file &amp;key (u (get-default-user))(cates)) (read-post-file u post-file context title (new-post u title context cates)))END别指望我发布的代码能够让你一键在你的博客上留下”this is a test”，你甚至别指望它能能够工作。但如果你本来就是一个资深的lisper，或者虽然不是lisper但却执意想看看结果。这里我就简要说说如何让这些代码欢乐起来: OS Ubuntu10.04，下载安装SBCL，不会有问题； 下载安装quicklisp，官方文档hand by hand，简单不会有问题； SBCL交互环境中使用quicklisp安装s-xml-rpc:(ql:quickload \"s-xml-rpc\") 装载我的代码:(asdf:load-system :cl-writer) 在home下添加配置文件.cl-writer.lisp，配置你博客信息，例如:(in-package cl-writer)(setf *default-user* (make-cppblog-user \"账户名\" \"密码\")) SBCL交互环境下测试:(in-package cl-writer)(new-post (get-default-user) \"this is a test\" \"title\")下载代码最后，终于敲完这篇文章，我需要通过以下步骤来发表它:in shell:rst2html.py lisp_xml_rpc.rst lisp_xml_rpc.htmlin SBCL:(writer-post-new \"lisp_xml_rpc.html\")EOF" } ]
